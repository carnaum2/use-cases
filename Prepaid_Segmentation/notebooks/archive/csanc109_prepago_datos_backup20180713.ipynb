{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended spark session: 35.3096249104 secs | default parallelism=2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # THIS MUST BE THE FIRST CELL IN THE NOTEBOOK\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    import time\n",
    "    import src.pycharm_workspace.lib_csanc109.utils.pyspark_configuration as pyspark_config\n",
    "\n",
    "    start_time = time.time()\n",
    "    sc, spark, sql_context = pyspark_config.get_spark_session(app_name=\"Euphoria Testing\", log_level=\"OFF\")\n",
    "    print(\"Ended spark session: {} secs | default parallelism={}\".format(time.time()-start_time, sc.defaultParallelism))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20180713-101730 [INFO ] Logging to file /var/SP/data/home/csanc109/logging/euphoria_20180713_101730.log\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os, sys\n",
    "from datetime import datetime\n",
    "import src.pycharm_workspace.lib_csanc109.utils.custom_logger as clogger\n",
    "\n",
    "HOME_SRC = os.path.join(os.environ.get('BDA_USER_HOME', ''), \"src\")\n",
    "\n",
    "PREPAID_EUPHORIA_SRC = os.path.join(os.environ.get('BDA_USER_HOME', ''), \"src\", \"pycharm_workspace\", \"PrepaidRevenueBoosting\")\n",
    "if PREPAID_EUPHORIA_SRC not in sys.path: \n",
    "    sys.path.append(PREPAID_EUPHORIA_SRC)\n",
    "    \n",
    "WHOAMI= os.getenv(\"USER\")\n",
    "    \n",
    "    \n",
    "# Create logger object (messages to stdout and file)\n",
    "logging_file = os.path.join(os.environ.get('BDA_USER_HOME', ''),\"logging\",\"euphoria_\"+datetime.now().strftime(\"%Y%m%d_%H%M%S\")+\".log\")\n",
    "logger = clogger.get_custom_logger(logging_file, std_channel=sys.stderr)\n",
    "logger.info(\"Logging to file {}\".format(logging_file))\n",
    "                      \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20180713-101730 [INFO ] ######################################################################\n",
      "20180713-101730 [INFO ] ##### EJECUTING PREPAID EUPHORIA CAMPAIGN AT 2018-07-13 10:17:30 #####\n",
      "20180713-101730 [INFO ] ######################################################################\n",
      "20180713-101754 [INFO ] THE END!!!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking a sample of 100\n"
     ]
    }
   ],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "from pyspark.sql.functions import substring\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import (udf,col,max as sql_max, when, count, isnull, concat, lpad, trim, lit, sum as sql_sum, length, upper)\n",
    "\n",
    "# Set up logs.\n",
    "right_now = datetime.now()\n",
    "reference_date = datetime(right_now.year, right_now.month, right_now.day)\n",
    "reference_date_str = reference_date.strftime('%Y%m%d')\n",
    "\n",
    "print_string = '##### EJECUTING PREPAID EUPHORIA CAMPAIGN AT {right_now} #####'\\\n",
    "    .format(right_now=right_now.strftime('%Y-%m-%d %X'))\n",
    "logger.info('#'*len(print_string))\n",
    "logger.info(print_string)\n",
    "logger.info('#'*len(print_string))\n",
    "\n",
    "reference_month = \"201805\"\n",
    "num_samples = 100\n",
    "debug_mode = True\n",
    "\n",
    "useful_columns_from_acFinalPrepago = [\"Fecha_ejecucion\", \"msisdn\",\n",
    "                                      #\"num_documento_cliente\", # NIF del cliente propietario del servicio\n",
    "                                      \"nacionalidad\", \"num_prepago\", \"num_pospago\",\n",
    "                                      \"age_in_years\",\n",
    "                                      #\"tipo_documento_cliente\", very uninformed\n",
    "                                      \"tipo_documento_comprador\", # Tipo de documento (NIF, Pasaporte, Tarj. Residencia…) asociado al comprador del servicio\n",
    "                                      \"x_fecha_nacimiento\", #\"fx_activacion\",\n",
    "                                      \"fx_1llamada\", # more reliable than fx_activacion\n",
    "                                      #\"fx_alta_postpago\"\n",
    "                                      \"year\", \"month\"\n",
    "                                     ]\n",
    "\n",
    "\n",
    "'''\n",
    "df_prepago = (spark.read.table(\"raw_es.customerprofilecar_prepservgsm\") # se calcula a cierre de mes, en concreto el dia 2 del mes sgte\n",
    "              .where((col(\"year\") == int(reference_month[:4]))\n",
    "                     & (col(\"month\") == int(reference_month[4:]))\n",
    "                    )\n",
    "              .where(col(\"estado_servicio\").isin(['CA', 'FCA', 'AC', 'FEX']))\n",
    "              #.where(substring(col('fx_timestamp_servicios_prepag0'),0,7) < reference_date_str[:4]+\"-\"+reference_date_str[4:6])       \n",
    "              .withColumn(\"hello\", substring(col('fx_timestamp_servicios_prepag0'),0,7))\n",
    "             ).select(col(\"msisdn_servicios_prepago\").alias(\"msisdn\"),\n",
    "                      col(\"ius_servicios_prepago\").alias(\"ius\"),\n",
    "                      col(\"imsi\").alias(\"srv_imsi\"),\n",
    "                      col(\"imei\").alias(\"srv_imei\"),\n",
    "                                          col(\"sim\").alias(\"srv_sim\"),\n",
    "                                          #col(\"srv_last_update\"),\n",
    "                                          col(\"codigo_plan_precios\").alias(\"srv_pricing_plan\"),\n",
    "                                          col(\"estado_servicio\").alias(\"srv_status\"),\n",
    "                                          col(\"tac_fac\").alias(\"srv_tac_fac\"),\n",
    "                                          col(\"fx_activacion\").alias(\"srv_activation_ts\"),\n",
    "                                          col(\"fx_1llamada\").alias(\"srv_firstcall_ts\"),\n",
    "                                          col(\"fx_ultimo_plan_precios\").alias(\"srv_last_pp_change_ts\"),\n",
    "                                          col(\"contador_plan_precios\").alias(\"srv_pp_counter\"),\n",
    "                     col(\"fx_timestamp_servicios_prepag0\"), col(\"hello\"))\n",
    "'''\n",
    "\n",
    "df_prepago = (spark.read.table(\"raw_es.vf_pre_ac_final\") # se calcula a cierre de mes, en concreto el dia 2 del mes sgte\n",
    "              .where((col(\"year\") == int(reference_month[:4]))\n",
    "                     & (col(\"month\") == int(reference_month[4:]))\n",
    "                    )\n",
    "              .where(col(\"X_FECHA_NACIMIENTO\") != \"X_FE\")\n",
    "              .withColumn(\"X_FECHA_NACIMIENTO\", when(length(col(\"X_FECHA_NACIMIENTO\"))>0,col(\"X_FECHA_NACIMIENTO\")))\n",
    "              .withColumn(\"NUM_DOCUMENTO_CLIENTE\", when(length(col(\"NUM_DOCUMENTO_CLIENTE\"))>0,col(\"NUM_DOCUMENTO_CLIENTE\")))\n",
    "              .withColumn(\"NUM_DOCUMENTO_COMPRADOR\", when(length(col(\"NUM_DOCUMENTO_COMPRADOR\"))>0,col(\"NUM_DOCUMENTO_COMPRADOR\")))\n",
    "              #.withColumn(\"age_in_years\", get_customer_age_udf(col(\"X_FECHA_NACIMIENTO\"), reference_month))\n",
    "              .withColumn(\"age_in_years\", lit(1))\n",
    "             # .withColumn(\"nacionalidad\", substitute_crappy_characters_udf(col(\"nacionalidad\")))\n",
    "             .select(*useful_columns_from_acFinalPrepago)\n",
    ".withColumnRenamed(\"year\", \"year_prepaid\")\n",
    ".withColumnRenamed(\"month\", \"month_prepaid\"))\n",
    "\n",
    "#################################\n",
    "# Reduce the number of rows if debug mode - this will reduce the size of the dataframes due to left joins\n",
    "if debug_mode: # and len(df_prepago.take(1)) > 0:\n",
    "    print(\"Taking a sample of {}\".format(num_samples))\n",
    "    df_prepago = spark.createDataFrame(df_prepago.take(num_samples))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Import PrepaidEuphoria class.\n",
    "from prepaid_euphoria import PrepaidEuphoria\n",
    "\n",
    "logger.info(\"THE END!!!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_balance_0 = (spark.read.table(\"raw_es.prepaid_transfbalance\")             \n",
    "#                               .where((col(\"year\") == int(reference_month[:4]))\n",
    "#                                    & (col(\"month\") == int(reference_month[4:])))\n",
    "#                     .select([\"clave_traspaso\", \"msisdn_receptor\", \"msisdn_emisor\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_peuph_date_master = (spark.read.table(\"tests_es.peuph_date_master\")\n",
    "                     .where((col(\"year\") == int(reference_month[:4]))\n",
    "                          & (col(\"month\") == int(reference_month[4:]))))\n",
    "                     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transferencias de Saldo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add_transfer_balance_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_balance_receptor = (spark.read.table(\"raw_es.prepaid_transfbalance\")\n",
    "                       .where((col(\"year\") == int(reference_month[:4]))\n",
    "                            & (col(\"month\") == int(reference_month[4:])))\n",
    "                                      .groupBy(\"msisdn_receptor\",\n",
    "                                               \"year\",\n",
    "                                               \"month\",\n",
    "                                               \"day\")\n",
    "                                      .agg(sql_sum(\"importe_traspasado\").alias(\"importe_traspasado_receptor\"),\n",
    "                                           count(\"importe_traspasado\").alias(\"num_rec\"))\n",
    "                                      .select(col(\"msisdn_receptor\"), \n",
    "                                              col(\"year\"), \n",
    "                                              col(\"month\"), \n",
    "                                              col(\"day\"), \n",
    "                                              col(\"importe_traspasado_receptor\"),\n",
    "                                             col(\"num_rec\"))\n",
    "                       .withColumnRenamed(\"year\", \"year_receptor\")\n",
    "                       .withColumnRenamed(\"month\", \"month_receptor\")\n",
    "                       .withColumnRenamed(\"day\", \"day_receptor\")\n",
    "                      )\n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_balance_emisor = (spark.read.table(\"raw_es.prepaid_transfbalance\")\n",
    "                     .where((col(\"year\") == int(reference_month[:4]))\n",
    "                          & (col(\"month\") == int(reference_month[4:])))\n",
    "                                      .groupBy(\"msisdn_emisor\",\n",
    "                                               \"year\",\n",
    "                                               \"month\",\n",
    "                                               \"day\")\n",
    "                                      .agg(sql_sum(\"importe_traspasado\").alias(\"importe_traspasado_emisor\"),\n",
    "                                           sql_sum(\"importe_cargo\").alias(\"importe_cargo_emisor\"),\n",
    "                                           count(\"importe_traspasado\").alias(\"num_em\"))\n",
    "                                      .select(col(\"msisdn_emisor\"), \n",
    "                                              col(\"year\"), \n",
    "                                              col(\"month\"), \n",
    "                                              col(\"day\"), \n",
    "                                              col(\"importe_traspasado_emisor\"),\n",
    "                                              col(\"importe_cargo_emisor\"),\n",
    "                                             col(\"num_em\"))\n",
    "                                            .withColumnRenamed(\"year\", \"year_emisor\")\n",
    "                                            .withColumnRenamed(\"month\", \"month_emisor\")\n",
    "                                            .withColumnRenamed(\"day\", \"day_emisor\"))\n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this dataframe has N prepago by M days \n",
    "df_prepago_cross_join = df_prepago.join(df_peuph_date_master,\n",
    "                                           how=\"left_outer\",\n",
    "                                           on=((df_prepago[\"month_prepaid\"]==df_peuph_date_master[\"month\"]) &\n",
    "                                               (df_prepago[\"year_prepaid\"]==df_peuph_date_master[\"year\"]))\n",
    "                                           )\n",
    "df_prepago_cross_join = df_prepago_cross_join.drop(*[\"month_prepaid\", \"year_prepaid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_prepago_cross_join_2 = df_prepago_cross_join.join(df_balance_receptor,\n",
    "                                           how=\"left\",\n",
    "                                           on=((df_prepago_cross_join[\"month\"]==df_balance_receptor[\"month_receptor\"]) &\n",
    "                                               (df_prepago_cross_join[\"year\"]==df_balance_receptor[\"year_receptor\"]) &\n",
    "                                               (df_prepago_cross_join[\"msisdn\"]==df_balance_receptor[\"msisdn_receptor\"]) &\n",
    "                                               (df_prepago_cross_join[\"day\"]==df_balance_receptor[\"day_receptor\"]))\n",
    "                                              )\n",
    "df_prepago_cross_join_2 = df_prepago_cross_join_2.drop(*[\"month_receptor\", \"year_receptor\", \"day_receptor\", \"msisdn_receptor\"])\n",
    "\n",
    "df_prepago_cross_join_3 = df_prepago_cross_join_2.join(df_balance_emisor,\n",
    "                                           how=\"left\",\n",
    "                                           on=((df_prepago_cross_join_2[\"month\"]==df_balance_emisor[\"month_emisor\"]) &\n",
    "                                               (df_prepago_cross_join_2[\"year\"]==df_balance_emisor[\"year_emisor\"]) &\n",
    "                                               (df_prepago_cross_join_2[\"msisdn\"]==df_balance_emisor[\"msisdn_emisor\"]) &\n",
    "                                               (df_prepago_cross_join_2[\"day\"]==df_balance_emisor[\"day_emisor\"]))\n",
    "                                              )\n",
    "df_prepago_cross_join_3 = df_prepago_cross_join_3.drop(*[\"month_emisor\", \"year_emisor\", \"day_emisor\", \"msisdn_emisor\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fecha_ejecucion',\n",
       " 'msisdn',\n",
       " 'nacionalidad',\n",
       " 'num_prepago',\n",
       " 'num_pospago',\n",
       " 'age_in_years',\n",
       " 'tipo_documento_comprador',\n",
       " 'x_fecha_nacimiento',\n",
       " 'fx_1llamada',\n",
       " 'beginning_of_day_ts',\n",
       " 'end_of_day_ts',\n",
       " 'day_int',\n",
       " 'day_str_1',\n",
       " 'day_str_2',\n",
       " 'year',\n",
       " 'month',\n",
       " 'day',\n",
       " 'importe_traspasado_receptor',\n",
       " 'num_rec',\n",
       " 'importe_traspasado_emisor',\n",
       " 'importe_cargo_emisor',\n",
       " 'num_em']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prepago_cross_join_3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# msisdn='695600350'\n",
    "\n",
    "\n",
    "# import src.pycharm_workspace.lib_csanc109.utils.pyspark_utils as pyspark_utils\n",
    "# from IPython.display import HTML, display\n",
    "# import tabulate\n",
    "# header = [\"msisdn\", \"importe_traspasado\", \"num_em\", \"num_rec\"]\n",
    "# data = pyspark_utils.df_to_list(df_prepago_cross_join_3.where(col(\"msisdn\")==msisdn).select(header))\n",
    "\n",
    "\n",
    "# display(HTML(tabulate.tabulate([header ] +data, tablefmt='html', headers='firstrow')))\n",
    "\n",
    "#df_prepago_cross_join_2.where(col(\"msisdn\")==msisdn).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Número de transferencias en las que el MSISDN ha sido receptor de saldo (tbal_rec_num).\n",
    "# Número de transferencias en las que el MSISDN ha sido el donante de saldo (tbal_tra_num).\n",
    "# Saldo recibido en transferencias (tbal_rec_amount). \n",
    "# Saldo donado en transferencias (tbal_tra_amount).\n",
    "\n",
    "df_balance_information = (df_prepago_cross_join_3\n",
    "    .withColumn(\"tbal_rec_amount\", 1.21*col(\"importe_traspasado_receptor\"))\n",
    "    .withColumnRenamed(\"num_rec\", \"tbal_rec_num\")\n",
    "    .withColumn(\"tbal_tra_amount\", 1.21*col(\"importe_traspasado_emisor\") + 1.21*col(\"importe_cargo_emisor\"))\n",
    "    .withColumnRenamed(\"num_em\", \"tbal_tra_num\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPUPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "udf_parse_importe = udf(lambda x:int(x[1:-1]),IntegerType())\n",
    "\n",
    "\n",
    "df_topups = (spark.read.table(\"raw_es.billingtopsups_rechargescash\")\n",
    "                       .where((col(\"year\") == int(reference_month[:4]))\n",
    "                            & (col(\"month\") == int(reference_month[4:])))\n",
    "                       .withColumn('importe_int',udf_parse_importe('importe'))\n",
    "                       .groupBy(\"ndc_msisdn\",\n",
    "                                \"year\",\n",
    "                                \"month\",\n",
    "                                \"day\")\n",
    "                        .agg(sql_sum(\"importe_int\").alias(\"tu_amount\"),\n",
    "                               count(\"importe_int\").alias(\"tu_num\"))\n",
    "                        .select(col(\"ndc_msisdn\"), \n",
    "                                col(\"year\"), \n",
    "                                col(\"month\"), \n",
    "                                col(\"day\"), \n",
    "                                #      col(\"tu_ts\"),\n",
    "                                col(\"tu_amount\"),\n",
    "                                col(\"tu_num\"))\n",
    "                       .withColumnRenamed(\"year\", \"year_topups\")\n",
    "                       .withColumnRenamed(\"month\", \"month_topups\")\n",
    "                       .withColumnRenamed(\"day\", \"day_topups\")\n",
    "                      )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_balance_information_2 = df_balance_information.join(df_topups,\n",
    "                                           how=\"left\",\n",
    "                                           on=((df_balance_information[\"month\"]==df_topups[\"month_topups\"]) &\n",
    "                                               (df_balance_information[\"year\"]==df_topups[\"year_topups\"]) &\n",
    "                                               (df_balance_information[\"msisdn\"]==df_topups[\"ndc_msisdn\"]) &\n",
    "                                               (df_balance_information[\"day\"]==df_topups[\"day_topups\"]))\n",
    "                                              )\n",
    "df_balance_information_2 = df_balance_information_2.drop(*[\"year_topups\", \"month_topups\", \"day_topups\", \"ndc_msisdn\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adelantos de saldo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add_advance_balance_information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance de saldo (ppio y final del dia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic (voice and sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(numeroorigen=u'653955924', year=2018, month=5, day=25, voice_amount=None, sms_amount=7, voice_total_duration=928.0, voice_avg_duration=928.0, voice_num_distinct_rec=4, sms_num_distinct_rec=0)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# voice_num - Number of calls made on a particular day,\n",
    "# voice_num_distinct_rec - Number of distinct receivers,\n",
    "# voice_total_duration - Total time spent making calls on a given day,\n",
    "# voice_avg_duration - Average time spent on calls on a given day,\n",
    "# voice_amount - Amount spend on calls on a particular day,\n",
    "# sms_num - Number of SMS made on a particular day,\n",
    "# sms_num_distinct_rec - Number of distinct SMS recipients on a given day.\n",
    "# sms_amount - Amount spent on SMS on a particular day.\n",
    "from pyspark.sql.functions import (udf,col,max as sql_max, when, countDistinct, isnull, concat, lpad, trim, lower, lit, sum as sql_avg, sum as sql_avg, length, upper)\n",
    "\n",
    "\n",
    "df_call_data = (spark.read.table(\"raw_es.prepaid_trafficvoicesms\")\n",
    "                       .where((col(\"year\") == int(reference_month[:4]))\n",
    "                            & (col(\"month\") == int(reference_month[4:])))\n",
    "                 .withColumn(\"numeroorigen\", trim(col(\"numeroorigen\")))\n",
    "                 .withColumn(\"numerodestino\", trim(col(\"numerodestino\")))\n",
    "                 .withColumn(\"vozsms\", lower(trim(col(\"vozsms\"))))      \n",
    "                 .withColumn(\"voice_amount\", when(col(\"vozsms\") == 'voz', col(\"importecobrado\")).otherwise(0))\n",
    "                 .withColumn(\"sms_amount\", when(col(\"vozsms\") == 'sms', col(\"importecobrado\")).otherwise(0))\n",
    "              .groupBy(\"numeroorigen\", \"year\", \"month\", \"day\")\n",
    "              .agg(sql_sum(\"voice_amount\").alias(\"voice_amount\"),\n",
    "                   count(\"sms_amount\").alias(\"sms_amount\"),\n",
    "                   sql_sum(when((col(\"vozsms\") == 'voz'), col(\"airduration\")).otherwise(None)).alias(\"voice_total_duration\"),\n",
    "                   sql_avg(when((col(\"vozsms\") == 'voz'), col(\"airduration\")).otherwise(None)).alias(\"voice_avg_duration\"),\n",
    "                   countDistinct(when((col(\"vozsms\") == 'voz'), col(\"numerodestino\")).otherwise(None)).alias(\"voice_num_distinct_rec\"),\n",
    "                   countDistinct(when((col(\"vozsms\") == 'sms'), col(\"numerodestino\")).otherwise(None)).alias(\"sms_num_distinct_rec\")))\n",
    "\n",
    "df_call_data.take(1)                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(msisdn=u'680007601', dateofcall=datetime.datetime(2018, 5, 25, 0, 0), voice_amount=1054.7601509094238)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_mb - total amount of MBs consumed by data sessions.\n",
    "# data_amount - total amount spent on data sessions.\n",
    "\n",
    "\n",
    "# volumen data\n",
    "df_data_consumed = (spark.read.table(\"raw_es.prepaid_trafficdata\")\n",
    "                       .where((col(\"year\") == int(reference_month[:4]))\n",
    "                            & (col(\"month\") == int(reference_month[4:])))\n",
    "                    .withColumn(\"data_mb\", col(\"volumen\")/(1024*1024))\n",
    "                    .groupBy(\"msisdn\", \"dateofcall\")\n",
    "                    .agg(sql_sum(\"data_mb\").alias(\"data_mb\"),\n",
    "                         sql_sum(\"CARGOREAL\").alias(\"data_amount\")))\n",
    "                    \n",
    "\n",
    "\n",
    "df_data_consumed.take(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        # Get voice data.\n",
    "        query = \"\"\"\n",
    "        WITH call_data AS (\n",
    "                           SELECT TRIM(numeroorigen) AS numeroorigen\n",
    "                                  ,TRIM(numerodestino) AS numerodestino\n",
    "                                  ,dia\n",
    "                                  ,TRIM(LOWER(vozsms)) AS vozsms\n",
    "                                  ,airduration\n",
    "                                  ,ROW_NUMBER() OVER (PARTITION BY TRIM(numeroorigen),\n",
    "                                                                   TRIM(numerodestino),\n",
    "                                                                   dia,\n",
    "                                                                   hora,\n",
    "                                                                   TRIM(LOWER(vozsms))\n",
    "                                                      ORDER BY 1) AS row_id\n",
    "                           FROM raw_es.prepaid_trafficvoicesms\n",
    "                           WHERE 10000*YEAR(dia) + 100*MONTH(dia) + DAY(dia) >= {min_partition_date}\n",
    "                                 AND 10000*YEAR(dia) + 100*MONTH(dia) + DAY(dia) <= {max_partition_date}\n",
    "                           )\n",
    "             ,aggregated_call_data AS (\n",
    "                                       SELECT numeroorigen\n",
    "                                              ,dia\n",
    "                                              ,SUM(CASE WHEN vozsms = 'voz' THEN 1 ELSE 0 END) AS voice_num\n",
    "                                              ,SUM(CASE WHEN vozsms = 'sms' THEN 1 ELSE 0 END) AS sms_num\n",
    "                                              ,COUNT(DISTINCT CASE WHEN vozsms = 'voz'\n",
    "                                                                   THEN numerodestino\n",
    "                                                                   ELSE NULL END) AS voice_num_distinct_rec\n",
    "                                              ,COUNT(DISTINCT CASE WHEN vozsms = 'sms'\n",
    "                                                                   THEN numerodestino\n",
    "                                                                   ELSE NULL END) AS sms_num_distinct_rec\n",
    "                                              ,SUM(CASE WHEN vozsms = 'voz'\n",
    "                                                        THEN airduration\n",
    "                                                        ELSE 0 END) AS voice_total_duration\n",
    "                                              ,AVG(CASE WHEN vozsms = 'voz'\n",
    "                                                        THEN airduration\n",
    "                                                        ELSE NULL END) AS voice_avg_duration\n",
    "                                       FROM call_data\n",
    "                                       WHERE row_id = 1\n",
    "                                       GROUP BY numeroorigen\n",
    "                                                ,dia\n",
    "                                       )\n",
    "        SELECT A.*\n",
    "               ,COALESCE(B.voice_num, 0) AS voice_num\n",
    "               ,COALESCE(B.sms_num, 0) AS sms_num\n",
    "               ,COALESCE(B.voice_num_distinct_rec, 0) AS voice_num_distinct_rec\n",
    "               ,COALESCE(B.sms_num_distinct_rec, 0) AS sms_num_distinct_rec\n",
    "               ,COALESCE(B.voice_total_duration, 0) AS voice_total_duration\n",
    "               ,COALESCE(B.voice_avg_duration, 0) AS voice_avg_duration\n",
    "        FROM {input_table_name} A\n",
    "        LEFT JOIN aggregated_call_data B\n",
    "        ON A.reference_ts = B.dia\n",
    "           AND A.msisdn = B.numeroorigen\n",
    "        \"\"\".format(input_table_name=input_table_name, min_partition_date=min_partition_date,\n",
    "                   max_partition_date=max_partition_date)\n",
    "        self.drop_create(query=query, output_table_name=output_table_name + '_0', advanced=True)\n",
    "\n",
    "        query = \"\"\"\n",
    "        WITH call_data AS (\n",
    "                           SELECT TRIM(numeroorigen) AS numeroorigen\n",
    "                                  ,TRIM(numerodestino) AS numerodestino\n",
    "                                  ,fechatarificacion\n",
    "                                  ,TRIM(LOWER(vozsms)) AS vozsms\n",
    "                                  ,importecobrado\n",
    "                                  ,ROW_NUMBER() OVER (PARTITION BY TRIM(numeroorigen),\n",
    "                                                                   TRIM(numerodestino),\n",
    "                                                                   fechatarificacion,\n",
    "                                                                   horatarificacion,\n",
    "                                                                   vozsms\n",
    "                                                      ORDER BY 1) AS row_id\n",
    "                           FROM raw_es.prepaid_trafficvoicesms\n",
    "                           WHERE 10000*YEAR(fechatarificacion)\n",
    "                                 + 100*MONTH(fechatarificacion)\n",
    "                                 + DAY(fechatarificacion) >= {min_partition_date}\n",
    "                                 AND 10000*YEAR(fechatarificacion)\n",
    "                                     + 100*MONTH(fechatarificacion)\n",
    "                                     + DAY(fechatarificacion) <= {max_partition_date}\n",
    "                           )\n",
    "             ,aggregated_call_data AS (\n",
    "                                       SELECT numeroorigen\n",
    "                                              ,fechatarificacion\n",
    "                                              ,SUM(CASE WHEN vozsms = 'voz'\n",
    "                                                        THEN importecobrado\n",
    "                                                        ELSE 0 END) AS voice_amount\n",
    "                                              ,SUM(CASE WHEN vozsms = 'sms'\n",
    "                                                        THEN importecobrado\n",
    "                                                        ELSE 0 END) AS sms_amount\n",
    "                                       FROM call_data\n",
    "                                       WHERE row_id = 1\n",
    "                                       GROUP BY numeroorigen, fechatarificacion\n",
    "                                       )\n",
    "        SELECT A.*\n",
    "               ,COALESCE(B.voice_amount, 0) AS voice_amount\n",
    "               ,COALESCE(B.sms_amount, 0) AS sms_amount\n",
    "        FROM {output_table_name}_0 A\n",
    "        LEFT JOIN aggregated_call_data B\n",
    "        ON A.reference_ts = B.fechatarificacion\n",
    "           AND A.msisdn = B.numeroorigen;\n",
    "        DROP TABLE IF EXISTS {output_table_name}_0;\n",
    "        \"\"\".format(output_table_name=output_table_name,\n",
    "                   min_partition_date=min_partition_date,\n",
    "                   max_partition_date=max_partition_date)\n",
    "        self.drop_create(query=query, output_table_name=output_table_name, advanced=True)\n",
    "        self.drop_input_table(input_table_name, condition=drop_input_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
