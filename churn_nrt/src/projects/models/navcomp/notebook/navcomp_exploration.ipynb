{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEVEL_SRC must contain the directory use-cases and pykhaos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20200121-081836 [INFO ] Logging to file /var/SP/data/home/csanc109/logging/out_20200121_081836.log\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, sys\n",
    "import datetime as dt\n",
    "DEVEL_SRC = os.path.join(os.environ.get('BDA_USER_HOME', ''), \"src\", \"devel\")\n",
    "if DEVEL_SRC not in sys.path:\n",
    "    sys.path.append(DEVEL_SRC)\n",
    "\n",
    "USECASES_SRC = os.path.join(DEVEL_SRC, \"use-cases\") # TODO when '-' is removed from name, remove also this line and adapt imports \n",
    "if USECASES_SRC not in sys.path: \n",
    "    sys.path.append(USECASES_SRC)\n",
    "    \n",
    "# AMDOCS_SRC = os.path.join(DEVEL_SRC, \"amdocs_informational_dataset\") # TODO when - is removed, remove also this line and adapt imports\n",
    "# if AMDOCS_SRC not in sys.path: \n",
    "#     sys.path.append(AMDOCS_SRC)\n",
    "    \n",
    "import pykhaos.utils.custom_logger as clogger\n",
    "logging_file = os.path.join(os.environ.get('BDA_USER_HOME', ''), \"logging\",\n",
    "                                    \"out_\" + dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + \".log\")\n",
    "logger = clogger.configure_logger(log_filename=logging_file, std_channel=sys.stderr, logger_name=\"\")\n",
    "logger.info(\"Logging to file {}\".format(logging_file))    \n",
    "        \n",
    "from project.project_generic import Project\n",
    "\n",
    "import pykhaos.utils.notebooks as nb\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "RUNNING_FROM_NOTEBOOK = nb.isnotebook()\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "if RUNNING_FROM_NOTEBOOK:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    %matplotlib inline  \n",
    "    EXTERNAL_LIB = os.path.join(os.environ.get('BDA_USER_HOME', ''), \"lib\", \"external_libs\")\n",
    "    if EXTERNAL_LIB not in sys.path:\n",
    "        sys.path.append(EXTERNAL_LIB)\n",
    "    # feel free from commenting this line and the other ones that begin with \"%%notify\" if you do not have \n",
    "    # the extension installed or copy de lib from /var/SP/data/home/csanc109/lib/external_libs/jupyternotify/\n",
    "    %load_ext jupyternotify \n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import Row, DataFrame, Column, Window\n",
    "from pyspark.sql.types import DoubleType, StringType, IntegerType, DateType, ArrayType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer, VectorAssembler, SQLTransformer, OneHotEncoder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.sql.functions import collect_set, concat, size, coalesce, col, lpad, struct, count as sql_count, lit, min as sql_min, max as sql_max, collect_list, udf, when, desc, asc, to_date, create_map, sum as sql_sum\n",
    "from pyspark.sql.types import StringType, ArrayType, MapType, StructType, StructField, IntegerType\n",
    "from pyspark.sql.functions import array, regexp_extract\n",
    "from itertools import chain\n",
    "from churn.datapreparation.general.data_loader import get_unlabeled_car, get_port_requests_table, get_numclients_under_analysis\n",
    "from churn.utils.constants import PORT_TABLE_NAME\n",
    "from churn.utils.udf_manager import Funct_to_UDF\n",
    "from pyspark.sql.functions import substring, datediff, row_number\n",
    "from pykhaos.utils.date_functions import move_date_n_days, move_date_n_cycles\n",
    "from pykhaos.utils.hdfs_functions import check_hdfs_exists\n",
    "from pykhaos.modeling.model_performance import get_lift\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended spark session: 23.4550309181 secs | default parallelism=4\n"
     ]
    }
   ],
   "source": [
    "from churn.utils.general_functions import init_spark\n",
    "spark = init_spark(\"navcomp+adobe\")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasa de evaporacion trigger nav comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_date_ = \"20190925\"\n",
    "filter_ = 'comps'\n",
    "save_ = True\n",
    "verbose = True\n",
    "\n",
    "\n",
    "from churn.analysis.triggers.navcomp.navcomp_utils import get_labeled_set_msisdn\n",
    "from churn.analysis.triggers.base_utils.base_utils import get_active_filter, get_disconnection_process_filter, get_churn_call_filter\n",
    "\n",
    "tr_set = get_labeled_set_msisdn(spark, tr_date_, sources='all', save_ = save_, verbose = verbose) \n",
    "\n",
    "# Modeling filters\n",
    "\n",
    "tr_active_filter = get_active_filter(spark, tr_date_, 90)\n",
    "\n",
    "tr_disconnection_filter = get_disconnection_process_filter(spark, tr_date_, 90)\n",
    "\n",
    "tr_churn_call_filter = get_churn_call_filter(spark, tr_date_, 90, 'msisdn')\n",
    "\n",
    "tr_set = tr_set \\\n",
    "    .join(tr_active_filter, ['msisdn'], 'inner') \\\n",
    "    .join(tr_disconnection_filter, ['nif_cliente'], 'inner') \\\n",
    "    .join(tr_churn_call_filter, ['msisdn'], 'inner')\n",
    "\n",
    "tr_set = filter_population(spark, tr_set, filter_)\n",
    "\n",
    "tr_set.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[col_ for col_ in tr_set.columns if \"port\" in col_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = tr_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tr_set_churn = tr_set_churn.cache()\n",
    "tr_set_churn.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = [\"PEPEPHONE\", \"ORANGE\", \"JAZZTEL\", \"MOVISTAR\", \"MASMOVIL\", \"YOIGO\", \"VODAFONE\", \"LOWI\", \"O2\", \"unknown\"]\n",
    "\n",
    "def get_most_consulted_operator(consulted_list, days_since_1st_navigation_list):\n",
    "    if not consulted_list: return \"None\"\n",
    "    combined_list = [(a,b,c) for a,b,c in zip(consulted_list, days_since_1st_navigation_list, competitors)]\n",
    "    # sort by consulted list and then by days since 1st navigation\n",
    "    sorted_list = sorted(combined_list, key = lambda x : (x[0], x[1]), reverse=True)\n",
    "    return sorted_list[0][2] if sorted_list else \"None\"\n",
    "\n",
    "\n",
    "get_most_consulted_operator_udf = udf(lambda x,y: get_most_consulted_operator(x,y), StringType())\n",
    "\n",
    "\n",
    "df_test = (df_test\n",
    "             .withColumn('consulted_list', array(*[col_ + \"_sum_count\" for col_ in competitors]))\n",
    "             .withColumn('days_since_1st_navigation_list', array(*[col_ + \"_max_days_since_navigation\" for col_ in competitors]))\n",
    "             .withColumn('most_consulted_operator', get_most_consulted_operator_udf(col('consulted_list'), col(\"days_since_1st_navigation_list\"))))\n",
    "\n",
    "#df_test.select(*([col_ + \"_sum_count\" for col_ in competitors] + [col_ + \"_max_days_since_navigation\" for col_ in competitors] +[\"most_consulted_operator\"])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from churn_nrt.src.data.sopos_dxs import MobPort\n",
    "\n",
    "df_target = MobPort(spark).get_module(tr_date_)\n",
    "\n",
    "\n",
    "tr_set_target = tr_set.join(df_target, on=[\"msisdn\"], how=\"left\")\n",
    "tr_set_churn = tr_set_target.where(col(\"label_mob\")==1)\n",
    "\n",
    "#tr_set_churn.select('portout_date_mob', \"max_days_since_navigation_comps\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days_until_churn: days since closing_day to churn_event (first churn event)\n",
    "from pyspark.sql.functions import from_unixtime,unix_timestamp\n",
    "# days_to_churn = fecha_de_sol_porta – fecha_de_la_última_navegación\n",
    "\n",
    "# days_until_churn: days since closing_day to churn_event (first churn event)\n",
    "tr_set_churn = (tr_set_churn.withColumn(\"days_until_sopo\", when(col(\"portout_date_mob\").isNotNull(), \n",
    "                                                                 datediff(col(\"portout_date_mob\"),\n",
    "                                                                          from_unixtime(unix_timestamp(lit(tr_date_), \"yyyyMMdd\")))).otherwise(-1)))\n",
    "\n",
    "tr_set_churn = tr_set_churn.withColumn(\"days_until_churn\", col(\"days_until_sopo\") + col(\"min_days_since_navigation_comps\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_ = \"days_until_churn\"\n",
    "n = 20\n",
    "\n",
    "bins, counts = tr_set_churn.select(col_).rdd.flatMap(lambda x: x).histogram(n)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(bins[:-1], bins=bins, weights=counts)\n",
    "plt.xlabel(\"** {} **\".format(col_))\n",
    "\n",
    "total = tr_set_churn.count()\n",
    "\n",
    "import numpy as np\n",
    "counts_cum = np.cumsum(counts)\n",
    "counts_cum = [100.0 * cc/total for cc in counts_cum]\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(bins[:-1], bins=bins, weights=counts_cum)\n",
    "plt.grid(True)\n",
    "plt.yticks(list(range(10,110,10))) \n",
    "plt.xlabel(\"cumsum {}\".format(col_))\n",
    "plt.ylabel(\"% churners [total churners = {}]\".format(total))\n",
    "\n",
    "pd.DataFrame({\"bins\" : bins[1:], \"counts\" : counts_cum})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.unpersist()\n",
    "\n",
    "from churn.analysis.triggers.base_utils.base_utils import get_customer_base\n",
    "date_ = \"20190930\"\n",
    "add_columns_customer = [\"birth_date\", \"fecha_naci\", 'CLASE_CLI_COD_CLASE_CLIENTE', 'X_CLIENTE_PRUEBA', \"TIPO_DOCUMENTO\"]\n",
    "add_columns=[\"TARIFF\", 'COD_ESTADO_GENERAL', \"srv_basic\"]\n",
    "closing_day = date_\n",
    "date_ = date_\n",
    "base_df = (get_customer_base(spark, date_, add_columns=add_columns, \n",
    "                             add_columns_customer=add_columns_customer,\n",
    "                            active_filter=False).filter(col('rgu')=='mobile'))#.select(*(['msisdn', 'nif_cliente', 'num_cliente'] + \n",
    "                                                                                                                                           #add_columns + add_columns_customer)))\n",
    "\n",
    "print(base_df.columns)\n",
    "\n",
    "base_df = (base_df.withColumn(\"birth_date\", when( (col(\"birth_date\").isNull() | (col(\"birth_date\") == 1753)), col(\"fecha_naci\")).otherwise(col(\"birth_date\")).cast(IntegerType()))\n",
    "                  .withColumn(\"age\", when(col(\"birth_date\") != 1753, lit(int(closing_day[:4])) - col(\"birth_date\")).otherwise(-1))\n",
    "          ).drop(\"birth_date\")\n",
    "\n",
    "base_df = base_df.cache()\n",
    "base_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.groupby(\"srv_basic\").agg(*[sql_count(\"*\").alias(\"count\")]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.groupby(\"CLASE_CLI_COD_CLASE_CLIENTE\").agg(*[sql_count(\"*\").alias(\"count\")]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.select(\"X_CLIENTE_PRUEBA\").dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.groupby(\"X_CLIENTE_PRUEBA\").agg(*[sql_count(\"*\").alias(\"count\")]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.groupby(\"COD_ESTADO_GENERAL\").agg(*[sql_count(\"*\").alias(\"count\")]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.groupby(\"TARIFF\").agg(*[sql_count(\"*\").alias(\"count\")]).show(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.select(\"NIF_CLIENTE\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.select(\"NUM_CLIENTE\").distinct().count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.select(\"msisdn\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.load(\"/user/csanc109/data/mobile_base_20190930_parquet\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df_insights.coalesce(1).write.mode('overwrite').save(\"/user/csanc109/data/mobile_base_20190930_parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df_insights = base_df.select(\"msisdn\", \"num_cliente\", \"nif_cliente\", \"srv_basic\", \"rgu\", 'CLASE_CLI_COD_CLASE_CLIENTE', 'COD_ESTADO_GENERAL', \"TARIFF\")\n",
    "base_df_insights.coalesce(1).write.mode('overwrite').format('csv').option('sep', '|').option('header', 'true').save(\"/user/csanc109/data/mobile_base_20190930\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df  = base_df.withColumn(\"age_disc\",  when(col(\"age\").isNull(), \"other\")\n",
    "                                         .when(col(\"age\")<20, \"<20\")\n",
    "                                         .when( (col(\"age\")>=20) & (col(\"age\")<25) , \"[20-25)\")\n",
    "                                         .when( (col(\"age\")>=25) & (col(\"age\")<30) , \"[25-30)\")\n",
    "                                         .when( (col(\"age\")>=30) & (col(\"age\")<35) , \"[30-35)\")\n",
    "                                         .when( (col(\"age\")>=35) & (col(\"age\")<40) , \"[35-40)\")\n",
    "                                         .when( (col(\"age\")>=40) & (col(\"age\")<45) , \"[40-45)\")\n",
    "                                         .when( (col(\"age\")>=45) & (col(\"age\")<50) , \"[45-50)\")\n",
    "                                         .when( (col(\"age\")>=50) & (col(\"age\")<55) , \"[50-55)\")\n",
    "                                         .when( (col(\"age\")>=55) & (col(\"age\")<60) , \"[55-60)\")\n",
    "                                         .when( (col(\"age\")>=60) & (col(\"age\")<65) , \"[60-65)\")\n",
    "                                         .when( col(\"age\")>=65, \">=65\")\n",
    "                                         .otherwise(\"other\"))\n",
    "\n",
    "base_df.groupby(\"age_disc\").agg(sql_count(\"*\").alias(\"count\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tgs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closing_day = \"20191031\"\n",
    "df_tgs = spark.read.load(\"/data/udf/vf_es/churn/extra_feats_mod/tgs/year={}/month={}/day={}\".format(int(closing_day[:4]), int(closing_day[4:6]), int(closing_day[6:])))\n",
    "df_tgs.select('tgs_days_since_f_inicio_bi',\n",
    " 'tgs_days_since_f_inicio_bi_exp',\n",
    " 'tgs_days_until_f_fin_bi',\n",
    " 'tgs_days_until_f_fin_bi_exp',\n",
    " 'tgs_days_until_fecha_fin_dto').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tgs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_tgs = df_tgs.withColumn(\"blindaje_categ\", when(  col(\"tgs_days_until_f_fin_bi\")>60, \"blindado\")\n",
    "                                      .when( (col(\"tgs_days_until_f_fin_bi\")>0) & (col(\"tgs_days_until_f_fin_bi\")<=60), \"blindado proximo\")\n",
    "                                      .when( ((col(\"tgs_blindaje_bi_expirado\")==1) & (col(\"tgs_days_since_f_inicio_bi_exp\")>60)), \"desblindado\")\n",
    "                                      .when( ((col(\"tgs_blindaje_bi_expirado\")==1) & (col(\"tgs_days_since_f_inicio_bi_exp\")>=0) & (col(\"tgs_days_since_f_inicio_bi_exp\")<=60)), \"desblindado reciente\")\n",
    "                    )\n",
    "\n",
    "df_tgs.groupby(\"blindaje_categ\").agg(sql_count(\"*\").alias(\"count\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from churn.analysis.triggers.navcomp.navcomp_utils import get_latest_scores\n",
    "\n",
    "df_scores = get_latest_scores(closing_day)\n",
    "\n",
    "mean_score = df_scores.select(sql_avg('scoring').alias('mean_score')).rdd.first()['mean_score']\n",
    "\n",
    "\n",
    "mean_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING NEW ATTRIBUTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_date_ = \"20191030\"\n",
    "filter_ = 'comps'\n",
    "save_ = True\n",
    "verbose = True\n",
    "\n",
    "\n",
    "from churn.analysis.triggers.navcomp.navcomp_utils import get_labeled_set_msisdn\n",
    "from churn.analysis.triggers.base_utils.base_utils import get_active_filter, get_disconnection_process_filter, get_churn_call_filter\n",
    "\n",
    "tr_set = get_labeled_set_msisdn(spark, tr_date_, sources='all', save_ = save_, verbose = verbose) \n",
    "tr_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _get_customer_master_feats(customer_tr_df):\n",
    "\n",
    "    class UDFclass:\n",
    "\n",
    "        @staticmethod\n",
    "        def compute_rgus_attrib(current_list, rgu_name):\n",
    "            import collections\n",
    "            rgus_dict = collections.Counter(current_list) if current_list is not None else {}\n",
    "            if rgu_name not in rgus_dict:\n",
    "                return 0\n",
    "            else:\n",
    "                return rgus_dict[rgu_name]\n",
    "\n",
    "    compute_rgus_attrib_udf = udf(lambda x, y: UDFclass.compute_rgus_attrib(x, y), IntegerType())\n",
    "\n",
    "    customer_tr_df = customer_tr_df.withColumn(\"nb_rgus_mobile\", compute_rgus_attrib_udf(\"rgus_list\", lit(\"mobile\")))\n",
    "    customer_tr_df = customer_tr_df.withColumn(\"nb_rgus_tv\", compute_rgus_attrib_udf(\"rgus_list\", lit(\"tv\")))\n",
    "    customer_tr_df = customer_tr_df.withColumn(\"nb_rgus_fixed\", compute_rgus_attrib_udf(\"rgus_list\", lit(\"fixed\")))\n",
    "    customer_tr_df = customer_tr_df.withColumn(\"nb_rgus_fbb\", compute_rgus_attrib_udf(\"rgus_list\", lit(\"fbb\")))\n",
    "    customer_tr_df = customer_tr_df.withColumn(\"nb_rgus_bam\", compute_rgus_attrib_udf(\"rgus_list\", lit(\"bam\")))\n",
    "\n",
    "    return customer_tr_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_ = \"20191022\"\n",
    "\n",
    "from churn.analysis.triggers.navcomp.metadata import get_metadata\n",
    "\n",
    "from churn.analysis.triggers.base_utils.base_utils import get_customer_base\n",
    "add_columns_customer = [\"birth_date\", \"fecha_naci\", 'CLASE_CLI_COD_CLASE_CLIENTE', 'X_CLIENTE_PRUEBA', \"TIPO_DOCUMENTO\"]\n",
    "#add_columns = [\"TARIFF\", 'COD_ESTADO_GENERAL', \"srv_basic\"]\n",
    "\n",
    "base_df = get_customer_base(spark, date_, add_columns_customer=add_columns_customer).filter(col('rgu')=='mobile').select('msisdn', 'nif_cliente', 'num_cliente', 'birth_date', 'fecha_naci')\n",
    "base_df = base_df.drop_duplicates(['msisdn', 'nif_cliente', 'num_cliente'])\n",
    "base_df = (base_df.withColumn(\"birth_date\", when((col(\"birth_date\").isNull() | (col(\"birth_date\") == 1753)), col(\"fecha_naci\")).otherwise(col(\"birth_date\")).cast(IntegerType()))\n",
    "                  .withColumn(\"age\", when(col(\"birth_date\") != 1753, lit(int(date_[:4])) - col(\"birth_date\")).otherwise(-1)))\n",
    "base_df = base_df.withColumn(\"age_disc\", when(col(\"age\").isNull(), \"other\").when(col(\"age\") < 20, \"<20\")\n",
    "                                        .when((col(\"age\") >= 20) & (col(\"age\") < 25), \"[20-25)\")\n",
    "                                        .when((col(\"age\") >= 25) & (col(\"age\") < 30), \"[25-30)\")\n",
    "                                        .when((col(\"age\") >= 30) & (col(\"age\") < 35), \"[30-35)\")\n",
    "                                        .when((col(\"age\") >= 35) & (col(\"age\") < 40), \"[35-40)\")\n",
    "                                        .when((col(\"age\") >= 40) & (col(\"age\") < 45), \"[40-45)\")\n",
    "                                        .when((col(\"age\") >= 45) & (col(\"age\") < 50), \"[45-50)\")\n",
    "                                        .when((col(\"age\") >= 50) & (col(\"age\") < 55), \"[50-55)\")\n",
    "                                        .when((col(\"age\") >= 55) & (col(\"age\") < 60), \"[55-60)\")\n",
    "                                        .when((col(\"age\") >= 60) & (col(\"age\") < 65), \"[60-65)\")\n",
    "                                        .when(col(\"age\") >= 65, \">=65\").otherwise(\"other\")).drop(\"birth_date\")\n",
    "# base_df.columns ['msisdn', 'nif_cliente', 'num_cliente', 'fecha_naci', 'age', 'age_disc']\n",
    "\n",
    "from churn.analysis.triggers.orders.customer_master import get_customer_master\n",
    "\n",
    "customer_metadata = get_metadata(spark, sources=['customer'])\n",
    "\n",
    "customer_feats = customer_metadata.select('feature').rdd.map(lambda x: x['feature']).collect() + ['nif_cliente']\n",
    "\n",
    "\n",
    "\n",
    "customer_tr_df = (get_customer_master(spark, date_, unlabeled=True)\n",
    "                        .filter((col('segment_nif') != 'Pure_prepaid') & (col(\"segment_nif\").isNotNull())).drop_duplicates([\"nif_cliente\"])\n",
    "                )\n",
    "\n",
    "customer_tr_df = (_get_customer_master_feats(customer_tr_df).select('nif_cliente', \n",
    " 'segment_nif',\n",
    " 'nb_rgus',\n",
    " 'rgus_list',\n",
    " 'tgs_days_until_fecha_fin_dto',\n",
    " 'nb_rgus_mobile',\n",
    " 'nb_rgus_tv',\n",
    " 'nb_rgus_fixed',\n",
    " 'nb_rgus_fbb',\n",
    " 'nb_rgus_bam'))\n",
    "\n",
    "customer_map_tmp = customer_metadata.select(\"feature\", \"imp_value\", \"type\").rdd.map(lambda x: (x[\"feature\"], x[\"imp_value\"], x[\"type\"])).collect()\n",
    "\n",
    "customer_map = dict([(x[0], str(x[1])) if x[2] == \"categorical\" else (x[0], float(x[1])) for x in customer_map_tmp])\n",
    "\n",
    "base_df = base_df.join(customer_tr_df, ['nif_cliente'], 'inner').na.fill(customer_map)\n",
    "\n",
    "base_df = base_df.select(customer_feats).na.fill(customer_map)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.load(\"/data/udf/vf_es/churn/triggers/navcomp_msisdn_data/year=2019/month=11/day=7\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod_navcomp = spark.read.load(\"/data/attributes/vf_es/model_outputs/model_scores/model_name=triggers_navcomp/year=2019\")\n",
    "df_mod_navcomp.select(\"year\", \"month\", \"day\", \"predict_closing_date\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_tr_df.select(\"msisdn\", 'nb_rgus', 'rgus_list', 'tgs_days_until_fecha_fin_dto', 'nb_rgus_mobile', 'nb_rgus_tv', 'nb_rgus_fixed', 'nb_rgus_fbb', 'nb_rgus_bam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_date = \"20190601\"\n",
    "from pykhaos.utils.date_functions import move_date_n_days\n",
    "end_port = move_date_n_days(tt_date, 15)\n",
    "from churn.analysis.triggers.base_utils.base_utils import get_mobile_portout_requests\n",
    "target = get_mobile_portout_requests(spark, tt_date, end_port).withColumnRenamed('label_mob', 'label').select('msisdn', 'label', \"portout_date_mob\")\n",
    "target.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VANISHING RATE DEL TOP-k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.load(\"/data/udf/vf_es/churn/triggers/nav_comp_tests/year=2019/month=11/day=7\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[col_ for col_ in spark.read.load(\"/data/udf/vf_es/churn/triggers/navcomp_msisdn_data/year=2019/month=10/day=24\").columns if \"age\" in col_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "navcomp_date = \"20190921\"\n",
    "target_date = navcomp_date\n",
    "\n",
    "tt_date = -1 # \"20190601\"\n",
    "\n",
    "navcomp_tr_df = spark.read.load(\"/data/udf/vf_es/churn/triggers/nav_comp_tests/year={}/month={}/day={}\".format(int(navcomp_date[:4]), int(navcomp_date[4:6]), int(navcomp_date[6:]))).drop(\"label\")\n",
    "\n",
    "# Labeling\n",
    "\n",
    "from churn.analysis.triggers.base_utils.base_utils import get_mobile_portout_requests\n",
    "\n",
    "from pykhaos.utils.date_functions import move_date_n_days\n",
    "\n",
    "end_port = move_date_n_days(target_date, 15)\n",
    "\n",
    "target = get_mobile_portout_requests(spark, navcomp_date, end_port).withColumnRenamed('label_mob', 'label').select('msisdn', 'label', \"portout_date_mob\")\n",
    "\n",
    "# Modeling filters\n",
    "\n",
    "tt_active_filter = get_active_filter(spark, navcomp_date, 90)\n",
    "\n",
    "tt_disconnection_filter = get_disconnection_process_filter(spark, navcomp_date, 90)\n",
    "\n",
    "tt_churn_call_filter = get_churn_call_filter(spark, navcomp_date, 90, 'msisdn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_set.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from churn.analysis.triggers.navcomp.navcomp_model import filter_population\n",
    "\n",
    "tt_set = navcomp_tr_df \\\n",
    "    .join(tt_active_filter, ['msisdn'], 'inner') \\\n",
    "    .join(tt_disconnection_filter, ['nif_cliente'], 'inner') \\\n",
    "    .join(tt_churn_call_filter, ['msisdn'], 'inner')\n",
    "\n",
    "tt_set = filter_population(spark, tt_set, filter_)\n",
    "\n",
    "tr_set_target = tt_set.join(target, ['msisdn'], 'left').na.fill({'label': 0.0})\n",
    "\n",
    "print \"[Info navcomp_model_production] After all the filters - Sie of the test set: \" + str(tt_set.count()) + \" - Number of distinct MSISDNs in the test set: \" + str(tt_set.select('msisdn').distinct().count())\n",
    "\n",
    "tr_set_churn = tr_set_target.where(col(\"label\")==1)\n",
    "\n",
    "from pyspark.sql.functions import from_unixtime,unix_timestamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from churn.analysis.triggers.base_utils.base_utils import get_mobile_portout_requests\n",
    "\n",
    "\n",
    "df_predictions = spark.read.load(\"/data/udf/vf_es/churn/triggers/nav_comp_tests_nav_comp_tests_alllabels/year=2019/month=9/day=21/\")\n",
    "\n",
    "target_date = \"20190921\"\n",
    "navcomp_date = target_date\n",
    "\n",
    "from pykhaos.utils.date_functions import move_date_n_days\n",
    "\n",
    "end_port = move_date_n_days(target_date, 15)\n",
    "\n",
    "target = get_mobile_portout_requests(spark, target_date, end_port).withColumnRenamed('label_mob', 'label').select('msisdn', 'label', \"portout_date_mob\")\n",
    "\n",
    "tr_set_target = df_predictions.drop(\"label\").join(target, ['msisdn'], 'left').na.fill({'label': 0.0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "num_nile = int(math.floor(float(tr_set_churn.count()) / 100.0))\n",
    "\n",
    "lift = get_lift(tr_set_churn, 'scoring', 'label', num_nile, 1.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[col_ for col_ in tr_set_target.columns if \"scor\" in col_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import from_unixtime,unix_timestamp\n",
    "\n",
    "col_ = \"days_until_churn\"\n",
    "n = 20\n",
    "\n",
    "myschema = tr_set_target.schema\n",
    "\n",
    "total = tr_set_target.count()\n",
    "print(\"total\", total)\n",
    "\n",
    "for top_ in [2000,3000,5000, 10000, 20000]:\n",
    "    \n",
    "    print(\"************** Analyzing top_{}\".format(top_))\n",
    "    \n",
    "    tr_set_target = tr_set_target.sort(desc(\"model_score\"))\n",
    "    \n",
    "    df_top = spark.createDataFrame(tr_set_target.head(top_), schema=myschema)\n",
    "    \n",
    "    tr_set_churn = df_top.where(col(\"label\")==1)\n",
    "    num_churners = tr_set_churn.count()\n",
    "    \n",
    "    tr_set_churn = (tr_set_churn.withColumn(\"days_until_sopo\", when(col(\"portout_date_mob\").isNotNull(), \n",
    "                                                                 datediff(col(\"portout_date_mob\"), from_unixtime(unix_timestamp(lit(navcomp_date), \"yyyyMMdd\")))).otherwise(-1)))\n",
    "\n",
    "    tr_set_churn = tr_set_churn.withColumn(\"days_until_churn\", col(\"days_until_sopo\") + col(\"min_days_since_navigation_comps\"))\n",
    "\n",
    "    print(\"1) num scores nulos\", tr_set_churn.where(col(\"model_score\").isNull()).count())\n",
    "\n",
    "    tr_set_churn = tr_set_churn.where(col(\"model_score\").isNotNull())\n",
    "                                                \n",
    "    tr_set_churn = tr_set_churn.cache()\n",
    "\n",
    "    print(\"2) churn_rate top{} = {}\".format(top_, 100.0*num_churners/top_))\n",
    "    \n",
    "    \n",
    "    bins, counts = tr_set_churn.select(col_).rdd.flatMap(lambda x: x).histogram(n)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(bins[:-1], bins=bins, weights=counts)\n",
    "    plt.xlabel(\"** {} ** (top = {}) (num_churners={}) (churn_rate={})\".format(col_, top_, num_churners, 100.0*num_churners/top_))\n",
    "\n",
    "    import numpy as np\n",
    "    counts_cum = np.cumsum(counts)\n",
    "    counts_cum = [100.0 * cc/num_churners for cc in counts_cum]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.hist(bins[:-1], bins=bins, weights=counts_cum)\n",
    "    plt.grid(True)\n",
    "    plt.yticks(list(range(10,110,10))) \n",
    "    plt.xlabel(\"cumsum {} (top = {}) (num_churners={}) (churn_rate={})\".format(col_, top_, num_churners, 100.0*num_churners/top_))\n",
    "\n",
    "    print(top_, pd.DataFrame({\"bins\" : bins[1:], \"counts\" : counts_cum}))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from churn.datapreparation.general.tgs_data_loader import get_tgs\n",
    "from churn_nrt.src.utils.date_functions import get_previous_cycle\n",
    "\n",
    "closing_day_tgs = get_previous_cycle(closing_day)\n",
    "print(\"Getting tgs for date {}\".format(closing_day_tgs))\n",
    "\n",
    "df_tgs = get_tgs(spark, closing_day_tgs, closing_day_tgs[:6], impute_nulls=False).select(\"nif_cliente\", 'tgs_days_until_fecha_fin_dto', 'tgs_days_until_f_fin_bi', 'msisdn')\n",
    "#df_tgs.columns -- ['nif_cliente', 'tgs_days_until_fecha_fin_dto', 'tgs_days_until_f_fin_bi']\n",
    "\n",
    "\n",
    "df_tgs = df_tgs.withColumn(\"blindaje_disc\", when(col(\"tgs_days_until_f_fin_bi\").isNull(), \"none\")\n",
    "                             .when(col(\"tgs_days_until_f_fin_bi\") > 60, \"hard\")\n",
    "                             .when((col(\"tgs_days_until_f_fin_bi\") >   0) & (col(\"tgs_days_until_f_fin_bi\") <= 60), \"soft\")\n",
    "                             .when((col(\"tgs_days_until_f_fin_bi\") <=  0) & (col(\"tgs_days_until_f_fin_bi\") >= -60), \"soft-nobounded\")\n",
    "                             .otherwise(\"none\"))\n",
    "\n",
    "#df_tgs.groupby('tgs_days_until_f_fin_bi', \"blindaje_disc\").agg(sql_count(\"*\").alias(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closing_day = \"20191016\"\n",
    "date_ = closing_day\n",
    "#from churn.analysis.triggers.orders.customer_master import get_tgs\n",
    "from churn.datapreparation.general.tgs_data_loader import get_tgs\n",
    "from churn_nrt.src.utils.date_functions import get_previous_cycle\n",
    "\n",
    "closing_day_tgs = get_previous_cycle(closing_day)\n",
    "print(\"Getting tgs for date {}\".format(closing_day_tgs))\n",
    "\n",
    "df_tgs = get_tgs(spark, closing_day_tgs, closing_day_tgs[:6], impute_nulls=False).select(\"nif_cliente\", 'tgs_days_until_fecha_fin_dto', 'tgs_days_until_f_fin_bi', 'msisdn')\n",
    "#df_tgs.columns -- ['nif_cliente', 'tgs_days_until_fecha_fin_dto', 'tgs_days_until_f_fin_bi']\n",
    "\n",
    "\n",
    "df_tgs = df_tgs.withColumn(\"blindaje_disc\", when(col(\"tgs_days_until_f_fin_bi\").isNull(), \"none\")\n",
    "                             .when(col(\"tgs_days_until_f_fin_bi\") > 60, \"hard\")\n",
    "                             .when((col(\"tgs_days_until_f_fin_bi\") >   0) & (col(\"tgs_days_until_f_fin_bi\") <= 60), \"soft\")\n",
    "                             .when((col(\"tgs_days_until_f_fin_bi\") <=  0) & (col(\"tgs_days_until_f_fin_bi\") >= -60), \"soft-nobounded\")\n",
    "                             .otherwise(\"none\"))\n",
    "\n",
    "# Desblindado [fcarren: Cliente desblindado donde ese desblindaje se produjo hace más de 2 meses, o que nunca tuvo blindaje]\n",
    "# Desblindado reciente [fcarren: Cliente desblindado, pero su desblindaje se ha producido en los recientes 1 o 2 meses]\n",
    "# Blindado próximo [fcarren: Cliente blindado, pero su le quedan sólo  1 o 2 meses para que se desblinde]\n",
    "# Blindado [fcarren: Cliente blindado, con blindaje activo de más de 2 meses]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tgs.groupby(\"blindaje_disc\", \"tgs_days_until_f_fin_bi\").agg(sql_count(\"*\").alias(\"count\")).sort(asc(\"tgs_days_until_f_fin_bi\")).show(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tgs_raw.groupby(\"blindaje_disc\").agg(sql_count(\"*\").alias(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from churn.analysis.triggers.navcomp.navcomp_utils import get_navcomp_car_msisdn\n",
    "\n",
    "df_navcomp = get_navcomp_car_msisdn(spark, date_, sources=[\"navcomp\",\"customer\",\"ccc\",\"spinners\",\"scores\"], save_ = False, verbose = False)\n",
    "nb_rgus_col = [col_ for col_ in df_navcomp.columns if col_.startswith(\"nb_rgus_\")]\n",
    "\n",
    "filter_ = ['comps']\n",
    "\n",
    "from churn.analysis.triggers.base_utils.base_utils import get_active_filter, get_disconnection_process_filter, get_churn_call_filter\n",
    "\n",
    "\n",
    "tt_active_filter = get_active_filter(spark, date_, 90)\n",
    "\n",
    "tt_disconnection_filter = get_disconnection_process_filter(spark, date_, 90)\n",
    "\n",
    "tt_churn_call_filter = get_churn_call_filter(spark, date_, 90, 'msisdn')\n",
    "\n",
    "from churn.analysis.triggers.navcomp.navcomp_model import filter_population\n",
    "\n",
    "tt_set = df_navcomp \\\n",
    "    .join(tt_active_filter, ['msisdn'], 'inner') \\\n",
    "    .join(tt_disconnection_filter, ['nif_cliente'], 'inner') \\\n",
    "    .join(tt_churn_call_filter, ['msisdn'], 'inner')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from churn.analysis.triggers.navcomp.navcomp_utils import get_volumen_attributes\n",
    "#df_get_volumen = get_volumen_attributes(spark, date_, nDays=-14)#.select(volumen_feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_ = 'comps'\n",
    "\n",
    "tt_set = filter_population(spark, tt_set, filter_)\n",
    "\n",
    "#tr_set_target = tt_set.join(target, ['msisdn'], 'left').na.fill({'label': 0.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from churn.analysis.triggers.base_utils.base_utils import get_mobile_portout_requests\n",
    "\n",
    "from pykhaos.utils.date_functions import move_date_n_days\n",
    "end_port = move_date_n_days(date_, 15)\n",
    "target = get_mobile_portout_requests(spark, date_, end_port).withColumnRenamed('label_mob', 'label').select('msisdn', 'label').withColumnRenamed(\"label\", \"label_1_15\")\n",
    "\n",
    "from pykhaos.utils.date_functions import move_date_n_days\n",
    "end_port_2 = move_date_n_days(end_port, 15)\n",
    "target_2 = get_mobile_portout_requests(spark, end_port, end_port_2).withColumnRenamed('label_mob', 'label').select('msisdn', 'label').withColumnRenamed(\"label\", \"label_16_30\")\n",
    "\n",
    "\n",
    "from pykhaos.utils.date_functions import move_date_n_days\n",
    "end_port_3 = move_date_n_days(date_, 30)\n",
    "target_3 = get_mobile_portout_requests(spark, date_, end_port_3).withColumnRenamed('label_mob', 'label').select('msisdn', 'label').withColumnRenamed(\"label\", \"label_1_30\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_,end_port,end_port_2, end_port_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from churn.analysis.triggers.orders.customer_master import get_customer_master\n",
    "customer_tr_df = (get_customer_master(spark, date_, unlabeled=True).filter((col('segment_nif') != 'Pure_prepaid') & (col(\"segment_nif\").isNotNull())).drop_duplicates([\"nif_cliente\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from churn.analysis.triggers.navcomp.navcomp_utils import get_latest_scores\n",
    "df_scores = get_latest_scores(spark, date_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_navcomp_select = tt_set.select(\"most_consulted_operator\", \"JAZZTEL_max_count\", \"VODAFONE_sum_count\", \"PEPEPHONE_min_days_since_navigation\", \"VODAFONE_min_days_since_navigation\", \n",
    "                                      \"norm_min_days_since_navigation_comps\", \"MOVISTAR_distinct_days_with_navigation\", \"unknown_distinct_days_with_navigation\", \"MOVISTAR_sum_count\", \n",
    "                                      \"norm_max_days_since_navigation_comps\",\"msisdn\", \"age\", \"age_disc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_navcomp_select = df_navcomp_select.cache()\n",
    "df_analysis.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = df_tgs.select(*['nif_cliente', 'tgs_days_until_fecha_fin_dto', 'tgs_days_until_f_fin_bi', 'blindaje_disc', 'msisdn']).join(df_navcomp_select, on=[\"msisdn\"], how=\"inner\")\n",
    "df_analysis = df_analysis.join(df_scores, on=[\"msisdn\"], how=\"left\")\n",
    "df_analysis = df_analysis.join(customer_tr_df.select(\"nif_cliente\", \"segment_nif\"), ['nif_cliente'], 'inner')\n",
    "\n",
    "df_analysis = df_analysis.join(target, ['msisdn'], 'left').na.fill({'label_1_15': 0.0})\n",
    "df_analysis = df_analysis.join(target_2, ['msisdn'], 'left').na.fill({'label_16_30': 0.0})\n",
    "df_analysis = df_analysis.join(target_3, ['msisdn'], 'left').na.fill({'label_1_30': 0.0})\n",
    "#df_analysis.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis.groupby(\"blindaje_disc\").agg(sql_count(\"*\").alias(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = df_analysis.withColumn(\"age_disc_simple\", when(col(\"age\").isNull(), \"other\")\n",
    "                             .when((col(\"age\") >   0) & (col(\"age\") < 20), \"<20\")\n",
    "                             .when((col(\"age\") >= 20) & (col(\"age\") < 35), \"[20-35)\")\n",
    "                             .when((col(\"age\") >= 35) & (col(\"age\") < 55), \"[35-55)\")\n",
    "                             .when((col(\"age\") >= 55) & (col(\"age\") < 70), \"[55-70)\")\n",
    "                             .when(col(\"age\") >= 70, \">=70\").otherwise(\"other\"))\n",
    "\n",
    "operadores = ['PEPEPHONE', 'JAZZTEL', 'MOVISTAR', 'MASMOVIL', 'YOIGO', 'VODAFONE', 'LOWI', 'O2', 'ORANGE']\n",
    "\n",
    "\n",
    "for op in operadores:\n",
    "    df_analysis = df_analysis.withColumn(\"flag_{}\".format(op), when(col(\"most_consulted_operator\")==op, 1).otherwise(0))\n",
    "\n",
    "    \n",
    "df_analysis = df_analysis.withColumn(\"most_consulted_operator_simple\", when(col(\"most_consulted_operator\").isin([\"MOVISTAR\", \"VODAFONE\", \"YOIGO\"]), col(\"most_consulted_operator\")).otherwise(\"OTHERS\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg as sql_avg\n",
    "myschema = df_analysis.schema\n",
    "df_analysis = df_analysis.sort(desc(\"scoring\"))\n",
    "df_top20k = spark.createDataFrame(df_analysis.head(20000), schema=myschema)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top20k.groupby(\"segment_nif\").agg(sql_count(\"*\").alias(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top20k.groupby(['blindaje_disc']).agg(*([sql_count(\"*\").alias(\"count\"), sql_sum(\"label_1_15\").alias(\"num_churners_1_15\"),                  \n",
    "                                                                                                             sql_avg(\"scoring\").alias(\"avg_scoring\")])).show(100,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top20k.groupby(\"blindaje_disc\").agg(sql_count(\"*\").alias(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top20k.groupby(['age_disc', 'blindaje_disc', \"most_consulted_operator\", \"segment_nif\"]).agg(*([sql_count(\"*\").alias(\"count\"), sql_sum(\"label_1_15\").alias(\"num_churners_1_15\"),                  \n",
    "                                                                                                             sql_avg(\"scoring\").alias(\"avg_scoring\")])).show(2500,truncate=False) \n",
    "                                                                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_agg_top20k = df_top20k.groupby(['blindaje_disc', \"most_consulted_operator\", \"segment_nif\"]).agg(*([sql_count(\"*\").alias(\"count\"), \n",
    "                                                                                                             sql_sum(\"label_1_15\").alias(\"num_churners_1_15\"), \n",
    "                                                                                                             sql_sum(\"label_16_30\").alias(\"num_churners_16_30\"), \n",
    "                                                                                                             sql_sum(\"label_1_30\").alias(\"num_churners_1_30\"), \n",
    "                                                                                                             sql_avg(\"scoring\").alias(\"avg_scoring\")] + \n",
    "                                                                                                            [sql_sum(\"flag_{}\".format(op)).alias(\"num_op_{}\".format(op)) for op in operadores]))\n",
    "df_agg_top20k.sort(desc(\"count\")).show(5000, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top20k.groupby(['age_disc_simple', \"blindaje_disc\"]).agg(*[sql_max(\"JAZZTEL_max_count\").alias(\"MAX_JAZZTEL_max_count\"),\n",
    "                                                              sql_min(\"JAZZTEL_max_count\").alias(\"MIN_JAZZTEL_max_count\"), \n",
    "                                                              sql_avg(\"JAZZTEL_max_count\").alias(\"AVG_JAZZTEL_max_count\"), \n",
    "                                                              \n",
    "                                                              sql_sum(\"VODAFONE_sum_count\").alias(\"SUM_VODAFONE_sum_count\"),\n",
    "                                                              sql_avg(\"VODAFONE_sum_count\").alias(\"AVG_VODAFONE_sum_count\"),\n",
    "                                                              sql_min(\"VODAFONE_sum_count\").alias(\"MIN_VODAFONE_sum_count\"),\n",
    "                                                              sql_max(\"VODAFONE_sum_count\").alias(\"MAX_VODAFONE_sum_count\"),\n",
    "                                                              \n",
    "                                                              sql_min(\"PEPEPHONE_min_days_since_navigation\").alias(\"MIN_PEPEPHONE_min_days_since_navigation\"),\n",
    "                                                              sql_max(\"PEPEPHONE_min_days_since_navigation\").alias(\"MAX_PEPEPHONE_min_days_since_navigation\"),\n",
    "                                                              sql_avg(\"PEPEPHONE_min_days_since_navigation\").alias(\"AVG_PEPEPHONE_min_days_since_navigation\"),\n",
    "\n",
    "                                                              sql_min(\"VODAFONE_min_days_since_navigation\").alias(\"MIN_VODAFONE_min_days_since_navigation\"),\n",
    "                                                              sql_max(\"VODAFONE_min_days_since_navigation\").alias(\"MAX_VODAFONE_min_days_since_navigation\"),\n",
    "                                                              sql_avg(\"VODAFONE_min_days_since_navigation\").alias(\"AVG_VODAFONE_min_days_since_navigation\"),\n",
    "\n",
    "                                                              sql_min(\"norm_min_days_since_navigation_comps\").alias(\"MIN_norm_min_days_since_navigation_comps\"),\n",
    "                                                              sql_max(\"norm_min_days_since_navigation_comps\").alias(\"MAX_norm_min_days_since_navigation_comps\"),\n",
    "                                                              sql_count(\"norm_min_days_since_navigation_comps\").alias(\"COUNT_norm_min_days_since_navigation_comps\"),\n",
    "\n",
    "                                                              sql_avg(\"MOVISTAR_distinct_days_with_navigation\").alias(\"AVG_MOVISTAR_distinct_days_with_navigation\"),\n",
    "                                                              sql_min(\"MOVISTAR_distinct_days_with_navigation\").alias(\"MIN_MOVISTAR_distinct_days_with_navigation\"),\n",
    "                                                              sql_max(\"MOVISTAR_distinct_days_with_navigation\").alias(\"MAX_MOVISTAR_distinct_days_with_navigation\"),\n",
    "\n",
    "                                                              sql_avg(\"unknown_distinct_days_with_navigation\").alias(\"AVG_unknown_distinct_days_with_navigation\"),\n",
    "                                                              sql_min(\"unknown_distinct_days_with_navigation\").alias(\"MIN_unknown_distinct_days_with_navigation\"),\n",
    "                                                              sql_max(\"unknown_distinct_days_with_navigation\").alias(\"MAX_unknown_distinct_days_with_navigation\"),\n",
    "                                                              \n",
    "                                                              sql_avg(\"MOVISTAR_sum_count\").alias(\"AVG_MOVISTAR_sum_count\"),\n",
    "                                                              sql_min(\"MOVISTAR_sum_count\").alias(\"MIN_MOVISTAR_sum_count\"),\n",
    "                                                              sql_max(\"MOVISTAR_sum_count\").alias(\"MAX_MOVISTAR_sum_count\"),\n",
    "\n",
    "                                                              sql_max(\"norm_max_days_since_navigation_comps\").alias(\"MAX_norm_max_days_since_navigation_comps\"),\n",
    "                                                              sql_min(\"norm_max_days_since_navigation_comps\").alias(\"MIN_norm_max_days_since_navigation_comps\"),\n",
    "                                                              sql_avg(\"norm_max_days_since_navigation_comps\").alias(\"AVG_norm_max_days_since_navigation_comps\"),\n",
    "\n",
    "                                                              sql_count(\"*\").alias(\"count\"), \n",
    "                                                                                                                          \n",
    "                                                             ]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_2 = df_top20k.groupby(['blindaje_disc', \"most_consulted_operator\"]).agg(*[sql_count(\"*\").alias(\"count\"), sql_avg(\"scoring\").alias(\"avg_scoring\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_2.sort(desc(\"count\")).show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_3 = df_analysis.groupby([\"most_consulted_operator\", 'age_disc_simple']).agg(*[sql_count(\"*\").alias(\"count\"), sql_avg(\"scoring\").alias(\"avg_scoring\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_3.sort(desc(\"count\")).show(150, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_scores = spark.read.load(\"/user/csanc109/data/mobile_base_20190930_parquet\")\n",
    "df_model_scores.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_scores2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_scores2 = spark.read.option(\"delimiter\", \"|\").option(\"header\",True).csv(\"/user/csanc109/data/mobile_base_20190930_insigths_campos/mobile_base_20190930_insights_campos.csv\")\n",
    "print(len(df_model_scores2.columns), df_model_scores2.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_scores = spark.read.option(\"delimiter\", \"|\").option(\"header\",True).csv(\"/user/csanc109/data/mobile_base_20190930_insigths/mobile_base_20190930_insights.csv\")\n",
    "print(len(df_model_scores.columns), df_model_scores.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_insi = spark.read.option(\"delimiter\", \"|\").option(\"header\",True).csv(\"/user/csanc109/data/mobile_base_20190930_insigths/mobile_base_20190930_insights.csv\")\n",
    "# # for col_ in df_insi.columns:\n",
    "# #     if col_ == \"MSISDN\":\n",
    "# #         df_insi = df_insi.withColumnRenamed(col_, col_.lower())\n",
    "# #     else:\n",
    "# #         df_insi = df_insi.withColumnRenamed(col_, col_.lower()+\"_insi\")\n",
    "     \n",
    "df_model_scores = spark.read.option(\"delimiter\", \"|\").option(\"header\",True).csv(\"/user/csanc109/data/mobile_base_20190930_insigths/mobile_base_20190930_insights.csv\")\n",
    "\n",
    "\n",
    "#df_model_scores = spark.read.load(\"/user/csanc109/data/mobile_base_20190930_parquet\")\n",
    "df_model_scores = df_model_scores.withColumn(\"scoring\", lit(0.0))\n",
    "df_model_scores = df_model_scores.withColumnRenamed(\"NIF_CLIENTE\", \"nif\")\n",
    "df_model_scores = df_model_scores.withColumnRenamed(\"NUM_CLIENTE\", \"client_id\")\n",
    "df_model_scores = df_model_scores.withColumnRenamed(\"MSISDN\", \"msisdn\")\n",
    "\n",
    "   \n",
    "df_model_scores.columns\n",
    "\n",
    "# Create the columns with missing identifiers\n",
    "for col_ in  ALL_ID_COLS:\n",
    "    if not col_ in df.columns:\n",
    "        # Avoid this problem \"Caused by: java.lang.RuntimeException: Unsupported data type NullType.\"\n",
    "        df = df.withColumn(col_, lit(\"\"))\n",
    "        print(\"Added None to non existing col {}\".format(col_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_model_scores = spark.read.option(\"delimiter\", \"|\").option(\"header\",True).csv(\"/user/csanc109/data/mobile_base_20190930_insigths/mobile_base_20190930_insights.csv\")\n",
    "\n",
    "\n",
    "#df_model_scores = spark.read.load(\"/user/csanc109/data/mobile_base_20190930_parquet\")\n",
    "df_model_scores = df_model_scores.withColumn(\"scoring\", lit(0.0))\n",
    "df_model_scores = df_model_scores.withColumnRenamed(\"NIF_CLIENTE\", \"nif\")\n",
    "df_model_scores = df_model_scores.withColumnRenamed(\"NUM_CLIENTE\", \"client_id\")\n",
    "df_model_scores = df_model_scores.withColumnRenamed(\"MSISDN\", \"msisdn\")\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import length, concat_ws, regexp_replace, split\n",
    "from churn.datapreparation.general.model_outputs_manager import ensure_types_model_scores_columns\n",
    "\n",
    "EXTRA_INFO_COLS = ['msisdn',\"client_id\", \"nif\"]\n",
    "\n",
    "MODEL_OUTPUTS_NULL_TAG = \"\"\n",
    "\n",
    "executed_at = dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S \")\n",
    "\n",
    "return_feed_execution = \"20190930\"\n",
    "\n",
    "day_partition = int(return_feed_execution[6:])\n",
    "month_partition = int(return_feed_execution[4:6])\n",
    "year_partition = int(return_feed_execution[:4])\n",
    "training_closing_date = \"20190930\"\n",
    "\n",
    "print(\"Going to insert with partition {} {} {} \".format(year_partition, month_partition, day_partition))\n",
    "\n",
    "'''\n",
    "MODEL PARAMETERS\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "df_pandas = pd.DataFrame({\n",
    "    \"model_name\": [\"mobile_base\"],\n",
    "    \"executed_at\": [executed_at],\n",
    "    \"model_level\": [\"msisdn\"],\n",
    "    \"training_closing_date\": [training_closing_date if training_closing_date else closing_day],\n",
    "    \"target\": [\"\"],\n",
    "    \"model_path\": [\"\"],\n",
    "    \"metrics_path\": [\"\"],\n",
    "    \"metrics_train\": [\"\"],\n",
    "    \"metrics_test\": [\"\"],\n",
    "    \"varimp\": [\"\"],\n",
    "    \"algorithm\": [\"\"],\n",
    "    \"author_login\": [\"csanc109\"],\n",
    "    \"extra_info\": [\"\"],\n",
    "    \"scores_extra_info_headers\": [\";\".join(EXTRA_INFO_COLS)],\n",
    "    \"year\":  [year_partition],\n",
    "    \"month\": [month_partition],\n",
    "    \"day\":   [day_partition],\n",
    "    \"time\": [int(executed_at.split(\" \")[1].replace(\":\", \"\"))]\n",
    "})\n",
    "\n",
    "df_parameters = spark.createDataFrame(df_pandas).withColumn(\"day\", col(\"day\").cast(\"integer\"))\\\n",
    "                                                .withColumn(\"month\", col(\"month\").cast(\"integer\"))\\\n",
    "                                                .withColumn(\"year\", col(\"year\").cast(\"integer\"))\\\n",
    "                                                .withColumn(\"time\", col(\"time\").cast(\"integer\"))\n",
    "\n",
    "'''\n",
    "MODEL SCORES\n",
    "'''\n",
    "\n",
    "# set to null the columns that go to extra_info field and have no value\n",
    "for col_ in EXTRA_INFO_COLS:\n",
    "    df_model_scores = df_model_scores.withColumn(col_,\n",
    "                                                 when(coalesce(length(col(col_)), lit(0)) == 0, MODEL_OUTPUTS_NULL_TAG).otherwise(\n",
    "                                                     col(col_)))\n",
    "\n",
    "df_model_scores = (\n",
    "        df_model_scores.withColumn(\"extra_info\", concat_ws(\";\", *[col(col_name) for col_name in EXTRA_INFO_COLS]))\n",
    "        .withColumn(\"prediction\", lit(\"0\"))\n",
    "        .drop(*EXTRA_INFO_COLS)\n",
    "        .withColumnRenamed(\"comb_score\", \"scoring\")\n",
    "        .withColumn(\"model_name\", lit(\"mobile_base\"))\n",
    "        .withColumn(\"executed_at\", lit(executed_at))\n",
    "        .withColumn(\"model_executed_at\", lit(executed_at))\n",
    "        .withColumn(\"year\", lit(year_partition).cast(\"integer\"))\n",
    "        .withColumn(\"month\",lit(month_partition).cast(\"integer\"))\n",
    "        .withColumn(\"day\", lit(day_partition).cast(\"integer\"))\n",
    "        .withColumn(\"time\", regexp_replace(split(col(\"executed_at\"), \" \")[1], \":\", \"\").cast(\"integer\"))\n",
    "        .withColumn(\"predict_closing_date\", lit(\"20190930\"))\n",
    "        .withColumn(\"model_output\", lit(\"\"))\n",
    "    )\n",
    "\n",
    "df_model_scores = ensure_types_model_scores_columns(df_model_scores, check_ids=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_path1 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=21/time=1574782575\"\n",
    "day_path2 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=22/time=1574791124\"\n",
    "day_path3 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=23/time=1574863576\"\n",
    "day_path4 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=24/time=1574791742\"\n",
    "day_path5 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=25/time=1574886360\"\n",
    "day_path6 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=26/time=1574887287\"\n",
    "day_path7 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=27/time=1574888086\"\n",
    "day_path8 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=28/time=1574944954\"\n",
    "day_path9 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=29/time=1574947667\"\n",
    "day_path10 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=30/time=1574941173\"\n",
    "\n",
    "paths_dict = {\"20191021\" : day_path1,\n",
    "              \"20191022\" : day_path2,\n",
    "              \"20191023\" : day_path3,\n",
    "              \"20191024\" : day_path4,\n",
    "              \"20191025\" : day_path5,\n",
    "              \"20191026\" : day_path6,\n",
    "              \"20191027\" : day_path7,\n",
    "              \"20191028\" : day_path8,\n",
    "              \"20191029\" : day_path9,\n",
    "              \"20191030\" : day_path10\n",
    "             }\n",
    "\n",
    "\n",
    "\n",
    "#label_kind = \"mobile\"\n",
    "label_kind = \"mobile\" \n",
    "closing_day = \"20191023\"\n",
    "\n",
    "for closing_day in paths_dict.keys():\n",
    "\n",
    "    df_labels = spark.read.load(paths_dict[closing_day])\n",
    "\n",
    "    print(\"NUM LABELS ORIG\", df_labels.select(sql_sum('label').alias('num_churners')).rdd.first()['num_churners'])\n",
    "\n",
    "    if label_kind in  [\"mobile+fix\"]:\n",
    "        df_lab = get_label(spark, closing_day, kind=label_kind, churn_window=15).select(\"msisdn\", \"label\")\n",
    "        df_labels = df_labels.drop(\"label\")\n",
    "        df_labels = df_labels.join(df_lab, on=[\"msisdn\"], how=\"left\").na.fill({'label': 0.0})\n",
    "\n",
    "    elif label_kind != \"mobile\":\n",
    "        print(\"Unknown kind {}. Program will exit here!\".format(kind))\n",
    "        import sys\n",
    "        sys.exit()\n",
    "\n",
    "    print(\"NUM LABELS AFTER\", df_labels.select(sql_sum('label').alias('num_churners')).rdd.first()['num_churners'])\n",
    "\n",
    "\n",
    "    from pyspark.sql.functions import avg as sql_avg\n",
    "    myschema = df_labels.schema\n",
    "    df_labels = df_labels.sort(desc(\"model_score\"))\n",
    "    df_top_6500 = spark.createDataFrame(df_labels.head(6500), schema=myschema)\n",
    "\n",
    "    tt_churn_ref = df_top_6500.select(sql_avg('label').alias('churn_ref')).rdd.first()['churn_ref']\n",
    "    print(closing_day, tt_churn_ref * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incrementals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from churn_nrt.src.utils.date_functions import days_range\n",
    "   \n",
    "from churn_nrt.src.utils.date_functions import move_date_n_days\n",
    "from pyspark.sql.functions import avg as sql_avg\n",
    "\n",
    "\n",
    "\n",
    "day_path1 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=21/time=1574782575\"\n",
    "day_path2 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=22/time=1574791124\"\n",
    "day_path3 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=23/time=1574863576\"\n",
    "day_path4 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=24/time=1574791742\"\n",
    "day_path5 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=25/time=1574886360\"\n",
    "day_path6 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=26/time=1574887287\"\n",
    "day_path7 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=27/time=1574888086\"\n",
    "day_path8 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=28/time=1574944954\"\n",
    "day_path9 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=29/time=1574947667\"\n",
    "day_path10 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=30/time=1574941173\"\n",
    "day_path11 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=31/time=1576059964\"\n",
    "\n",
    "#range_dates = days_range(\"20191021\", \"20191025\")\n",
    "range_dates = [\"20191030\"] \n",
    "print(range_dates)\n",
    "paths_dict = {\n",
    "               \"20191021\" : day_path1,\n",
    "               \"20191022\" : day_path2,\n",
    "               \"20191023\" : day_path3,\n",
    "               \"20191024\" : day_path4,\n",
    "               \"20191025\" : day_path5,\n",
    "               \"20191026\" : day_path6,\n",
    "               \"20191027\" : day_path7,\n",
    "               \"20191028\" : day_path8,\n",
    "               \"20191029\" : day_path9,\n",
    "               \"20191030\" : day_path10,\n",
    "               \"20191031\" : day_path11\n",
    "            }\n",
    "\n",
    "#label_kind = \"mobile\"\n",
    "label_kind = \"mobile+fix\" \n",
    "top_ = 727\n",
    "step_=1\n",
    "verbose=True\n",
    "compute_lift=True\n",
    "\n",
    "for closing_day in range_dates:\n",
    "    \n",
    "    closing_day_B = move_date_n_days(closing_day, n=step_)\n",
    "    print(\" * - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - *\")\n",
    "    if closing_day in paths_dict.keys():\n",
    "        print(closing_day, paths_dict[closing_day])\n",
    "    else:\n",
    "        print(\"no existe\")\n",
    "        continue\n",
    "        \n",
    "    if closing_day_B in paths_dict.keys():\n",
    "        print(closing_day_B, paths_dict[closing_day_B])\n",
    "    else:\n",
    "        print(\"no existe\")\n",
    "        continue\n",
    "\n",
    "    df_labels_A = spark.read.load(paths_dict[closing_day])\n",
    "    df_labels_B = spark.read.load(paths_dict[closing_day_B])\n",
    "    df_labels_join = df_labels_A.select(\"msisdn\").join(df_labels_B.select(\"msisdn\", \"label\", \"model_score\"), ['msisdn'], 'right').where(df_labels_A['msisdn'].isNull())\n",
    "    df_labels_join = df_labels_join.cache()\n",
    "    if verbose: print(\"volumen incremental\", df_labels_join.count())\n",
    "\n",
    "    #print(\"NUM LABELS ORIG\", df_labels_join.select(sql_sum('label').alias('num_churners')).rdd.first()['num_churners'])\n",
    "\n",
    "    if label_kind in  [\"mobile+fix\", \"mobile\"]:\n",
    "        df_lab = get_label(spark, closing_day_B, kind=label_kind, churn_window=15).select(\"msisdn\", \"label\")\n",
    "        df_labels_join = df_labels_join.drop(\"label\")\n",
    "        df_labels_join = df_labels_join.join(df_lab, on=[\"msisdn\"], how=\"left\").na.fill({'label': 0.0})\n",
    "        \n",
    "    elif label_kind != \"mobile\":\n",
    "        print(\"Unknown kind {}. Program will exit here!\".format(label_kind))\n",
    "        import sys\n",
    "        sys.exit()\n",
    "\n",
    "    #print(\"NUM LABELS AFTER\", df_labels_join.select(sql_sum('label').alias('num_churners')).rdd.first()['num_churners'])\n",
    "\n",
    "    tt_churn_ref = df_labels_join.select(sql_avg('label').alias('churn_ref')).rdd.first()['churn_ref']\n",
    "    if verbose: print(\"churn_rate\", tt_churn_ref)\n",
    "    \n",
    "    myschema3 = df_labels_join.schema\n",
    "    \n",
    "    if top_:\n",
    "        from pyspark.sql.functions import avg as sql_avg\n",
    "        df_labels_join = df_labels_join.sort(desc(\"model_score\"))\n",
    "        df_top_400 = spark.createDataFrame(df_labels_join.head(top_), schema=myschema3)\n",
    "        tt_churn_ref = df_top_400.select(sql_avg('label').alias('churn_ref')).rdd.first()['churn_ref']\n",
    "        print(\"------\", label_kind, closing_day, closing_day_B, \"ChRate{}\".format(top_), tt_churn_ref * 100)\n",
    "        \n",
    "    if compute_lift:\n",
    "        from churn_nrt.src.projects_utils.models.modeler import get_cumulative_lift_fix_step\n",
    "        cum_churn_rate = get_cumulative_lift_fix_step(spark, df_labels_join, ord_col =  'model_score', label_col = 'label', step_=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencia de Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msisdn_df.unpersist()\n",
    "msisdn_df = spark.read.table(\"raw_es.campaign_msisdncontacthist\")\n",
    "msisdn_df = msisdn_df.filter((col(\"CampaignCode\").contains(\"COMP_WEB\")) & (col(\"Creatividad\").startswith(\"LLAM_\"))).drop_duplicates([\"msisdn\"])\n",
    "msisdn_df = msisdn_df.where(col(\"year\")==2019).where(col(\"month\")==10)\n",
    "#msisdn_df = msisdn_df.persist()\n",
    "msisdn_df.groupby(\"year\", \"month\", \"day\").agg(sql_count(\"*\").alias(\"count\")).sort(desc(\"year\"), desc(\"month\"), desc(\"day\")).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closing_day = \"20191027\"\n",
    "\n",
    "\n",
    "day_path1 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=21/time=1574782575\"\n",
    "day_path2 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=22/time=1574791124\"\n",
    "day_path3 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=23/time=1574863576\"\n",
    "day_path4 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=24/time=1574791742\"\n",
    "day_path5 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=25/time=1574886360\"\n",
    "day_path6 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=26/time=1574887287\"\n",
    "day_path7 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=27/time=1574888086\"\n",
    "day_path8 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=28/time=1574944954\"\n",
    "day_path9 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=29/time=1574947667\"\n",
    "day_path10 = \"/data/udf/vf_es/churn/triggers/nav_comp_tests_all_labels/year=2019/month=10/day=30/time=1574941173\"\n",
    "\n",
    "\n",
    "\n",
    "paths_dict = {\"20191021\" : day_path1,\n",
    "              \"20191022\" : day_path2,\n",
    "              \"20191023\" : day_path3,\n",
    "              \"20191024\" : day_path4,\n",
    "              \"20191025\" : day_path5,\n",
    "              \"20191026\" : day_path6,\n",
    "              \"20191027\" : day_path7,\n",
    "              \"20191028\" : day_path8,\n",
    "              \"20191029\" : day_path9,\n",
    "              \"20191030\" : day_path10\n",
    "             }\n",
    "\n",
    "df_car = spark.read.load(paths_dict[closing_day])\n",
    "\n",
    "print(\"NUM LABELS original\", df_car.select(sql_sum('label').alias('num_churners')).rdd.first()['num_churners'])\n",
    "\n",
    "\n",
    "df_car = df_car.drop(\"label\")\n",
    "df_lab = get_label(spark, closing_day, kind=\"mobile\", churn_window=15)\n",
    "\n",
    "df_car_mobile = df_car.join(df_lab, on=[\"msisdn\"], how=\"left\").na.fill({'label': 0.0})\n",
    "\n",
    "print(\"NUM LABELS mobile\", df_car_mobile.select(sql_sum('label').alias('num_churners')).rdd.first()['num_churners'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_label(spark, closing_day, kind=\"mobile\", churn_window=15, columns=\"simple\"):\n",
    "    from churn_nrt.src.utils.date_functions import move_date_n_days\n",
    "    #start_port = move_date_n_days(closing_day, n=1)\n",
    "    end_port = move_date_n_days(closing_day, n=churn_window)\n",
    "\n",
    "    if kind==\"mobile\":\n",
    "\n",
    "        from churn.analysis.triggers.base_utils.base_utils import get_mobile_portout_requests, get_customer_base\n",
    "        df_target = get_mobile_portout_requests(spark, closing_day, end_port).select(\"msisdn\", \"label_mob\").withColumnRenamed(\"label_mob\", \"label\")\n",
    "        return df_target\n",
    "    \n",
    "    elif kind==\"mobile+fix\":\n",
    "        \n",
    "        print(\"Computing target with mobile and fix sopo\")\n",
    "        \n",
    "\n",
    "        from churn_nrt.src.data.sopos_dxs import FixPort\n",
    "        from churn_nrt.src.data.customer_base import CustomerBase\n",
    "\n",
    "        # The base of active services on closing_day\n",
    "        from churn.analysis.triggers.base_utils.base_utils import get_mobile_portout_requests, get_customer_base\n",
    "        base_df = get_customer_base(spark, closing_day).select('msisdn', \"nif_cliente\", \"rgu\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Getting portout requests for fix and mobile services, and disconnections of fbb services\n",
    "        print(\"******* Asking for FixPort...\")\n",
    "        df_sopo_fix = FixPort(spark).get_module(closing_day, save=False, churn_window=churn_window)\n",
    "        df_sopo_fix = (df_sopo_fix.join(base_df.select(\"msisdn\", \"nif_cliente\"), ['msisdn'], \"left\").na.fill({'label_srv': 0.0}))\n",
    "        # Agg by nif_cliente the column label_srv just to be sure that only one per nif\n",
    "        window_nc = Window.partitionBy(\"nif_cliente\")\n",
    "        df_sopo_fix = df_sopo_fix.withColumn('label_srv', sql_max('label_srv').over(window_nc)).na.fill({'label_srv': 0.0})     \n",
    "        df_sopo_fix = df_sopo_fix.drop_duplicates([\"nif_cliente\"])\n",
    "\n",
    "\n",
    "        base_df = base_df.join(get_mobile_portout_requests(spark, closing_day, end_port).select('msisdn', 'label_mob'), ['msisdn'], 'left').na.fill(0.0)\n",
    "        df_sopos = (base_df.join(df_sopo_fix.select(\"nif_cliente\", \"label_srv\"), ['nif_cliente'], \"left\").na.fill({'label_srv': 0.0}))\n",
    "\n",
    "        df_sopos = df_sopos.withColumn('label', when((col('label_srv') == 1.0) | (col('label_mob') == 1.0), 1.0).otherwise(0.0))\n",
    "        \n",
    "        if columns==\"simple\":\n",
    "            return df_sopos.filter(col('rgu') == 'mobile').select(\"msisdn\", \"label\")\n",
    "        else:\n",
    "            return df_sopos.filter(col('rgu') == 'mobile').select(\"msisdn\", \"label\", \"label_mob\", \"label_srv\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Unknown kind {}. Program will exit here!\".format(kind))\n",
    "        return None\n",
    "                \n",
    "        \n",
    "#get_label(spark, closing_day=\"20191024\", kind=\"mobile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn Rate - Insights campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from churn_nrt.src.utils.date_functions import days_range\n",
    "    \n",
    "from churn_nrt.src.utils.date_functions import move_date_n_days\n",
    "from pyspark.sql.functions import avg as sql_avg\n",
    "\n",
    "#label_kind = \"mobile\"\n",
    "#label_kind = \"mobile+fix\" \n",
    "\n",
    "\n",
    "# for closing_day in range_dates:\n",
    "    \n",
    "#     print(closing_day, paths_dict[closing_day])\n",
    "  \n",
    "#     msisdn_df = spark.read.table(\"raw_es.campaign_msisdncontacthist\")\n",
    "\n",
    "#     insights_df = msisdn_df.filter((col('year')==int(closing_day[:4])) & (col('month') == int(closing_day[4:6])) & (col('day') == int(closing_day[6:])) & (col(\"CampaignCode\").contains(\"COMP_WEB\")) & (col(\"Creatividad\").startswith(\"LLAM_\"))).select(\"msisdn\").distinct()\n",
    "#     print(\"clients\", insights_df.count())\n",
    "#     #start_port = move_date_n_days(closing_day, n=1)\n",
    "#     end_port = move_date_n_days(closing_day, n=15)\n",
    "\n",
    "#     from churn.analysis.triggers.base_utils.base_utils import get_mobile_portout_requests, get_customer_base\n",
    "#     #insights_df.join(get_mobile_portout_requests(spark, start_port, end_port).select(\"msisdn\", \"label_mob\").withColumnRenamed(\"label_mob\", \"label\"), ['msisdn'], 'left').na.fill({'label': 0.0}).select(sql_avg('label')).show()\n",
    "#     insights_df.join(get_label(spark, closing_day, kind=label_kind, churn_window=15).select(\"msisdn\", \"label\"), ['msisdn'], 'left').na.fill({'label': 0.0}).select(sql_avg('label')).show()\n",
    "\n",
    "\n",
    "base_closing_day = \"20191031\"\n",
    "base_closing_day_end = \"20191031\"\n",
    "port_closing_day = base_closing_day_end\n",
    "label_kind = \"mobile+fix\" \n",
    "\n",
    "#msisdn_df.unpersist()\n",
    "msisdn_df = (spark.read.table(\"raw_es.campaign_msisdncontacthist\")\n",
    "                .where( ((col(\"CampaignCode\").contains(\"COMP_WEB\")) & (col(\"Creatividad\").startswith(\"LLAM_\"))))\n",
    "                .withColumn(\"datedate\", concat(col('year'), lpad(col('month'), 2, '0'), lpad(col('day'), 2, '0'))).cache()\n",
    "                .where(   (col('datedate')>= base_closing_day) & (col('datedate')<= base_closing_day_end))\n",
    "                .drop_duplicates([\"msisdn\"]))\n",
    "print(\"clients\", msisdn_df.count())\n",
    "print(\"drop_duplic\", msisdn_df.drop_duplicates([\"msisdn\"]).count())\n",
    "msisdn_df.groupby(\"year\", \"month\", \"day\").agg(sql_count(\"*\").alias(\"count\")).sort(desc(\"year\"), desc(\"month\"), desc(\"day\")).show(100)\n",
    "#start_port = move_date_n_days(closing_day, n=1)\n",
    "#end_port = move_date_n_days(base_closing_day_end, n=15)\n",
    "msisdn_df.groupby(\"datedate\").agg(sql_count(\"*\").alias(\"count\")).sort(desc(\"datedate\")).show(100)\n",
    "\n",
    "from churn.analysis.triggers.base_utils.base_utils import get_mobile_portout_requests, get_customer_base\n",
    "#insights_df.join(get_mobile_portout_requests(spark, start_port, end_port).select(\"msisdn\", \"label_mob\").withColumnRenamed(\"label_mob\", \"label\"), ['msisdn'], 'left').na.fill({'label': 0.0}).select(sql_avg('label')).show()\n",
    "msisdn_df.join(get_label(spark, base_closing_day_end, kind=label_kind, churn_window=15).select(\"msisdn\", \"label\"), ['msisdn'], 'left').na.fill({'label': 0.0}).select(sql_avg('label')).show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msisdn_df = spark.read.table(\"raw_es.campaign_msisdncontacthist\")\n",
    "msisdn_df = msisdn_df.filter((col(\"CampaignCode\").contains(\"COMP_WEB\")) & (col(\"Creatividad\").startswith(\"LLAM_\"))).drop_duplicates([\"msisdn\"])\n",
    "msisdn_df = msisdn_df.where(col(\"year\")==2019).where(col(\"month\")>=10)\n",
    "\n",
    "msisdn_df.groupby(\"year\", \"month\", \"day\").agg(sql_count(\"*\").alias(\"count\")).sort(desc(\"year\"), desc(\"month\"), desc(\"day\")).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bd = spark.read.option(\"delimeter\", \"|\").option(\"header\",True).csv(\"/user/csanc109/data/mobile_base_20190930_desanonim/Mobile_Base-20190930.csv\")\n",
    "df_bd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "u'Path does not exist: hdfs://nameservice1/data/raw/vf_es/customerprofilecar/ADOBE_SECTIONS/1.1/parquet;'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-6cc5cf6f7936>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/data/raw/vf_es/customerprofilecar/ADOBE_SECTIONS/1.1/parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/cloudera/parcels/SPARK2/lib/spark2/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda-2.5.0/lib/python2.7/site-packages/py4j/java_gateway.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/SPARK2/lib/spark2/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: u'Path does not exist: hdfs://nameservice1/data/raw/vf_es/customerprofilecar/ADOBE_SECTIONS/1.1/parquet;'"
     ]
    }
   ],
   "source": [
    "spark.read.load(\"/data/raw/vf_es/customerprofilecar/ADOBE_SECTIONS/1.1/parquet\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADOBE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+----------------------------------------------------------------------------+\n",
      "|Date               |msisdn   |Pages                                                                       |\n",
      "+-------------------+---------+----------------------------------------------------------------------------+\n",
      "|2019-11-19 00:08:36|B42000417|productos y servicios:resumen de productos y servicios                      |\n",
      "|2019-11-19 00:08:45|B42000417|productos y servicios:detalle de tarifa:vodafone tv online                  |\n",
      "|2019-11-19 00:16:33|B42000417|productos y servicios:resumen de productos y servicios                      |\n",
      "|2019-11-19 00:16:41|B42000417|productos y servicios:detalle de tarifa:vodafone tv online                  |\n",
      "|2019-11-19 00:17:17|B42000417|productos y servicios:detalle de tarifa:vodafone tv online:cambio de usuario|\n",
      "|2019-11-19 00:17:57|B42000417|dashboard:home                                                              |\n",
      "|2019-11-19 00:21:11|620324021|mi cuenta:resumen de mi cuenta                                              |\n",
      "|2019-11-19 00:20:15|605018123|dashboard:home                                                              |\n",
      "|2019-11-19 00:20:18|605018123|overlay promo_bf:no ilimitable                                              |\n",
      "|2019-11-19 00:20:18|605018123|dashboard:home                                                              |\n",
      "|2019-11-19 00:20:26|605018123|facturas:mis facturas:resumen de cuentas                                    |\n",
      "|2019-11-19 00:20:45|605018123|dashboard:home                                                              |\n",
      "|2019-11-19 00:20:49|605018123|dashboard:home                                                              |\n",
      "|2019-11-19 00:20:55|605018123|que tengo contratado:resumen que tengo contratado                           |\n",
      "|2019-11-19 00:21:44|605018123|facturas:mis facturas:resumen de cuentas                                    |\n",
      "|2019-11-19 00:21:49|605018123|que tengo contratado:resumen que tengo contratado                           |\n",
      "|2019-11-19 00:22:04|605018123|dashboard:home                                                              |\n",
      "|2019-11-19 00:22:08|605018123|dashboard:home                                                              |\n",
      "|2019-11-19 00:22:10|605018123|facturas:mis facturas:resumen de cuentas                                    |\n",
      "|2019-11-19 00:22:13|605018123|facturas:mis facturas:resumen de cuentas:editar alias factura               |\n",
      "+-------------------+---------+----------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_net = spark.read.table(\"raw_es.customerprofilecar_adobe_sections\").drop(\"service_processed_at\", \"service_file_id\", \"year\", \"month\", \"day\").withColumn(\"msisdn\", col(\"MSISDN\").substr(3, 9))\n",
    "df_net.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------+\n",
      "|section              |count   |\n",
      "+---------------------+--------+\n",
      "|dashboard            |17580672|\n",
      "|facturas             |5390241 |\n",
      "|productos_y_servicios|5381573 |\n",
      "|que_tengo_contratado |3607038 |\n",
      "|mi_cuenta            |2792485 |\n",
      "|mensajes             |2054267 |\n",
      "|prelogin             |1573449 |\n",
      "|childbrowser         |1012288 |\n",
      "|webview              |978901  |\n",
      "|consumo              |927399  |\n",
      "|screen_myrewards     |816450  |\n",
      "|averias              |737563  |\n",
      "|overlay_promo_bf     |366341  |\n",
      "|faqs                 |354766  |\n",
      "|login                |324253  |\n",
      "|ajustes_de_linea     |314110  |\n",
      "|need_help            |309608  |\n",
      "|ajustes              |295724  |\n",
      "|screen_allrewards    |279236  |\n",
      "|screen_rewarddetails |277214  |\n",
      "+---------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'from_unixtime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-671f5da48313>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m df_net = df_net.withColumn(\"days_since_nav\", when(col(\"date_\").isNotNull(),\n\u001b[0;32m---> 33\u001b[0;31m                                                   datediff(from_unixtime(unix_timestamp(lit(closing_day), \"yyyyMMdd\")), from_unixtime(unix_timestamp(col(\"date_\"), \"yyyyMMdd\")))).otherwise(-1))\n\u001b[0m\u001b[1;32m     34\u001b[0m df_net = df_net.withColumn(\"diff\", when(col(\"days_since_nav\") != -1,\n\u001b[1;32m     35\u001b[0m                                         lag(col(\"days_since_nav\"), -1).over(Window.partitionBy(\"msisdn\").orderBy(asc(\"days_since_nav\"))) - col(\"days_since_nav\")).otherwise(None))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'from_unixtime' is not defined"
     ]
    }
   ],
   "source": [
    "#df_net.unpersist()\n",
    "\n",
    "\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "\n",
    "df_net = spark.read.table(\"raw_es.customerprofilecar_adobe_sections\").drop(\"service_processed_at\", \"service_file_id\", \"year\", \"month\", \"day\").withColumn(\"msisdn\", col(\"MSISDN\").substr(3, 9))\n",
    "\n",
    "func_date =  udf (lambda x: dt.datetime.strptime(x, '%Y-%m-%d %H:%M:%S').strftime(\"%Y%m%d\"), StringType())\n",
    "\n",
    "df_net = df_net.withColumn('date_', func_date(col('Date'))).drop(\"Date\")\n",
    "\n",
    "stages_name = [\"section\", \"subsection\", \"page_name\"]\n",
    "\n",
    "for ii, col_ in enumerate(stages_name):\n",
    "    if col_ == \"section\":\n",
    "        # Do not split if Pages is an url\n",
    "        df_net = df_net.withColumn(col_, when(~col(\"Pages\").rlike(\"^https://\"), split(\"Pages\", \":\")[ii]).otherwise(col(\"Pages\")))\n",
    "    else:\n",
    "        df_net = df_net.withColumn(col_, when(~col(\"Pages\").rlike(\"^https://\"), split(\"Pages\", \":\")[ii]).otherwise(None))\n",
    "\n",
    "df_net = df_net.withColumn('section', regexp_replace('section', ' ', '_'))  # remove spaces with underscore to avoid error when writing df\n",
    "df_net = df_net.withColumn(\"section\", when(col(\"section\").rlike(\"https://m.vodafone.es/mves/Dashboard/Ayuda\"), \"url_ayuda\").otherwise(col(\"section\")))\n",
    "#df_net.groupby(\"section\").agg(sql_count(\"*\").alias(\"count\")).sort(desc(\"count\")).show(truncate=False)\n",
    "\n",
    "#print(\"[MyVFdata] Filtering sections other than {}\".format(\",\".join(sections)))\n",
    "#df_net = df_net.where(col(\"section\").isin(sections))\n",
    "df_net.groupby(\"section\").agg(sql_count(\"*\").alias(\"count\")).sort(desc(\"count\")).show(truncate=False)\n",
    "\n",
    "df_net = df_net.withColumn(\"days_since_nav\", when(col(\"date_\").isNotNull(),\n",
    "                                                  datediff(from_unixtime(unix_timestamp(lit(closing_day), \"yyyyMMdd\")), from_unixtime(unix_timestamp(col(\"date_\"), \"yyyyMMdd\")))).otherwise(-1))\n",
    "df_net = df_net.withColumn(\"diff\", when(col(\"days_since_nav\") != -1,\n",
    "                                        lag(col(\"days_since_nav\"), -1).over(Window.partitionBy(\"msisdn\").orderBy(asc(\"days_since_nav\"))) - col(\"days_since_nav\")).otherwise(None))\n",
    "\n",
    "\n",
    "\n",
    "df_net = df_net.withColumn('date_', func_date(col('Date')))\n",
    "\n",
    "#df_net.show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sections = df_net.select(\"section\").distinct().rdd.map(lambda x: x[0]).collect()\n",
    "df_net.select(\"section\", \"subsection\", \"page_name\").groupby(\"section\", \"subsection\", \"page_name\").agg(sql_count(\"*\").alias(\"count\")).sort(desc(\"count\")).show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sections = df_net.select(\"section\").distinct().rdd.map(lambda x: x[0]).collect()\n",
    "sections = [u'https://m.vodafone.es/mves/billing/currentConsumption',\n",
    " u'lo_sentimos,_el_servicio_no_esta_disponible',\n",
    " u'television',\n",
    " u'https://m.vodafone.es/mves/myAccount/permissions',\n",
    " u'https://m.vodafone.es/mves/myAccount/billingAccounts',\n",
    " u'https://m.vodafone.es/mves/TopUp/topUpHistory',\n",
    " u'settings_privacy_page',\n",
    " u'https://m.vodafone.es/mves/splash',\n",
    " u'service_settings',\n",
    " u'https://m.vodafone.es/mves/billing/eBill',\n",
    " u'roaming_warning_popup',\n",
    " u'https://m.vodafone.es/mves/ProductsAndServices/securenet',\n",
    " u'overlay_informacion_5g',\n",
    " u'mis_dispositivos',\n",
    " u'https://m.vodafone.es/mves/PurchasedProducts/couteDetails',\n",
    " u'https://m.vodafone.es/mves/Dashboard',\n",
    " u'childbrowser',\n",
    " u'ayuda_y_soporte',\n",
    " u'https://m.vodafone.es/mves/myAccount/nif',\n",
    " u'https://m.vodafone.es/mves/billing/billingOverview',\n",
    " u'https://m.vodafone.es/mves/LineServices/CallOptions/DictaSMS',\n",
    " u'https://m.vodafone.es/mves/ServiceSettings/thirdPartyChild',\n",
    " u'https://m.vodafone.es/mves/myAccount/details',\n",
    " u'https://m.vodafone.es/mves/myAccount/PermissionsAndPreferences/DiagnosticoDeMiVodafone',\n",
    " u'network_usage_error',\n",
    " u'dictasms',\n",
    " u'avisos_de_llamada_perdida',\n",
    " u'MyVodafone_Production/2098',\n",
    " u'Speed_Checker_Error',\n",
    " u'ajustes_y_extras',\n",
    " u'https://m.vodafone.es/mves/billing/creditNotes',\n",
    " u'https://m.vodafone.es/mves/myAccount/serviceSelectorCommitmentContract',\n",
    " u'que_tengo_contratado',\n",
    " u'overlay_maintenance',\n",
    " u'network_usage_reset_confirmation_page',\n",
    " u'MyVodafone_Production/1917',\n",
    " u'https://m.vodafone.es/mves/ProductsAndServices/extrasList',\n",
    " u'Running_Speed_Test',\n",
    " u'https://m.vodafone.es/mves/myAccount/commitmentContracts',\n",
    " u'https://m.vodafone.es/mves/FaultManagement/RecentTickets',\n",
    " u'https://m.vodafone.es/mves/myAccount/editDetails',\n",
    " u'asistente',\n",
    " u'inicio',\n",
    " u'https://m.vodafone.es/mves/ProductsAndServices/MainScreen',\n",
    " u'facturas',\n",
    " u'Speed_Checker_Landing_Page',\n",
    " u'upgrade',\n",
    " u'https://m.vodafone.es/mves',\n",
    " u'https://m.vodafone.es/mves/login/companyChooser',\n",
    " u'Permission_Request',\n",
    " u'https://m.vodafone.es/mves/ProductsAndServices/PlanDetails',\n",
    " u'login',\n",
    " u'netperform_privacy_policy',\n",
    " u'https://m.vodafone.es/mves/ProductsAndServices/details',\n",
    " u'overlay_favourite',\n",
    " u'https://m.vodafone.es/mves/ProductsAndServices/ManageMiWifi/MiWifiLanding',\n",
    " u'https://m.vodafone.es/mves/myAccount/PermissionsAndAuthorizations',\n",
    " u'screen_allrewards',\n",
    " u'https://m.vodafone.es/mves/ServiceSettings/purchasesAndSubscriptions',\n",
    " u'https://m.vodafone.es/mves/billing/billConfig',\n",
    " u'overlay_no_disponibilidad',\n",
    " u'Mi_Vodafone_4.4.7_(176)',\n",
    " u'https://m.vodafone.es/mves/myAccount/Mycontracts/MainPage',\n",
    " u'prelogin',\n",
    " u'screen_rewarddetails',\n",
    " u'faq',\n",
    " u'network_usage_landing_page',\n",
    " u'https://m.vodafone.es/mves/myAccount/OverviewScreen',\n",
    " u'https://m.vodafone.es/mves/login',\n",
    " u'tarifa',\n",
    " u'https://m.vodafone.es/mves/billing/BillOverview',\n",
    " u'https://m.vodafone.es/mves/ProductsAndServices/superWifiDetails',\n",
    " u'migracion_destiny',\n",
    " u'faqs',\n",
    " u'https://m.vodafone.es/mves/billing/billingDetails',\n",
    " u'https://m.vodafone.es/mves/ProductsAndServices/update',\n",
    " u'permission_gps_request',\n",
    " u'https://m.vodafone.es/mves/myAccount/PermissionsAndPreferences',\n",
    " u'https://m.vodafone.es/mves/licenses',\n",
    " u'https://m.vodafone.es/mves/myAccount/Serviceaccess/MainPage',\n",
    " u'dashboard',\n",
    " u'https://m.vodafone.es/mves/PurchasedProducts/MainScreen',\n",
    " u'Netperform_Privacy_policy',\n",
    " u'purchase',\n",
    " u'url_ayuda',\n",
    " u'https://m.vodafone.es/mves/LineServices/CallOptions/SMSAlert',\n",
    " u'productsandservices',\n",
    " u'https://m.vodafone.es/mves/impersonate',\n",
    " u'https://m.vodafone.es/mves/dashboard',\n",
    " u'https://m.vodafone.es/mves/Promotions/xmas',\n",
    " u'https://m.vodafone.es/mves/myAccount/editPassword',\n",
    " u'https://m.vodafone.es/mves/login/loginSeibelRedirection',\n",
    " u'https://m.vodafone.es/mves/TopUp/currentSpendingHistory',\n",
    " u'MyVodafone_Production/1767',\n",
    " u'gestionar_identificador_llamada',\n",
    " u'ctc_sin_tarifa',\n",
    " u'promo_navidad',\n",
    " u'https://m.vodafone.es/mves/FaultManagement/LandingPage',\n",
    " u'MyVodafone_Production/2052',\n",
    " u'necesitas_mas_ayuda',\n",
    " u'https://m.vodafone.es/mves/serviceSettings/pinpuk',\n",
    " u'mi_cuenta',\n",
    " u'averias',\n",
    " u'\\xbfNecesitas_m\\xe1s_ayuda?',\n",
    " u'push_notification',\n",
    " u'https://m.vodafone.es/mves/FaultManagement/Categories',\n",
    " u'https://m.vodafone.es/mves/myAccount/prefrences',\n",
    " u'https://m.vodafone.es/mves/ecareLanding',\n",
    " u'https://m.vodafone.es/mves/billing/CurrentSpendingConsumptionDetails',\n",
    " u'https://m.vodafone.es/mves/LineServices/CallOptions/Voicemail',\n",
    " u'https://m.vodafone.es/mves/billing/deviceInvoice',\n",
    " u'https://m.vodafone.es/mves/billing/billPaymentDetails',\n",
    " u'https://m.vodafone.es/mves/myAccount/accessInfo',\n",
    " u'https://m.vodafone.es/mves/ProductsAndServices/newChannelList',\n",
    " u'bienvenido_a_destiny',\n",
    " u'red',\n",
    " u'factura',\n",
    " u'internet,_fijo_y_vodafone_one',\n",
    " u'running_speed_test',\n",
    " u'https://m.vodafone.es/mves/FaultManagement/OpenNewTicket',\n",
    " u'https://m.vodafone.es/mves/TopUp/topUpPrepaidservice',\n",
    " u'https://m.vodafone.es/mves/login/orderMangment',\n",
    " u'https://m.vodafone.es/mves/contingency',\n",
    " u'https://m.vodafone.es/mves/serviceSettings/PINPUKManagement',\n",
    " u'ajustes',\n",
    " u'https://m.vodafone.es/mves/myAccount/YourDetails/MainPage',\n",
    " u'https://m.vodafone.es/mves/myAccount/permissionAndPrefrence',\n",
    " u'promo_bf',\n",
    " u'aviso_legal',\n",
    " u'overlay_promo_bf',\n",
    " u'overlay_discover',\n",
    " u'https://m.vodafone.es/mves/billing/billPayment',\n",
    " u'yetalive',\n",
    " u'overlay_offline',\n",
    " u'permisos',\n",
    " u'screen_myrewards',\n",
    " u'https://m.vodafone.es/mves/serviceSettings/thirdPartyLanding',\n",
    " u'https://m.vodafone.es/mves/myAccount/contracts',\n",
    " u'previous_speed_test_results',\n",
    " u'aviso_registro_mi_vodafone.',\n",
    " u'productos_y_servicios',\n",
    " u'https://m.vodafone.es/mves/billing/Abonos',\n",
    " u'webview',\n",
    " u'https://m.vodafone.es/mves/recommender',\n",
    " u'https://m.vodafone.es/mves/billing/BillDetails/DevicesInvoices',\n",
    " u'vodafone',\n",
    " u'avisos_para_rellamadas',\n",
    " u'https://m.vodafone.es/mves/LineServices/Restrictions/MainPage',\n",
    " u'promotions',\n",
    " u'speed_checker_error',\n",
    " u'https://m.vodafone.es/mves/myAccount/Paymethods/MainPage',\n",
    " u'bienvenido',\n",
    " u'miercoyes',\n",
    " u'overlay_no_codes_left',\n",
    " u'need_help',\n",
    " u'mi_vodafone',\n",
    " u'popup_confirmacion_permisos',\n",
    " u'https://m.vodafone.es/mves/Promotions/onboarding',\n",
    " u'Speed_Test_Results',\n",
    " u'aviso',\n",
    " u'llamadas_en_espera',\n",
    " u'https://m.vodafone.es/mves/nuevosBeneficios',\n",
    " u'condiciones_de_uso_del_logado_por_red',\n",
    " u'ocultar_tu_numero',\n",
    " u'https://m.vodafone.es/mves/billing/BillConfigurations',\n",
    " u'registro',\n",
    " u'https://m.vodafone.es/mves/ServiceSettings/PINPUKManagement',\n",
    " u'https://m.vodafone.es/mves/ServiceSettings/RestrictionsThirdPartyLandingPage',\n",
    " u'avisos',\n",
    " u'screen_raffles',\n",
    " u'https://m.vodafone.es/mves/Inbox/InboxListing',\n",
    " u'app_launch',\n",
    " u'https://m.vodafone.es/mves/LineServices/CallOptions/Waiting',\n",
    " u'destiny_migracion_septiembre',\n",
    " u'https://m.vodafone.es/mves/myAccount/gdprConfirmPermission',\n",
    " u'gracias_por_utilizar_mi_vodafone',\n",
    " u'mensajes',\n",
    " u'home',\n",
    " u'opciones_de_llamada',\n",
    " u'ventajas_exclusivas',\n",
    " u'Asistente',\n",
    " u'permission_request',\n",
    " u'https://m.vodafone.es/mves/ProductsAndServices/Extras/Entertainment/Listing',\n",
    " u'igracion_destiny',\n",
    " u'https://m.vodafone.es/mves/billing/BillDetails',\n",
    " u'',\n",
    " u'https://m.vodafone.es/mves/Inbox/details',\n",
    " u'MyVodafone_Production/1822',\n",
    " u'consumo',\n",
    " u'datos_personales',\n",
    " u'registrop',\n",
    " u'ajustes_de_linea',\n",
    " u'https://m.vodafone.es/mves/myAccount/editEmail',\n",
    " u'https://m.vodafone.es/mves/myAccount/otp',\n",
    " u'detalle_de_tarifas',\n",
    " u'https://m.vodafone.es/mves/myAccount/siteSelector',\n",
    " u'FAQs',\n",
    " u'https://m.vodafone.es/mves/ProductsAndServices/combi',\n",
    " u'https://m.vodafone.es/mves/LineServices/MobileConnect',\n",
    " u'https://m.vodafone.es/mves/LineServices/CallOptions/HidemyNumber',\n",
    " u'recargas',\n",
    " u'Previous_Speed_Test_Results',\n",
    " u'https://m.vodafone.es/mves/ProductsAndServices/Prepaidenjoymore/Listing',\n",
    " u'null',\n",
    " u'speed_test_results',\n",
    " u'screen_redeemedrewards',\n",
    " u'contigencia',\n",
    " u'https://m.vodafone.es/mves/billing/billingDetailsServiceUsages',\n",
    " u'https://m.vodafone.es/mves/LineServices/CallOptions/MainPage',\n",
    " u'https://m.vodafone.es/mves/LineServices/CallOptions/Autoredial',\n",
    " u'https://m.vodafone.es/mves/LineServices/VbyVodafone',\n",
    " u'MyVodafone_Production/1970',\n",
    " u'gestion_de_lineas',\n",
    " u'https://m.vodafone.es/mves/billing/noBills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_net.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer = spark.read.load(\"/data/udf/vf_es/amdocs_ids/customer/year=2019/month=9/day=30\")\n",
    "df_customer.where(col(\"num_cliente\")=='462624393').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_service = spark.read.load(\"/data/udf/vf_es/amdocs_ids/service/year=2019/month=9/day=30\")\n",
    "\n",
    "df_service.where(col(\"HOMEZONE\").isNotNull()).select(\"SRV_BASIC\", \"RGU\", \"HOMEZONE\", \"DESC_SRV_BASIC\").distinct().show(100, truncate=False)\n",
    "# +---------+------+--------+\n",
    "# |SRV_BASIC|RGU   |HOMEZONE|\n",
    "# +---------+------+--------+\n",
    "# |TRDNP    |fixed |VFETC   |\n",
    "# |TESTA    |fixed |VFETC   |\n",
    "# |VFETC    |fixed |VFETC   |\n",
    "# |MRPD1    |mobile|VFETC   |\n",
    "# |TESTH    |mobile|VFETC   |\n",
    "# |TESTH    |fixed |VFETC   |\n",
    "# +---------+------+--------+\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_service.where(col(\"HOMEZONE\").isNotNull()).select(\"SRV_BASIC\", \"RGU\", \"HOMEZONE\", \"DESC_SRV_BASIC\").groupby(col(\"SRV_BASIC\"), col(\"HOMEZONE\"), col(\"RGU\")).agg(sql_count(\"*\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_service_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_service_new = spark.read.load(\"/data/udf/vf_es/amdocs_inf_dataset/service/year=2019/month=9/day=21\")\n",
    "\n",
    "df_service_new.where( col(\"Serv_HOMEZONE\").isNotNull() & (col(\"Serv_HOMEZONE\") != \"unknown\")).select(\"Serv_SRV_BASIC\", \"Serv_RGU\", \"Serv_HOMEZONE\", \"Serv_DESC_SRV_BASIC\").groupby(col(\"Serv_SRV_BASIC\"), col(\"Serv_HOMEZONE\"), col(\"Serv_RGU\")).agg(sql_count(\"*\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Services Information...\n"
     ]
    }
   ],
   "source": [
    "closing_day = \"20190930\"\n",
    "import datetime as dt\n",
    "from pyspark.sql.functions import (col, lit, lower, concat, count, max, avg, desc, asc, row_number, lpad, trim, when, split, to_date, coalesce,  isnull)\n",
    "\n",
    "def is_null_date(fecha):\n",
    "    return year(fecha) == 1753\n",
    "\n",
    "from pyspark.sql.functions import  (sum as sql_sum, countDistinct, trim\n",
    "                                    ,max, greatest , split,desc, col, current_date\n",
    "                                    , datediff, lit, translate, udf\n",
    "                                    , when, concat_ws, concat, decode, length\n",
    "                                    , substring, to_date, regexp_replace, lpad\n",
    "                                    , hour, date_format, row_number\n",
    "                                    , expr, coalesce, udf, year)\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "print('Getting Services Information...')\n",
    "data_mapper = spark.read.format('com.databricks.spark.csv').options(header='true', inferschema='true',\n",
    "                                                                    delimiter='|').load('/tmp/rbuendi1/blow/')\n",
    "data_service_ori = (spark.read.load(\"/data/raw/vf_es/customerprofilecar/SERVICESOW/1.1/parquet/\")\n",
    "    # data_service_ori = (spark.read.table(\"raw_es.customerprofilecar_servicesow\")\n",
    "                    .where(\n",
    "    concat(col('year'), lpad(col('month'), 2, '0'), lpad(col('day'), 2, '0')) <= closing_day))\n",
    "\n",
    "data_serviceprice_ori = (spark.read.load(\"/data/raw/vf_es/priceplanstariffs/PLANPRIC_ONO/1.0/parquet/\")\n",
    "    # data_serviceprice_ori = (spark.read.table(\"raw_es.planpric_ono\")\n",
    "                         .where(\n",
    "    concat(col('year'), lpad(col('month'), 2, '0'), lpad(col('day'), 2, '0')) <= closing_day))\n",
    "w_srv = Window().partitionBy(\"OBJID\").orderBy(desc(\"year\"), desc(\"month\"), desc(\"day\"))\n",
    "data_service_ori_norm = (data_service_ori\n",
    "                         .withColumn(\"rowNum\", row_number().over(w_srv))\n",
    "                         .where(col('rowNum') == 1)\n",
    "                         )\n",
    "\n",
    "w_srv_price = Window().partitionBy(\"OBJID\").orderBy(desc(\"year\"), desc(\"month\"), desc(\"day\"))\n",
    "data_serviceprice_ori_norm = (data_serviceprice_ori\n",
    "                              .withColumn(\"rowNum\", row_number().over(w_srv_price))\n",
    "                              .withColumnRenamed('OBJID', 'OBJID2PRICE')\n",
    "                              .withColumnRenamed('PRICE', 'PRICE2PRICE')\n",
    "                              .where(col('rowNum') == 1)\n",
    "                              )\n",
    "# Params Load - In a not so far future it should be loaded from BDP MAESTRO_SERVICIOS\n",
    "LOC_RT_PATH = '/data/udf/vf_es/ref_tables/amdocs_ids/'\n",
    "LOC_RT_EXPORT_MAP = LOC_RT_PATH + 'RBL_EXPORT_MAP.TXT'\n",
    "LOC_RT_PARAM_OW_SERVICES= LOC_RT_PATH + 'PARAM_OW_SERVICES.TXT'\n",
    "data_service_param = spark.read.csv(LOC_RT_PARAM_OW_SERVICES, header=True,sep='\\t')\n",
    "#data_service_param = spark.read.format('com.databricks.spark.csv').options(header='true', inferschema='true',delimiter='\\t').load('/tmp/rbuendi1/PARAM_AMD_DLAB/')\n",
    "data_service_param = (data_service_param.where(col('rgu').isNotNull())\n",
    "  .withColumn('rgu', \n",
    "    when(data_service_param['rgu'] == 'bam-movil', 'bam_mobile')\n",
    "    .when(data_service_param['rgu'] == 'movil', 'mobile')\n",
    "    .otherwise(data_service_param['rgu'])))\n",
    "\n",
    "ClosingDay_date = dt.date(int(closing_day[:4]), int(closing_day[4:6]), int(closing_day[6:8]))\n",
    "yesterday = ClosingDay_date + dt.timedelta(days=-1)\n",
    "\n",
    "data_service_tmp1_basic = (data_service_ori_norm[\n",
    "                               'OBJID', 'NUM_CLIENTE', 'NUM_SERIE', 'COD_SERVICIO', 'ESTADO_SERVICIO', 'FECHA_INST', 'FECHA_CAMB', 'INSTANCIA', 'PRIM_RATE', 'SERVICIOS_ACTUALES2PRICE', 'year', 'month', 'day']\n",
    "                           # .where(col('NUM_CLIENTE')=='758012325')   # aplicamos filtro para muestreo\n",
    "                           .where(((to_date(col('FECHA_CAMB')) >= yesterday)) | (col('FECHA_CAMB').isNull()) | (is_null_date(col('FECHA_CAMB'))))\n",
    "                           .withColumn(\"Instancia_P\", trim(split(data_service_ori_norm.INSTANCIA, '\\\\.')[0]))\n",
    "                           .withColumn(\"Instancia_S\", split(data_service_ori_norm.INSTANCIA, '\\\\.')[1])\n",
    "                           .withColumn(\"TACADA\", concat(col('year'), lpad(col('month'), 2, '0'), lpad(col('day'), 2, '0')))\n",
    "                           .join(data_service_param['COD_SERVICIO', 'DESC_SERVICIO', 'RGU', 'RGU_mobile', 'RGU_BAM', 'TIPO', 'LEGACY'],[\"COD_SERVICIO\"], 'inner')\n",
    "                           .join(data_serviceprice_ori_norm['OBJID2PRICE', 'PRICE2PRICE'],\n",
    "                                 col('SERVICIOS_ACTUALES2PRICE') == col('OBJID2PRICE'), 'leftouter')\n",
    "                           .withColumn('MSISDN',\n",
    "                                       when((col('Instancia_S').isNull() & (col('COD_SERVICIO') == 'TVOTG')),\n",
    "                                            concat(lit('FICT_TVOTG_'), data_service_ori_norm.NUM_CLIENTE))\n",
    "                                       .when((col('Instancia_S').isNull() & (col('COD_SERVICIO') != 'TVOTG')),\n",
    "                                             data_service_ori_norm.NUM_SERIE)\n",
    "                                       .otherwise(lit(None)))\n",
    "                           .withColumn('SERV_PRICE',\n",
    "                                       when((col('PRIM_RATE').isNull()) | (trim(col('PRIM_RATE')) == ''),\n",
    "                                            data_serviceprice_ori_norm.PRICE2PRICE.cast('double'))\n",
    "                                       .otherwise(data_service_ori_norm.PRIM_RATE.cast('double'))\n",
    "                                       )\n",
    "                           )\n",
    "data_service_tmp2_basic = (data_service_tmp1_basic\n",
    "        .groupBy('NUM_CLIENTE', 'Instancia_P')\n",
    "        .agg(\n",
    "        max(col('MSISDN')).alias(\"MSISDN\")\n",
    "        , max(when(col('Instancia_S').isNull(), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"SRV_BASIC\")\n",
    "        , max(when(col('Instancia_S').isNull(), data_service_tmp1_basic.DESC_SERVICIO)\n",
    "              .otherwise(None)).alias(\"DESC_SRV_BASIC\")\n",
    "        , max(when(col('Instancia_S').isNull(), data_service_tmp1_basic.OBJID)\n",
    "              .otherwise(None)).alias(\"OBJID\")\n",
    "        , max(when(col('Instancia_S').isNull(), data_service_tmp1_basic.TACADA)\n",
    "              .otherwise(None)).alias(\"TACADA\")\n",
    "        , max(when(col('Instancia_S').isNull(), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_SRV_BASIC\")\n",
    "        , max(when(col('Instancia_S').isNull(), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_SRV_BASIC\")\n",
    "        , max(when(col('Instancia_S').isNull(), data_service_tmp1_basic.RGU)\n",
    "              .otherwise(None)).alias(\"RGU\")\n",
    "        , max(when((col('TIPO') == 'SIM'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"TIPO_SIM\")\n",
    "        , max(when((col('TIPO') == 'SIM'), data_service_tmp1_basic.NUM_SERIE)\n",
    "              .otherwise(None)).alias(\"IMSI\")\n",
    "        , max(when((col('TIPO') == 'TARIFA'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"TARIFF\")\n",
    "        , max(when((col('TIPO') == 'TARIFA'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_TARIFF\")\n",
    "        , max(when((col('TIPO') == 'TARIFA'), data_service_tmp1_basic.DESC_SERVICIO)\n",
    "              .otherwise(None)).alias(\"DESC_TARIFF\")\n",
    "        , max(when((col('TIPO') == 'TARIFA'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_TARIFF\")\n",
    "        , max(when((col('TIPO') == 'TARIFA_VOZ'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"VOICE_TARIFF\")\n",
    "        , max(when((col('TIPO') == 'TARIFA_VOZ'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_VOICE_TARIFF\")\n",
    "        , max(when((col('TIPO') == 'TARIFA_VOZ'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_VOICE_TARIFF\")\n",
    "        , max(when((col('TIPO') == 'MODULO_DATOS'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"DATA\")\n",
    "        , max(when((col('TIPO') == 'MODULO_DATOS'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_DATA\")\n",
    "        , max(when((col('TIPO') == 'MODULO_DATOS'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_DATA\")\n",
    "        , max(when((col('TIPO').isin('DTO_NIVEL1')), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"DTO_LEV1\")\n",
    "        , max(when((col('TIPO').isin('DTO_NIVEL1')), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_DTO_LEV1\")\n",
    "        , max(when((col('TIPO') == 'DTO_NIVEL1'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_DTO_LEV1\")\n",
    "        , max(when((col('TIPO').isin('DTO_NIVEL2')), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"DTO_LEV2\")\n",
    "        , max(when((col('TIPO').isin('DTO_NIVEL2')), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_DTO_LEV2\")\n",
    "        , max(when((col('TIPO') == 'DTO_NIVEL2'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_DTO_LEV2\")\n",
    "        , max(when((col('TIPO').isin('DTO_NIVEL3')), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"DTO_LEV3\")\n",
    "        , max(when((col('TIPO').isin('DTO_NIVEL3')), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_DTO_LEV3\")\n",
    "        , max(when((col('TIPO') == 'DTO_NIVEL3'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_DTO_LEV3\")\n",
    "        , max(when((col('TIPO').isin('DATOS_ADICIONALES')), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"DATA_ADDITIONAL\")\n",
    "        , max(when((col('TIPO').isin('DATOS_ADICIONALES')), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_DATA_ADDITIONAL\")\n",
    "        , max(when((col('TIPO') == 'DATOS_ADICIONALES'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_DATA_ADDITIONAL\")\n",
    "        , max(when((col('TIPO') == 'OOB'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"OOB\")\n",
    "        , max(when((col('TIPO') == 'OOB'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_OOB\")\n",
    "        , max(when((col('TIPO') == 'OOB'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_OOB\")\n",
    "        , max(when((col('TIPO') == 'NETFLIX_NAPSTER'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"NETFLIX_NAPSTER\")\n",
    "        , max(when((col('TIPO') == 'NETFLIX_NAPSTER'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_NETFLIX_NAPSTER\")\n",
    "        , max(when((col('TIPO') == 'NETFLIX_NAPSTER'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_NETFLIX_NAPSTER\")\n",
    "        , max(when((col('TIPO') == 'ROAMING_BASICO'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"ROAMING_BASIC\")\n",
    "        , max(when((col('TIPO') == 'ROAMING_BASICO'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_ROAMING_BASIC\")\n",
    "        , max(when((col('TIPO') == 'ROAMING_BASICO'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_ROAMING_BASIC\")\n",
    "        , max(when((col('TIPO') == 'ROAM_USA_EUR'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"ROAM_USA_EUR\")\n",
    "        , max(when((col('TIPO') == 'ROAM_USA_EUR'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_ROAM_USA_EUR\")\n",
    "        , max(when((col('TIPO') == 'ROAM_USA_EUR'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_ROAM_USA_EUR\")\n",
    "        , max(when((col('TIPO') == 'ROAM_ZONA_2'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"ROAM_ZONA_2\")\n",
    "        , max(when((col('TIPO') == 'ROAM_ZONA_2'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_ROAM_ZONA_2\")\n",
    "        , max(when((col('TIPO') == 'ROAM_ZONA_2'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_ROAM_ZONA_2\")\n",
    "        , max(when((col('TIPO') == 'CONSUMO_MIN'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"CONSUM_MIN\")\n",
    "        , max(when((col('TIPO') == 'CONSUMO_MIN'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_CONSUM_MIN\")\n",
    "        , max(when((col('TIPO') == 'CONSUMO_MIN'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_CONSUM_MIN\")\n",
    "        , max(when(col('COD_SERVICIO') == 'SIMVF', 1)\n",
    "              .otherwise(0)).alias(\"SIM_VF\")\n",
    "        , max(when((col('TIPO') == 'HOMEZONE'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"HOMEZONE\")\n",
    "        , max(when((col('TIPO') == 'HOMEZONE'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_HOMEZONE\")\n",
    "        , max(when((col('TIPO') == 'HOMEZONE'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_HOMEZONE\")\n",
    "        , max(when((col('TIPO') == 'HOMEZONE'), data_service_tmp1_basic.NUM_SERIE)\n",
    "              .otherwise(None)).alias(\"MOBILE_HOMEZONE\")\n",
    "        , max(when((col('TIPO') == 'UPGRADE'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"FBB_UPGRADE\")\n",
    "        , max(when((col('TIPO') == 'UPGRADE'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_FBB_UPGRADE\")\n",
    "        , max(when((col('TIPO') == 'UPGRADE'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_FBB_UPGRADE\")\n",
    "        , max(when((col('TIPO') == 'DECO'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"DECO_TV\")\n",
    "        , max(when((col('TIPO') == 'DECO'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_DECO_TV\")\n",
    "        , max(when((col('TIPO') == 'DECO'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_DECO_TV\")\n",
    "        , max(when((col('TIPO') == 'DECO'), data_service_tmp1_basic.NUM_SERIE)\n",
    "              .otherwise(None)).alias(\"NUM_SERIE_DECO_TV\")\n",
    "        , max(when((col('TIPO') == 'DECO'), data_service_tmp1_basic.OBJID)\n",
    "              .otherwise(None)).alias(\"OBJID_DECO_TV\")\n",
    "        , max(when((col('TIPO') == 'TVCUOTAALTA'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"TV_CUOTA_ALTA\")\n",
    "        , max(when((col('TIPO') == 'TVCUOTAALTA'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_TV_CUOTA_ALTA\")\n",
    "        , max(when((col('TIPO') == 'TVCUOTAALTA'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_TV_CUOTA_ALTA\")\n",
    "        , max(when((col('TIPO') == 'TV_PLANES_TARIFAS'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"TV_TARIFF\")\n",
    "        , max(when((col('TIPO') == 'TV_PLANES_TARIFAS'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_TV_TARIFF\")\n",
    "        , max(when((col('TIPO') == 'TV_PLANES_TARIFAS'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_TV_TARIFF\")\n",
    "        , max(when((col('TIPO') == 'TV_CUOTASCARGOS'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"TV_CUOT_CHARGES\")\n",
    "        , max(when((col('TIPO') == 'TV_CUOTASCARGOS'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_TV_CUOT_CHARGES\")\n",
    "        , max(when((col('TIPO') == 'TV_CUOTASCARGOS'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_TV_CUOT_CHARGES\")\n",
    "        , max(when((col('TIPO') == 'TVPROMOS'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"TV_PROMO\")\n",
    "        , max(when((col('TIPO') == 'TVPROMOS'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_TV_PROMO\")\n",
    "        , max(when((col('TIPO') == 'TVPROMOS'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_TV_PROMO\")\n",
    "        , max(when((col('TIPO') == 'TVPROMOUSER'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"TV_PROMO_USER\")\n",
    "        , max(when((col('TIPO') == 'TVPROMOUSER'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_TV_PROMO_USER\")\n",
    "        , max(when((col('TIPO') == 'TVPROMOUSER'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_TV_PROMO_USER\")\n",
    "        , max(when((col('TIPO') == 'TV_ABONOS'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"TV_ABONOS\")\n",
    "        , max(when((col('TIPO') == 'TV_ABONOS'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_TV_ABONOS\")\n",
    "        , max(when((col('TIPO') == 'TV_ABONOS'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_TV_ABONOS\")\n",
    "        , max(when((col('TIPO') == 'TV_FIDELIZA'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"TV_LOYALTY\")\n",
    "        , max(when((col('TIPO') == 'TV_FIDELIZA'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_TV_LOYALTY\")\n",
    "        , max(when((col('TIPO') == 'TV_FIDELIZA'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_TV_LOYALTY\")\n",
    "        , max(when((col('TIPO') == 'TV_SVA'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"TV_SVA\")\n",
    "        , max(when((col('TIPO') == 'TV_SVA'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_TV_SVA\")\n",
    "        , max(when((col('TIPO') == 'TV_SVA'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_TV_SVA\")\n",
    "        , max(when((col('TIPO') == 'C_PLUS'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"FOOTBALL_TV\")\n",
    "        , max(when((col('TIPO') == 'C_PLUS'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_FOOTBALL_TV\")\n",
    "        , max(when((col('TIPO') == 'C_PLUS'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_FOOTBALL_TV\")\n",
    "        , max(when((col('TIPO') == 'MOTOR'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"MOTOR_TV\")\n",
    "        , max(when((col('TIPO') == 'MOTOR'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_MOTOR_TV\")\n",
    "        , max(when((col('TIPO') == 'MOTOR'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_MOTOR_TV\")\n",
    "        , max(when((col('TIPO') == 'PVR'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"PVR_TV\")\n",
    "        , max(when((col('TIPO') == 'PVR'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_PVR_TV\")\n",
    "        , max(when((col('TIPO') == 'PVR'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_PVR_TV\")\n",
    "        , max(when((col('TIPO') == 'ZAPPER'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"ZAPPER_TV\")\n",
    "        , max(when((col('TIPO') == 'ZAPPER'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_ZAPPER_TV\")\n",
    "        , max(when((col('TIPO') == 'ZAPPER'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_ZAPPER_TV\")\n",
    "        , max(when((col('TIPO') == 'TRYBUY'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"TRYBUY_TV\")\n",
    "        , max(when((col('TIPO') == 'TRYBUY'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_TRYBUY_TV\")\n",
    "        , max(when((col('TIPO') == 'TRYBUY'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_TRYBUY_TV\")\n",
    "        , max(when((col('TIPO') == 'TRYBUY_AUTOM'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"TRYBUY_AUTOM_TV\")\n",
    "        , max(when((col('TIPO') == 'TRYBUY_AUTOM'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_TRYBUY_AUTOM_TV\")\n",
    "        , max(when((col('TIPO') == 'TRYBUY_AUTOM'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_TRYBUY_AUTOM_TV\")\n",
    "\n",
    "        , max(when((col('TIPO') == 'CINE'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"CINE\")\n",
    "        , max(when((col('TIPO') == 'CINE'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_CINE\")\n",
    "        , max(when((col('TIPO') == 'CINE'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_CINE\")\n",
    "\n",
    "        , max(when((col('TIPO') == 'SERIES'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"SERIES\")\n",
    "        , max(when((col('TIPO') == 'SERIES'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_SERIES\")\n",
    "        , max(when((col('TIPO') == 'SERIES'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_SERIES\")\n",
    "\n",
    "        , max(when((col('TIPO') == 'SERIEFANS'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"SERIEFANS\")\n",
    "        , max(when((col('TIPO') == 'SERIEFANS'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_SERIEFANS\")\n",
    "        , max(when((col('TIPO') == 'SERIEFANS'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_SERIEFANS\")\n",
    "\n",
    "        , max(when((col('TIPO') == 'SERIELOVERS'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"SERIELOVERS\")\n",
    "        , max(when((col('TIPO') == 'SERIELOVERS'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_SERIELOVERS\")\n",
    "        , max(when((col('TIPO') == 'SERIELOVERS'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_SERIELOVERS\")\n",
    "\n",
    "        , max(when((col('TIPO') == 'CINEFANS'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"CINEFANS\")\n",
    "        , max(when((col('TIPO') == 'CINEFANS'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_CINEFANS\")\n",
    "        , max(when((col('TIPO') == 'CINEFANS'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_CINEFANS\")\n",
    "\n",
    "        , max(when((col('TIPO') == 'PEQUES'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"PEQUES\")\n",
    "        , max(when((col('TIPO') == 'PEQUES'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_PEQUES\")\n",
    "        , max(when((col('TIPO') == 'PEQUES'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_PEQUES\")\n",
    "\n",
    "        , max(when((col('TIPO') == 'DOCUMENTALES'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"DOCUMENTALES\")\n",
    "        , max(when((col('TIPO') == 'DOCUMENTALES'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_DOCUMENTALES\")\n",
    "        , max(when((col('TIPO') == 'DOCUMENTALES'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_DOCUMENTALES\")\n",
    "\n",
    "        , max(when((col('TIPO') == 'HBO'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"HBO\")\n",
    "        , max(when((col('TIPO') == 'HBO'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_HBO\")\n",
    "        , max(when((col('TIPO') == 'HBO'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_HBO\")\n",
    "\n",
    "        , max(when((col('TIPO') == 'PROMO_HBO'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"PROMO_HBO\")\n",
    "        , max(when((col('TIPO') == 'PROMO_HBO'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_PROMO_HBO\")\n",
    "        , max(when((col('TIPO') == 'PROMO_HBO'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_PROMO_HBO\")\n",
    "\n",
    "        , max(when((col('TIPO') == 'FILMIN'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"FILMIN\")\n",
    "        , max(when((col('TIPO') == 'FILMIN'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_FILMIN\")\n",
    "        , max(when((col('TIPO') == 'FILMIN'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_FILMIN\")\n",
    "\n",
    "        , max(when((col('TIPO') == 'PROMO_FILMIN'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"PROMO_FILMIN\")\n",
    "        , max(when((col('TIPO') == 'PROMO_FILMIN'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_PROMO_FILMIN\")\n",
    "        , max(when((col('TIPO') == 'PROMO_FILMIN'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_PROMO_FILMIN\")\n",
    "\n",
    "        #VODAFONE PASS\n",
    "        , max(when((col('TIPO') == 'VIDEOHDPASS'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"VIDEOHDPASS\")\n",
    "        , max(when((col('TIPO') == 'VIDEOHDPASS'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_VIDEOHDPASS\")\n",
    "        , max(when((col('TIPO') == 'VIDEOHDPASS'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_VIDEOHDPASS\")\n",
    "\n",
    "        , max(when((col('TIPO') == 'MUSICPASS'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"MUSICPASS\")\n",
    "        , max(when((col('TIPO') == 'MUSICPASS'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_MUSICPASS\")\n",
    "        , max(when((col('TIPO') == 'MUSICPASS'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_MUSICPASS\")\n",
    "\n",
    "        , max(when((col('TIPO') == 'VIDEOPASS'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"VIDEOPASS\")\n",
    "        , max(when((col('TIPO') == 'VIDEOPASS'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_VIDEOPASS\")\n",
    "        , max(when((col('TIPO') == 'VIDEOPASS'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_VIDEOPASS\")\n",
    "\n",
    "        , max(when((col('TIPO') == 'SOCIALPASS'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"SOCIALPASS\")\n",
    "        , max(when((col('TIPO') == 'SOCIALPASS'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_SOCIALPASS\")\n",
    "        , max(when((col('TIPO') == 'SOCIALPASS'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_SOCIALPASS\")\n",
    "\n",
    "        , max(when((col('TIPO') == 'MAPSPASS'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"MAPSPASS\")\n",
    "        , max(when((col('TIPO') == 'MAPSPASS'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_MAPSPASS\")\n",
    "        , max(when((col('TIPO') == 'MAPSPASS'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_MAPSPASS\")\n",
    "\n",
    "        , max(when((col('TIPO') == 'CHATPASS'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"CHATPASS\")\n",
    "        , max(when((col('TIPO') == 'CHATPASS'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_CHATPASS\")\n",
    "        , max(when((col('TIPO') == 'CHATPASS'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_CHATPASS\")\n",
    "\n",
    "        , max(when((col('TIPO') == 'AMAZON'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"AMAZON\")\n",
    "        , max(when((col('TIPO') == 'AMAZON'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_AMAZON\")\n",
    "        , max(when((col('TIPO') == 'AMAZON'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_AMAZON\")\n",
    "\n",
    "        , max(when((col('TIPO') == 'PROMO_AMAZON'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"PROMO_AMAZON\")\n",
    "        , max(when((col('TIPO') == 'PROMO_AMAZON'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_PROMO_AMAZON\")\n",
    "        , max(when((col('TIPO') == 'PROMO_AMAZON'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_PROMO_AMAZON\")\n",
    "\n",
    "        , max(when((col('TIPO') == 'TIDAL'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"TIDAL\")\n",
    "        , max(when((col('TIPO') == 'TIDAL'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_TIDAL\")\n",
    "        , max(when((col('TIPO') == 'TIDAL'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_TIDAL\")\n",
    "\n",
    "        , max(when((col('TIPO') == 'PROMO_TIDAL'), data_service_tmp1_basic.COD_SERVICIO)\n",
    "              .otherwise(None)).alias(\"PROMO_TIDAL\")\n",
    "        , max(when((col('TIPO') == 'PROMO_TIDAL'), data_service_tmp1_basic.FECHA_INST)\n",
    "              .otherwise(None)).alias(\"FX_PROMO_TIDAL\")\n",
    "        , max(when((col('TIPO') == 'PROMO_TIDAL'), data_service_tmp1_basic.SERV_PRICE)\n",
    "              .otherwise(None)).alias(\"PRICE_PROMO_TIDAL\")\n",
    "        )\n",
    "                      )\n",
    "\n",
    "cols_tv_charges = ['PRICE_SRV_BASIC',\\\n",
    "'PRICE_TV_CUOT_CHARGES',\\\n",
    "'PRICE_TV_CUOTA_ALTA',\\\n",
    "'PRICE_DECO_TV',\\\n",
    "'PRICE_TV_TARIFF',\\\n",
    "'PRICE_TV_PROMO',\\\n",
    "'PRICE_TV_PROMO_USER',\\\n",
    "'PRICE_TV_LOYALTY',\\\n",
    "'PRICE_TV_SVA',\\\n",
    "'PRICE_TV_ABONOS',\\\n",
    "'PRICE_TRYBUY_AUTOM_TV',\\\n",
    "'PRICE_TRYBUY_TV',\\\n",
    "'PRICE_ZAPPER_TV',\\\n",
    "'PRICE_PVR_TV',\\\n",
    "'PRICE_MOTOR_TV',\\\n",
    "'PRICE_FOOTBALL_TV',\\\n",
    "'PRICE_CINE',\\\n",
    "'PRICE_SERIES',\\\n",
    "'PRICE_SERIEFANS',\\\n",
    "'PRICE_SERIELOVERS',\\\n",
    "'PRICE_CINEFANS',\\\n",
    "'PRICE_PEQUES',\\\n",
    "'PRICE_DOCUMENTALES']\n",
    "\n",
    "cols_mobile_charges = ['PRICE_SRV_BASIC',\\\n",
    "'PRICE_TARIFF',\\\n",
    "'PRICE_DTO_LEV1',\\\n",
    "'PRICE_DTO_LEV2',\\\n",
    "'PRICE_DTO_LEV3',\\\n",
    "'PRICE_DATA',\\\n",
    "'PRICE_VOICE_TARIFF',\\\n",
    "'PRICE_DATA_ADDITIONAL',\\\n",
    "'PRICE_OOB',\\\n",
    "'PRICE_NETFLIX_NAPSTER',\\\n",
    "'PRICE_ROAM_USA_EUR',\\\n",
    "'PRICE_ROAMING_BASIC',\\\n",
    "'PRICE_ROAM_ZONA_2',\\\n",
    "'PRICE_CONSUM_MIN']\n",
    "\n",
    "data_service_tmp3_basic = (data_service_tmp2_basic\n",
    "                       .withColumn('TV_TOTAL_CHARGES_PREV', sum(coalesce(data_service_tmp2_basic[c], lit(0)) for c in cols_tv_charges))\n",
    "                       .withColumn('MOBILE_BAM_TOTAL_CHARGES_PREV', sum(coalesce(data_service_tmp2_basic[c], lit(0)) for c in cols_mobile_charges))\n",
    "                      )\n",
    "\n",
    "w_srv_2 = Window().partitionBy(\"NUM_CLIENTE\", \"MSISDN\").orderBy(desc(\"TACADA\"))\n",
    "\n",
    "data_service_tmp4_basic = (data_service_tmp3_basic\n",
    "                       .withColumn(\"rowNum\", row_number().over(w_srv_2))\n",
    "                       .where(col('rowNum') == 1)\n",
    "                      )\n",
    "\n",
    "w_srv_3 = Window().partitionBy(\"MSISDN\").orderBy(desc(\"TACADA\"))\n",
    "\n",
    "data_service_tmp5_basic = (data_service_tmp4_basic\n",
    "                       .withColumn(\"rowNum\", row_number().over(w_srv_3))\n",
    "                       .where(col('rowNum') == 1)\n",
    "                       .join(data_mapper, (col(\"OBJID\") == col(\"CAMPO3\")), 'leftouter')\n",
    "                      )\n",
    "\n",
    "data_service_tmp6_basic = (data_service_tmp5_basic\n",
    "                       .withColumn('flag_msisdn_err',\n",
    "                                   when(col('msisdn').like('% '), 1)\n",
    "                                   .otherwise(0))\n",
    "                       .withColumn('msisdn', trim(col('msisdn')))\n",
    "                       .where(col('msisdn').isNotNull())\n",
    "                       .where(col('msisdn') != '')\n",
    "                       .withColumn('TV_TOTAL_CHARGES',\n",
    "                                   when(col('rgu') == 'tv', data_service_tmp5_basic.TV_TOTAL_CHARGES_PREV)\n",
    "                                   .otherwise(0))\n",
    "                       .withColumn('MOBILE_BAM_TOTAL_CHARGES',\n",
    "                                   when(col('rgu').isin('bam', 'bam_mobile', 'mobile'),data_service_tmp5_basic.MOBILE_BAM_TOTAL_CHARGES_PREV)\n",
    "                                   .otherwise(0))\n",
    "                       .drop(col('TV_TOTAL_CHARGES_PREV'))\n",
    "                       .drop(col('MOBILE_BAM_TOTAL_CHARGES_PREV'))\n",
    "                       .drop(col('rowNum'))\n",
    "                      )\n",
    "\n",
    "data_service_tmp6_basic = data_service_tmp6_basic.filter((~isnull(col('NUM_CLIENTE'))) & (~col('NUM_CLIENTE').isin('', ' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+-----------+---------------------------+----------------+-----------+------------------+---------------+-------------------+\n",
      "|SUPEROFERTA|TIPO_DOCUMENTO|NUM_CLIENTE|CLASE_CLI_COD_CLASE_CLIENTE|X_CLIENTE_PRUEBA|NIF_CLIENTE|COD_ESTADO_GENERAL|NIF_FACTURACION|    FECHA_MIGRACION|\n",
      "+-----------+--------------+-----------+---------------------------+----------------+-----------+------------------+---------------+-------------------+\n",
      "|       ON19|        N.I.F.|  954345290|                         RS|               0|  04612449I|                09|      79075358R|1753-01-01 00:10:04|\n",
      "+-----------+--------------+-----------+---------------------------+----------------+-----------+------------------+---------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df_service.where(col(\"OBJID\").isin(\"722163038\",\"945388489\",\"936853265\")).join(spark.read.load(\"/data/udf/vf_es/amdocs_inf_dataset/customer/year=2019/month=9/day=30\"), on=[\"NUM_CLIENTE\"], how=\"inner\").show()\n",
    "from churn.analysis.triggers.base_utils.base_utils import get_customers, get_customers_insights\n",
    "\n",
    "df_c = get_customers_insights(spark, \"20190930\", add_columns=[\"TIPO_DOCUMENTO\", \"X_CLIENTE_PRUEBA\", \"NIF_CLIENTE\"])\n",
    "# df_c.where(col(\"NIF_CLIENTE\").rlike(\"^999\")).groupby(\"TIPO_DOCUMENTO\").agg(sql_count(\"*\")).show()\n",
    "\n",
    "df_c.where(col(\"NUM_CLIENTE\")==\"954345290\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+------+---------+--------------+-----+------+------------+---------------+---+--------+----+------+---------+-----------+------------+------------+---------------+------------------+----+-------+----------+--------+-----------+--------------+--------+-----------+--------------+--------+-----------+--------------+---------------+------------------+---------------------+---+------+---------+---------------+------------------+---------------------+-------------+----------------+-------------------+------------+---------------+------------------+-----------+--------------+-----------------+----------+-------------+----------------+------+--------+-----------+--------------+---------------+-----------+--------------+-----------------+-------+----------+-------------+-----------------+-------------+-------------+----------------+-------------------+---------+------------+---------------+---------------+------------------+---------------------+--------+-----------+--------------+-------------+----------------+-------------------+---------+------------+---------------+----------+-------------+----------------+------+---------+------------+-----------+--------------+-----------------+--------+-----------+--------------+------+---------+------------+---------+------------+---------------+---------+------------+---------------+---------------+------------------+---------------------+----+-------+----------+------+---------+------------+---------+------------+---------------+-----------+--------------+-----------------+--------+-----------+--------------+------+---------+------------+------------+---------------+------------------+---+------+---------+---------+------------+---------------+------+---------+------------+------------+---------------+------------------+-----------+--------------+-----------------+---------+------------+---------------+---------+------------+---------------+----------+-------------+----------------+--------+-----------+--------------+--------+-----------+--------------+------+---------+------------+------------+---------------+------------------+-----+--------+-----------+-----------+--------------+-----------------+------+------+------+---------------+----------------+------------------------+\n",
      "|NUM_CLIENTE|Instancia_P|msisdn|SRV_BASIC|DESC_SRV_BASIC|OBJID|TACADA|FX_SRV_BASIC|PRICE_SRV_BASIC|RGU|TIPO_SIM|IMSI|TARIFF|FX_TARIFF|DESC_TARIFF|PRICE_TARIFF|VOICE_TARIFF|FX_VOICE_TARIFF|PRICE_VOICE_TARIFF|DATA|FX_DATA|PRICE_DATA|DTO_LEV1|FX_DTO_LEV1|PRICE_DTO_LEV1|DTO_LEV2|FX_DTO_LEV2|PRICE_DTO_LEV2|DTO_LEV3|FX_DTO_LEV3|PRICE_DTO_LEV3|DATA_ADDITIONAL|FX_DATA_ADDITIONAL|PRICE_DATA_ADDITIONAL|OOB|FX_OOB|PRICE_OOB|NETFLIX_NAPSTER|FX_NETFLIX_NAPSTER|PRICE_NETFLIX_NAPSTER|ROAMING_BASIC|FX_ROAMING_BASIC|PRICE_ROAMING_BASIC|ROAM_USA_EUR|FX_ROAM_USA_EUR|PRICE_ROAM_USA_EUR|ROAM_ZONA_2|FX_ROAM_ZONA_2|PRICE_ROAM_ZONA_2|CONSUM_MIN|FX_CONSUM_MIN|PRICE_CONSUM_MIN|SIM_VF|HOMEZONE|FX_HOMEZONE|PRICE_HOMEZONE|MOBILE_HOMEZONE|FBB_UPGRADE|FX_FBB_UPGRADE|PRICE_FBB_UPGRADE|DECO_TV|FX_DECO_TV|PRICE_DECO_TV|NUM_SERIE_DECO_TV|OBJID_DECO_TV|TV_CUOTA_ALTA|FX_TV_CUOTA_ALTA|PRICE_TV_CUOTA_ALTA|TV_TARIFF|FX_TV_TARIFF|PRICE_TV_TARIFF|TV_CUOT_CHARGES|FX_TV_CUOT_CHARGES|PRICE_TV_CUOT_CHARGES|TV_PROMO|FX_TV_PROMO|PRICE_TV_PROMO|TV_PROMO_USER|FX_TV_PROMO_USER|PRICE_TV_PROMO_USER|TV_ABONOS|FX_TV_ABONOS|PRICE_TV_ABONOS|TV_LOYALTY|FX_TV_LOYALTY|PRICE_TV_LOYALTY|TV_SVA|FX_TV_SVA|PRICE_TV_SVA|FOOTBALL_TV|FX_FOOTBALL_TV|PRICE_FOOTBALL_TV|MOTOR_TV|FX_MOTOR_TV|PRICE_MOTOR_TV|PVR_TV|FX_PVR_TV|PRICE_PVR_TV|ZAPPER_TV|FX_ZAPPER_TV|PRICE_ZAPPER_TV|TRYBUY_TV|FX_TRYBUY_TV|PRICE_TRYBUY_TV|TRYBUY_AUTOM_TV|FX_TRYBUY_AUTOM_TV|PRICE_TRYBUY_AUTOM_TV|CINE|FX_CINE|PRICE_CINE|SERIES|FX_SERIES|PRICE_SERIES|SERIEFANS|FX_SERIEFANS|PRICE_SERIEFANS|SERIELOVERS|FX_SERIELOVERS|PRICE_SERIELOVERS|CINEFANS|FX_CINEFANS|PRICE_CINEFANS|PEQUES|FX_PEQUES|PRICE_PEQUES|DOCUMENTALES|FX_DOCUMENTALES|PRICE_DOCUMENTALES|HBO|FX_HBO|PRICE_HBO|PROMO_HBO|FX_PROMO_HBO|PRICE_PROMO_HBO|FILMIN|FX_FILMIN|PRICE_FILMIN|PROMO_FILMIN|FX_PROMO_FILMIN|PRICE_PROMO_FILMIN|VIDEOHDPASS|FX_VIDEOHDPASS|PRICE_VIDEOHDPASS|MUSICPASS|FX_MUSICPASS|PRICE_MUSICPASS|VIDEOPASS|FX_VIDEOPASS|PRICE_VIDEOPASS|SOCIALPASS|FX_SOCIALPASS|PRICE_SOCIALPASS|MAPSPASS|FX_MAPSPASS|PRICE_MAPSPASS|CHATPASS|FX_CHATPASS|PRICE_CHATPASS|AMAZON|FX_AMAZON|PRICE_AMAZON|PROMO_AMAZON|FX_PROMO_AMAZON|PRICE_PROMO_AMAZON|TIDAL|FX_TIDAL|PRICE_TIDAL|PROMO_TIDAL|FX_PROMO_TIDAL|PRICE_PROMO_TIDAL|CAMPO1|CAMPO2|CAMPO3|flag_msisdn_err|TV_TOTAL_CHARGES|MOBILE_BAM_TOTAL_CHARGES|\n",
      "+-----------+-----------+------+---------+--------------+-----+------+------------+---------------+---+--------+----+------+---------+-----------+------------+------------+---------------+------------------+----+-------+----------+--------+-----------+--------------+--------+-----------+--------------+--------+-----------+--------------+---------------+------------------+---------------------+---+------+---------+---------------+------------------+---------------------+-------------+----------------+-------------------+------------+---------------+------------------+-----------+--------------+-----------------+----------+-------------+----------------+------+--------+-----------+--------------+---------------+-----------+--------------+-----------------+-------+----------+-------------+-----------------+-------------+-------------+----------------+-------------------+---------+------------+---------------+---------------+------------------+---------------------+--------+-----------+--------------+-------------+----------------+-------------------+---------+------------+---------------+----------+-------------+----------------+------+---------+------------+-----------+--------------+-----------------+--------+-----------+--------------+------+---------+------------+---------+------------+---------------+---------+------------+---------------+---------------+------------------+---------------------+----+-------+----------+------+---------+------------+---------+------------+---------------+-----------+--------------+-----------------+--------+-----------+--------------+------+---------+------------+------------+---------------+------------------+---+------+---------+---------+------------+---------------+------+---------+------------+------------+---------------+------------------+-----------+--------------+-----------------+---------+------------+---------------+---------+------------+---------------+----------+-------------+----------------+--------+-----------+--------------+--------+-----------+--------------+------+---------+------------+------------+---------------+------------------+-----+--------+-----------+-----------+--------------+-----------------+------+------+------+---------------+----------------+------------------------+\n",
      "+-----------+-----------+------+---------+--------------+-----+------+------------+---------------+---+--------+----+------+---------+-----------+------------+------------+---------------+------------------+----+-------+----------+--------+-----------+--------------+--------+-----------+--------------+--------+-----------+--------------+---------------+------------------+---------------------+---+------+---------+---------------+------------------+---------------------+-------------+----------------+-------------------+------------+---------------+------------------+-----------+--------------+-----------------+----------+-------------+----------------+------+--------+-----------+--------------+---------------+-----------+--------------+-----------------+-------+----------+-------------+-----------------+-------------+-------------+----------------+-------------------+---------+------------+---------------+---------------+------------------+---------------------+--------+-----------+--------------+-------------+----------------+-------------------+---------+------------+---------------+----------+-------------+----------------+------+---------+------------+-----------+--------------+-----------------+--------+-----------+--------------+------+---------+------------+---------+------------+---------------+---------+------------+---------------+---------------+------------------+---------------------+----+-------+----------+------+---------+------------+---------+------------+---------------+-----------+--------------+-----------------+--------+-----------+--------------+------+---------+------------+------------+---------------+------------------+---+------+---------+---------+------------+---------------+------+---------+------------+------------+---------------+------------------+-----------+--------------+-----------------+---------+------------+---------------+---------+------------+---------------+----------+-------------+----------------+--------+-----------+--------------+--------+-----------+--------------+------+---------+------------+------------+---------------+------------------+-----+--------+-----------+-----------+--------------+-----------------+------+------+------+---------------+----------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from churn.analysis.triggers.base_utils.base_utils import get_services\n",
    "\n",
    "df_serv = get_services(spark, \"20190930\")\n",
    "\n",
    "df_serv.where(col(\"NUM_CLIENTE\")==\"954345290\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-15f6f778c1cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_serv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MSISDN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"600657317\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/cloudera/parcels/SPARK2/lib/spark2/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \"\"\"\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda-2.5.0/lib/python2.7/site-packages/py4j/java_gateway.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda-2.5.0/lib/python2.7/site-packages/py4j/java_gateway.pyc\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda-2.5.0/lib/python2.7/site-packages/py4j/java_gateway.pyc\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda-2.5.0/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_serv.where(col(\"MSISDN\")==\"600657317\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+------+---------------------------+------+------+-----------+-----+-----------+------------------+---------+\n",
      "|rgu|num_cliente|TARIFF|clase_cli_cod_clase_cliente|msisdn|campo2|Instancia_P|OBJID|nif_cliente|cod_estado_general|srv_basic|\n",
      "+---+-----------+------+---------------------------+------+------+-----------+-----+-----------+------------------+---------+\n",
      "+---+-----------+------+---------------------------+------+------+-----------+-----+-----------+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from churn.analysis.triggers.base_utils.base_utils import get_customers, get_active_services_insights\n",
    "\n",
    "df_active_services = get_active_services_insights(spark, \"20190930\", customer_cols=None, service_cols=[\"TARIFF\", \"OBJID\", \"campo2\", \"Instancia_P\"])#.where(col(\"rgu\")==\"mobile\")\n",
    "#df_active_services = df_active_services.where( ( (col(\"TARIFF\").isNull()) | ((~col(\"TARIFF\").isin(\"DTVC2\", \"DTVC5\")))))\n",
    "\n",
    "df_active_services.where(col(\"NUM_CLIENTE\")==\"954345290\").show()\n",
    "\n",
    "#df_active_services.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DataTemplate] module name = customer_base | path = /data/udf/vf_es/churn_nrt/customer_base | verbose = True\n",
      "[DataTemplate] get_module | Asking module customer_base - for closing_day=20190930 save=False save_others=False\n",
      "[DataTemplate] get_module | args: () | kwargs: {}\n",
      "[CustomerBase] is_default_module | args: () | kwargs: {}\n",
      "[DataTemplate] get_module | Found already an existing module - '/data/udf/vf_es/churn_nrt/customer_base/year=2019/month=9/day=30'\n",
      "+-----------+-----------+------+---+------------------+---------+------+-----------+-------------------+----------------------+------------------+-----------------------+--------------------------+---------------------+-------------------+-----------+---------+-----------------------+----------------+\n",
      "|nif_cliente|NUM_CLIENTE|msisdn|rgu|cod_estado_general|srv_basic|TARIFF|segment_nif|nb_fbb_services_nif|nb_mobile_services_nif|nb_tv_services_nif|nb_prepaid_services_nif|nb_bam_mobile_services_nif|nb_fixed_services_nif|nb_bam_services_nif|nb_rgus_nif|rgus_list|tgs_days_until_f_fin_bi|tgs_has_discount|\n",
      "+-----------+-----------+------+---+------------------+---------+------+-----------+-------------------+----------------------+------------------+-----------------------+--------------------------+---------------------+-------------------+-----------+---------+-----------------------+----------------+\n",
      "+-----------+-----------+------+---+------------------+---------+------+-----------+-------------------+----------------------+------------------+-----------------------+--------------------------+---------------------+-------------------+-----------+---------+-----------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from churn_nrt.src.data.customer_base import CustomerBase\n",
    "from churn_nrt.src.data_utils.base_filters import get_mobile_base\n",
    "df_bd = get_mobile_base(spark, date_=\"20190930\", save=False)\n",
    "df_bd.where(col(\"NUM_CLIENTE\")==\"954345290\").show()\n",
    "#df_bd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_service_tmp1_basic.where( col(\"NUM_CLIENTE\")==\"954345290\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_service_tmp2_basic.where( col(\"NUM_CLIENTE\")==\"954345290\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_service_tmp4_basic.where( col(\"NUM_CLIENTE\")==\"954345290\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_service_tmp6_basic.where( col(\"MSISDN\") == \"600392900\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(spark.read.load(\"/data/raw/vf_es/customerprofilecar/SERVICESOW/1.1/parquet/\").where(concat(col('year'), lpad(col('month'), 2, '0'), lpad(col('day'), 2, '0')) <= closing_day)).where(col(\"num_serie\") == \"600657317\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+------------+---------+--------+-------+----------+----------+-----------+---------------+--------------+----------------+---------------+--------------+--------------+-----------+---------+------------+----------+---------+------------+--------+--------+---------+----------+--------+-------+-----------------+-----------------+--------+-------------+------------------------+---+--------------------+--------------+---------+---------+-----------------+--------+--------+---------+-------+-----------+------------------+---------------+---------------+---------------+-----------------+-----+------+----------+-------------+--------------------+---------------+----+-----+---+\n",
      "|OBJID|NUM_CLIENTE|COD_SERVICIO|INSTANCIA|NUM_PRIM|NUM_ADD|FECHA_INST|FECHA_CAMB|CAMP_ACTIVE|OPE_DIVISION_ID|OPE_EMPRESA_ID|OPE_OPERADORA_ID|ESTADO_SERVICIO|FECHA_INI_CAMP|FECHA_FIN_CAMP|TIPO_PRECIO|PRIM_RATE|PRICE_METHOD|CHARGE_PER|REL_OBJID|PART_ESTATUS|FILLER_1|SERVICIO|NUM_SERIE|PRICE_CODE|RGU_REAL|PAQUETE|FECHA_INI_PAQUETE|FECHA_FIN_PAQUETE|QUANTITY|SUBSCRIBER_ID|SERVICIOS_ACTUALES2PRICE|CUC|NUM_CLIENTE_FICTICIO|VELOCIDAD_REAL|PARAMETRO|cComments|Telefono_asociado|X_Modelo|X_ID_VPN|X_ID_SEDE|X_Marca|X_PROD2PROD|X_FACTURA_CORTESIA|X_ESTADO_DESACT|X_MOTIVO_DESACT|X_PERFIL_DESACT|X_FECHA_MIGRACION|X_IUS|CO_NLS|X_ID_QUOTE|X_PRECIO_PAGO|service_processed_at|service_file_id|year|month|day|\n",
      "+-----+-----------+------------+---------+--------+-------+----------+----------+-----------+---------------+--------------+----------------+---------------+--------------+--------------+-----------+---------+------------+----------+---------+------------+--------+--------+---------+----------+--------+-------+-----------------+-----------------+--------+-------------+------------------------+---+--------------------+--------------+---------+---------+-----------------+--------+--------+---------+-------+-----------+------------------+---------------+---------------+---------------+-----------------+-----+------+----------+-------------+--------------------+---------------+----+-----+---+\n",
      "+-----+-----------+------------+---------+--------+-------+----------+----------+-----------+---------------+--------------+----------------+---------------+--------------+--------------+-----------+---------+------------+----------+---------+------------+--------+--------+---------+----------+--------+-------+-----------------+-----------------+--------+-------------+------------------------+---+--------------------+--------------+---------+---------+-----------------+--------+--------+---------+-------+-----------+------------------+---------------+---------------+---------------+-----------------+-----+------+----------+-------------+--------------------+---------------+----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(spark.read.load(\"/data/raw/vf_es/customerprofilecar/SERVICESOW/1.0/parquet/\").where(concat(col('year'), lpad(col('month'), 2, '0'), lpad(col('day'), 2, '0')) <= closing_day)).where(col(\"NUM_CLIENTE\") == \"954345290\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+------------+----------+--------+-------+-------------------+-------------------+-----------+---------------+--------------+----------------+---------------+-------------------+-------------------+-----------+--------------------+------------+----------+-----------+--------------------+--------+--------+---------+----------+--------------------+--------------------+-------------------+-------------------+--------+-------------+------------------------+---+--------------------+--------------+---------+--------------------+-----------------+--------+--------+---------+-------+-----------+------------------+---------------+---------------+---------------+-------------------+-----+------+----------+--------------------+--------+-----------+--------------+-----------+----------------+------------+-----------------+---------------+----------------+--------------+---------------------+-------------------+--------------------+--------------------+----+-----+---+\n",
      "|      objid|NUM_CLIENTE|COD_SERVICIO| INSTANCIA|NUM_PRIM|NUM_ADD|         FECHA_INST|         FECHA_CAMB|CAMP_ACTIVE|OPE_DIVISION_ID|OPE_EMPRESA_ID|OPE_OPERADORA_ID|ESTADO_SERVICIO|     FECHA_INI_CAMP|     FECHA_FIN_CAMP|TIPO_PRECIO|           PRIM_RATE|PRICE_METHOD|CHARGE_PER|  rel_objid|        PART_ESTATUS|FILLER_1|SERVICIO|NUM_SERIE|PRICE_CODE|            RGU_REAL|             PAQUETE|  FECHA_INI_PAQUETE|  FECHA_FIN_PAQUETE|QUANTITY|SUBSCRIBER_ID|SERVICIOS_ACTUALES2PRICE|CUC|NUM_CLIENTE_FICTICIO|VELOCIDAD_REAL|PARAMETRO|           cComments|Telefono_asociado|X_Modelo|X_ID_VPN|X_ID_SEDE|X_Marca|X_PROD2PROD|X_FACTURA_CORTESIA|X_ESTADO_DESACT|X_MOTIVO_DESACT|X_PERFIL_DESACT|  X_FECHA_MIGRACION|X_IUS|CO_NLS|X_ID_QUOTE|       X_PRECIO_PAGO|ID_IPVPN|CHILD2CONTR|x_almacen_rmca|x_sfid_rmca|x_proveedor_rmca|x_canal_rmca|X_NOMB_PARTNER_TV|X_ID_PARTNER_TV|X_NOMB_CONTENIDO|FLG_WL_ROAMING|X_PERFIL_ACCESO_MOVIL|   FX_ALTA_VODAFONE|service_processed_at|     service_file_id|year|month|day|\n",
      "+-----------+-----------+------------+----------+--------+-------+-------------------+-------------------+-----------+---------------+--------------+----------------+---------------+-------------------+-------------------+-----------+--------------------+------------+----------+-----------+--------------------+--------+--------+---------+----------+--------------------+--------------------+-------------------+-------------------+--------+-------------+------------------------+---+--------------------+--------------+---------+--------------------+-----------------+--------+--------+---------+-------+-----------+------------------+---------------+---------------+---------------+-------------------+-----+------+----------+--------------------+--------+-----------+--------------+-----------+----------------+------------+-----------------+---------------+----------------+--------------+---------------------+-------------------+--------------------+--------------------+----+-----+---+\n",
      "|01024511142|  954345290|       M100C|15        |        |       |2019-08-22 00:00:00|2019-09-02 00:00:00|           |             02|            53|             556|              D|1753-01-01 00:10:04|1753-01-01 00:10:04|           |-0000000000000000...|            |          |00000000000|Desconectado     ...|        |        |         |          |*                ...|Cargo Opcional   ...|1753-01-01 00:10:04|1753-01-01 00:10:04|   +0001|             |               268580328|   |           000000000|              |         |                    |                 |        |        |         |       |           |                 0|               |               |               |1753-01-01 00:10:04|     |      |          |+0000000000000000...|        |          0|              |           |                |            |                 |               |                |             0|                     |2019-08-22 00:00:00|2019-09-05 04:50:...|53b263d0-ac96-482...|2019|    9|  3|\n",
      "|       null|  954345290|       SECUR|6.17      |        |       |2019-09-22 00:00:00|1753-01-01 00:10:04|           |             02|            53|             556|              A|1753-01-01 00:10:04|1753-01-01 00:10:04|           |                    |            |          |       null|Activo           ...|        |        |         |          |M                ...|Voz              ...|1753-01-01 00:10:04|1753-01-01 00:10:04|   +0001|             |               268580005|   |           000000000|              |         |WA SECUR         ...|                 |        |        |         |       |           |                 0|               |               |               |1753-01-01 00:10:04|     |      |          |+0000000000000000...|        | 1024511113|              |           |                |            |                 |               |                |             0|                     |2019-09-22 00:00:00|2019-09-25 04:49:...|410f084d-d41f-451...|2019|    9| 23|\n",
      "+-----------+-----------+------------+----------+--------+-------+-------------------+-------------------+-----------+---------------+--------------+----------------+---------------+-------------------+-------------------+-----------+--------------------+------------+----------+-----------+--------------------+--------+--------+---------+----------+--------------------+--------------------+-------------------+-------------------+--------+-------------+------------------------+---+--------------------+--------------+---------+--------------------+-----------------+--------+--------+---------+-------+-----------+------------------+---------------+---------------+---------------+-------------------+-----+------+----------+--------------------+--------+-----------+--------------+-----------+----------------+------------+-----------------+---------------+----------------+--------------+---------------------+-------------------+--------------------+--------------------+----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(spark.read.load(\"/data/raw/vf_es/customerprofilecar/SERVICESOW/1.1/parquet/\").where(concat(col('year'), lpad(col('month'), 2, '0'), lpad(col('day'), 2, '0')) <= closing_day)).where(col(\"NUM_CLIENTE\") == \"954345290\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closing_day = \"20190930\"\n",
    "\n",
    "data_service_ori = (spark.read.load(\"/data/raw/vf_es/customerprofilecar/SERVICESOW/1.1/parquet/\").where(concat(col('year'), lpad(col('month'), 2, '0'), lpad(col('day'), 2, '0')) <= closing_day))\n",
    "\n",
    "#data_serviceprice_ori = (spark.read.load(\"/data/raw/vf_es/priceplanstariffs/PLANPRIC_ONO/1.0/parquet/\").where(concat(col('year'), lpad(col('month'), 2, '0'), lpad(col('day'), 2, '0')) <= closing_day))\n",
    "w_srv = Window().partitionBy(\"OBJID\").orderBy(desc(\"year\"), desc(\"month\"), desc(\"day\"))\n",
    "data_service_ori_norm = (data_service_ori\n",
    "                         .withColumn(\"rowNum\", row_number().over(w_srv))\n",
    "                         .where(col('rowNum') == 1))\n",
    "(data_service_ori_norm.withColumn(\"Instancia_P\", trim(split(data_service_ori_norm.INSTANCIA, '\\\\.')[0]))\n",
    ".withColumn(\"Instancia_S\", split(data_service_ori_norm.INSTANCIA, '\\\\.')[1])\n",
    ".withColumn('MSISDN',\n",
    "                                       when((col('Instancia_S').isNull() & (col('COD_SERVICIO') == 'TVOTG')),\n",
    "                                            concat(lit('FICT_TVOTG_'), data_service_ori_norm.NUM_CLIENTE))\n",
    "                                       .when((col('Instancia_S').isNull() & (col('COD_SERVICIO') != 'TVOTG')),\n",
    "                                             data_service_ori_norm.NUM_SERIE)\n",
    "                                       .otherwise(lit(None)))).where(col(\"MSISDN\") == \"600657317\").select(\"NUM_CLIENTE\", \"NUM_SERIE\", \"MSISDN\", \"Instancia_P\", \"Instancia_S\", \"COD_SERVICIO\", \"objid\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+----------+-------+----+---------------+------+-------------+\n",
      "|COD_SERVICIO|rgu|RGU_mobile|RGU_BAM|TIPO|PRIMERAS_LINEAS|LEGACY|DESC_SERVICIO|\n",
      "+------------+---+----------+-------+----+---------------+------+-------------+\n",
      "+------------+---+----------+-------+----+---------------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LOC_RT_PATH = '/data/udf/vf_es/ref_tables/amdocs_ids/'\n",
    "LOC_RT_EXPORT_MAP = LOC_RT_PATH + 'RBL_EXPORT_MAP.TXT'\n",
    "LOC_RT_PARAM_OW_SERVICES= LOC_RT_PATH + 'PARAM_OW_SERVICES.TXT'\n",
    "data_service_param = spark.read.csv(LOC_RT_PARAM_OW_SERVICES, header=True,sep='\\t')\n",
    "#data_service_param = spark.read.format('com.databricks.spark.csv').options(header='true', inferschema='true',delimiter='\\t').load('/tmp/rbuendi1/PARAM_AMD_DLAB/')\n",
    "data_service_param = (data_service_param.where(col('rgu').isNotNull())\n",
    "  .withColumn('rgu', \n",
    "    when(data_service_param['rgu'] == 'bam-movil', 'bam_mobile')\n",
    "    .when(data_service_param['rgu'] == 'movil', 'mobile')\n",
    "    .otherwise(data_service_param['rgu'])))\n",
    "\n",
    "data_service_param.where(col(\"COD_SERVICIO\").isin(\"M100C\", \"SECUR\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+----------+-------+-----------+---------------+------+--------------------+\n",
      "|COD_SERVICIO|   rgu|RGU_mobile|RGU_BAM|       TIPO|PRIMERAS_LINEAS|LEGACY|       DESC_SERVICIO|\n",
      "+------------+------+----------+-------+-----------+---------------+------+--------------------+\n",
      "|       MRSUI|mobile|         1|      0|SERV_BASICO|              0|     1|Susp. Impago móvi...|\n",
      "+------------+------+----------+-------+-----------+---------------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_service_param.where(col(\"COD_SERVICIO\").isin(\"MRSUI\")).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+---------------+-------------+--------+----+----------+-----+---------+------+--------------+-----------------+------------+--------+--------+--------+--------+--------+--------+------------+--------+---------+--------+-------+------+-------------+---------------+-------------------------+----------+------+---------+---------+---------+--------------------+---------------+----+-----+---+\n",
      "|COD_SERVICIO|RGU|PARAMETRIZACION|DESC_SERVICIO|PRODUCTO|PESO|REPETICION|CLASE|LIN_EQUIV|AMBITO|AFECTA_PAQUETE|AFECTA_MOVIMIENTO|MEGAPRODUCTO|DETALLE1|DETALLE2|DETALLE3|DETALLE4|DETALLE5|DETALLE6|FORMULA_GGCC|RGF_GGCC|TIPO_PLAN|CONTABLE|TRATADO|TARIFA|OBSERVACIONES|USUARIO_ULT_MOD|FECHA_ULTIMA_MODIFICACION|SUSPENSION|IMPAGO|FAMILY_VF|X_VF_TYPE|X_SUBTIPO|service_processed_at|service_file_id|year|month|day|\n",
      "+------------+---+---------------+-------------+--------+----+----------+-----+---------+------+--------------+-----------------+------------+--------+--------+--------+--------+--------+--------+------------+--------+---------+--------+-------+------+-------------+---------------+-------------------------+----------+------+---------+---------+---------+--------------------+---------------+----+-----+---+\n",
      "+------------+---+---------------+-------------+--------+----+----------+-----+---------+------+--------------+-----------------+------------+--------+--------+--------+--------+--------+--------+------------+--------+---------+--------+-------+------+-------------+---------------+-------------------------+----------+------+---------+---------+---------+--------------------+---------------+----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.load(\"/data/raw/vf_es/customerprofilecar/WEBSERVICES/1.0/parquet\").where(col(\"COD_SERVICIO\").isin(\"M100C\")).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = spark.read.load(\"/data/udf/vf_es/churn_nrt/navcomp/15/year=2020/month=1/day=2\")\n",
    "from churn_nrt.src.utils.pyspark_utils import count_nans\n",
    "\n",
    "A = count_nans(df_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DataTemplate] module name = ccc/msisdn | path = /data/udf/vf_es/churn_nrt/ccc/msisdn | verbose = True\n",
      "[CCC] get_bucket_info | Num entries in bucket: 126855\n",
      "[CCC] get_bucket_info | Elapsed time 1.6561601162 secs \n"
     ]
    }
   ],
   "source": [
    "from churn_nrt.src.data.orders_sla import OrdersSLA\n",
    "df_metadata = OrdersSLA(spark).get_metadata()\n",
    "\n",
    "\n",
    "\n",
    "metadata_cols = df_metadata.rdd.map(lambda x: x['feature']).collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DataTemplate] module name = orders_sla | path = /data/udf/vf_es/churn_nrt/orders_sla | verbose = True\n",
      "OK partition '/data/udf/vf_es/churn_nrt/orders_sla/year=2019/month=10/day=31'\n"
     ]
    }
   ],
   "source": [
    "module_name = \"orders_sla\"\n",
    "\n",
    "if module_name == \"orders_sla\":\n",
    "    from churn_nrt.src.data.orders_sla import OrdersSLA\n",
    "    df_metadata = OrdersSLA(spark).get_metadata()\n",
    "elif module_name == \"customer\":\n",
    "    from churn_nrt.src.data.customer_data import Customer\n",
    "    df_metadata = Customer(spark).get_metadata()\n",
    "elif module_name == \"service\":\n",
    "    from churn_nrt.src.data.service_data import Service\n",
    "    df_metadata = Service(spark).get_metadata()\n",
    "    \n",
    "    \n",
    "ids = [\"msisdn\", \"NUM_CLIENTE\", \"NIF_CLIENTE\"]\n",
    "\n",
    "metadata_cols = df_metadata.rdd.map(lambda x: x['feature']).collect()\n",
    "\n",
    "\n",
    "module_partitions = spark.read.load(\"/data/udf/vf_es/churn_nrt/{}/\".format(module_name)).select(\"year\", \"month\", \"day\").distinct().rdd.map(lambda x: (x['year'], x['month'], x['day'])).collect()\n",
    "\n",
    "for part in module_partitions:\n",
    "    \n",
    "    path_module = \"/data/udf/vf_es/churn_nrt/orders_sla/year={}/month={}/day={}\".format(part[0], part[1], part[2])\n",
    "    module_cols = list(set(spark.read.load(path_module).columns) - set(ids))\n",
    "    \n",
    "    \n",
    "    A = list(set(metadata_cols) - set(module_cols))\n",
    "    B = list(set(module_cols) - set(metadata_cols))\n",
    "    \n",
    "    if A or B:\n",
    "        print(\"ERROR partition '{}'\".format(path_module))\n",
    "        \n",
    "        if A:\n",
    "            print(\"\\t metadata has columns that are not present in module: {}\".format(\",\".join(A)))\n",
    "        if B:\n",
    "            print(\"\\t module has columns that are not present in metadata: {}\".format(\",\".join(B)))\n",
    "        \n",
    "    else:\n",
    "        print(\"OK partition '{}'\".format(path_module))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(metadata_cols) - set(module_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'inc_OTHER_CUSTOMER_INFORMATION_MANAGEMENT_w4vsw4']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[col_ for col_ in metadata_cols if col_ == \"inc_OTHER_CUSTOMER_INFORMATION_MANAGEMENT_w4vsw4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['msisdn']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(module_cols) - set(metadata_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|segment_nif|count(1)|\n",
      "+-----------+--------+\n",
      "|      Other|       3|\n",
      "|Mobile_only| 6002009|\n",
      "+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.load(\"/data/udf/vf_es/churn_nrt/customer_base/year=2020/month=1/day=2\").select(\"segment_nif\").groupby(\"segment_nif\").agg(sql_count(\"*\")).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
