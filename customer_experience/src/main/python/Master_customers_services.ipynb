{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --queue root.datascience.normal  --conf spark.port.maxRetries=50  --conf spark.network.timeout=10000000  --conf spark.executor.heartbeatInterval=60  --conf spark.yarn.executor.memoryOverhead=2G  --conf spark.sql.broadcastTimeout=1200  --master yarn --conf spark.serializer=org.apache.spark.serializer.KryoSerializer --conf spark.kryoserializer.buffer.max=1g --py-files /var/SP/data/home/bbergua/artifacts/bda-core-ra-complete-assembly-2.0.0.jar,/var/SP/data/home/bbergua/artifacts/common.zip,/var/SP/data/home/bbergua/artifacts/graphframes.zip,/var/SP/data/home/bbergua/artifacts/scripts.zip,/var/SP/data/home/bbergua/artifacts/xgboost4j-spark-2.1.1-0.7-jar-with-dependencies.jar --files /var/SP/data/home/bbergua/scripts/properties/red_agent/nodes-de.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/nodes-es.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/nodes-ie.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/nodes-it.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/nodes.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/nodes-pt.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/nodes-uk.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/nodes-ut.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/spark.properties --jars /var/SP/data/home/bbergua/artifacts/bda-core-ra-complete-assembly-2.0.0.jar --conf spark.akka.threads=32 --conf spark.akka.frameSize=500 --conf spark.driver.maxResultSize=8g --conf spark.local.dir=/var/SP/data/home/bbergua/local-spark-dir/  --executor-memory 16g --driver-memory 16g --conf spark.shuffle.manager=tungsten-sort  --queue root.datascience.normal --conf spark.dynamicAllocation.enabled=true --conf spark.shuffle.service.enabled=true --conf spark.dynamicAllocation.maxExecutors=15 --conf spark.dynamicAllocation.minExecutors=1 --conf spark.dynamicAllocation.executorIdleTimeout=120 --files /var/SP/data/home/bbergua/scripts/properties/red_agent/nodes.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/nodes-de.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/nodes-es.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/nodes-ie.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/nodes-it.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/nodes-pt.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/nodes-uk.properties\n",
      " --queue root.datascience.normal  --conf spark.port.maxRetries=50  --conf spark.network.timeout=10000000  --conf spark.executor.heartbeatInterval=60  --conf spark.yarn.executor.memoryOverhead=2G  --conf spark.sql.broadcastTimeout=1200  --master yarn --conf spark.serializer=org.apache.spark.serializer.KryoSerializer --conf spark.kryoserializer.buffer.max=1g --py-files /var/SP/data/home/bbergua/artifacts/bda-core-ra-complete-assembly-2.0.0.jar,/var/SP/data/home/bbergua/artifacts/common.zip,/var/SP/data/home/bbergua/artifacts/graphframes.zip,/var/SP/data/home/bbergua/artifacts/scripts.zip,/var/SP/data/home/bbergua/artifacts/xgboost4j-spark-2.1.1-0.7-jar-with-dependencies.jar --files /var/SP/data/home/bbergua/scripts/properties/red_agent/nodes-de.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/nodes-es.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/nodes-ie.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/nodes-it.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/nodes.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/nodes-pt.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/nodes-uk.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/nodes-ut.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/spark.properties --jars /var/SP/data/home/bbergua/artifacts/bda-core-ra-complete-assembly-2.0.0.jar --conf spark.akka.threads=32 --conf spark.akka.frameSize=500 --conf spark.driver.maxResultSize=8g --conf spark.local.dir=/var/SP/data/home/bbergua/local-spark-dir/  --executor-memory 16g --driver-memory 16g --conf spark.shuffle.manager=tungsten-sort  --queue root.datascience.normal --conf spark.dynamicAllocation.enabled=true --conf spark.shuffle.service.enabled=true --conf spark.dynamicAllocation.maxExecutors=15 --conf spark.dynamicAllocation.minExecutors=1 --conf spark.dynamicAllocation.executorIdleTimeout=120 --files /var/SP/data/home/bbergua/scripts/properties/red_agent/nodes.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/nodes-de.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/nodes-es.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/nodes-ie.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/nodes-it.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/nodes-pt.properties,/var/SP/data/home/bbergua/scripts/properties/red_agent/nodes-uk.properties pyspark-shell \n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from common.src.main.python.utils.hdfs_generic import *\n",
    "import os\n",
    "\n",
    "MAX_N_EXECUTORS=15\n",
    "MIN_N_EXECUTORS=1\n",
    "N_CORES_EXECUTOR=4\n",
    "EXECUTOR_IDLE_MAX_TIME=120\n",
    "EXECUTOR_MEMORY='16g'\n",
    "DRIVER_MEMORY='16g'\n",
    "N_CORES_DRIVER=1\n",
    "MEMORY_OVERHEAD=N_CORES_EXECUTOR*2048\n",
    "QUEUE=\"root.datascience.normal\"\n",
    "BDA_CORE_VERSION=\"1.0.0\"\n",
    "\n",
    "SPARK_COMMON_OPTS=os.environ.get('SPARK_COMMON_OPTS', '')\n",
    "SPARK_COMMON_OPTS+=\" --executor-memory %s --driver-memory %s\" % (EXECUTOR_MEMORY, DRIVER_MEMORY)\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.shuffle.manager=tungsten-sort\"\n",
    "SPARK_COMMON_OPTS+=\"  --queue %s\" % QUEUE\n",
    "\n",
    "# Dynamic allocation configuration\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.dynamicAllocation.enabled=true\"\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.shuffle.service.enabled=true\"\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.dynamicAllocation.maxExecutors=%s\" % (MAX_N_EXECUTORS)\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.dynamicAllocation.minExecutors=%s\" % (MIN_N_EXECUTORS)\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.dynamicAllocation.executorIdleTimeout=%s\" % (EXECUTOR_IDLE_MAX_TIME)\n",
    "\n",
    "BDA_ENV = os.environ.get('BDA_USER_HOME', '')\n",
    "\n",
    "# Attach bda-core-ra codebase\n",
    "SPARK_COMMON_OPTS+=\" --files \\\n",
    "{}/scripts/properties/red_agent/nodes.properties,\\\n",
    "{}/scripts/properties/red_agent/nodes-de.properties,\\\n",
    "{}/scripts/properties/red_agent/nodes-es.properties,\\\n",
    "{}/scripts/properties/red_agent/nodes-ie.properties,\\\n",
    "{}/scripts/properties/red_agent/nodes-it.properties,\\\n",
    "{}/scripts/properties/red_agent/nodes-pt.properties,\\\n",
    "{}/scripts/properties/red_agent/nodes-uk.properties\".format(*[BDA_ENV]*7)\n",
    "\n",
    "os.environ[\"SPARK_COMMON_OPTS\"] = SPARK_COMMON_OPTS\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"%s pyspark-shell \" % SPARK_COMMON_OPTS\n",
    "\n",
    "print os.environ.get('SPARK_COMMON_OPTS', '')\n",
    "print os.environ.get('PYSPARK_SUBMIT_ARGS', '')\n",
    "\n",
    "sc, sparkSession, sqlContext = run_sc()\n",
    "print sc.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import subprocess\n",
    "# Spark utils\n",
    "from pyspark.sql.functions import array_contains, col, collect_set, concat, lit, lpad, size, struct, trim, udf, when\n",
    "from pyspark.sql.types import IntegerType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 2.1.0.cloudera1\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession.builder\n",
    "         .appName(\"VF-ES Master customers services\")\n",
    "         .master(\"yarn\")\n",
    "         .config(\"spark.submit.deployMode\", \"client\")\n",
    "         .config(\"spark.ui.showConsoleProgress\", \"true\")\n",
    "         .enableHiveSupport()\n",
    "         .getOrCreate()\n",
    "         )\n",
    "print 'Spark version:', spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some useful functions for generating customer's segment (Prepaid, Mobile-only, Convergent, and others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace column names of the type 'fun(colname)' by 'fun_colname'\n",
    "# Also replace any character not in [a-zA-Z0-9_.] with '_'\n",
    "def fix_column_names(df):\n",
    "        names = df.schema.names\n",
    "\n",
    "        for n in names:\n",
    "            m = re.search('([^()]*)\\(([^()]*)\\)', n)\n",
    "            if m is not None:\n",
    "                # print m.group(0), '->', m.group(1) + '_' + m.group(2)\n",
    "                df = df.withColumnRenamed(n, m.group(1) + '_' + m.group(2))\n",
    "\n",
    "            m = re.sub('[^a-zA-Z0-9_.]', '_', n)\n",
    "            if n != m:\n",
    "                df = df.withColumnRenamed(n, m)\n",
    "\n",
    "        return df\n",
    "\n",
    "# First of all, we need to aggregate MSISDNs by NIF for Oracle customers, and by NUM_CLIENTE and then by NIF for Ono customers\n",
    "def calculate_vfpos_segment_by_id():\n",
    "        flags_fields = ['flagvoz', 'flagadsl', 'flagftth'] #, 'flaglpd', 'flaghz', 'flagtivo', 'flagvfbox', 'flagfutbol', 'flagmotor']\n",
    "        \n",
    "        data = spark.table('raw_es.vf_pos_ac_final').select(['x_num_ident', 'x_id_red', 'partitioned_month']+flags_fields)\n",
    "        for col in flags_fields:\n",
    "            data = data.withColumn(col, data[col].cast(IntegerType()))\n",
    "\n",
    "        data_by_id = data.groupBy(['x_num_ident', 'partitioned_month']).sum(*flags_fields)\n",
    "        data_by_id = fix_column_names(data_by_id)\n",
    "\n",
    "        # Calculate Mobile-Only\n",
    "        # flags_fixed = ['sum_' + c for c in flags_fields if c != 'flagvoz']\n",
    "        # mo_condition = (data_by_id['sum_flagvoz'] > 0)\n",
    "        # for flag in flags_fixed:\n",
    "        #     if flag in data_by_id.columns:\n",
    "        #         # print 'Adding fixed flag', flag, 'to mo_condition'\n",
    "        #         mo_condition = mo_condition & (data_by_id[flag] == 0)\n",
    "        mo_condition = (data_by_id['sum_flagvoz'] > 0) & (data_by_id['sum_flagadsl'] == 0) | (data_by_id['sum_flagftth'] == 0)\n",
    "        data_by_id = data_by_id.withColumn('is_mobile_only', when(mo_condition, True).otherwise(False))\n",
    "\n",
    "        # Calculate Convergent\n",
    "        # co_condition = None\n",
    "        # for flag in flags_fixed:\n",
    "        #     if flag in data_by_id.columns:\n",
    "        #         # print 'Adding flag', flag, 'to co_condition'\n",
    "        #         if co_condition is None:\n",
    "        #             co_condition = (data_by_id[flag] > 0)\n",
    "        #         else:\n",
    "        #             co_condition = co_condition | (data_by_id[flag] > 0)\n",
    "        # \n",
    "        # co_condition = (data_by_id['sum_flagvoz'] > 0) & co_condition\n",
    "        co_condition = (data_by_id['sum_flagadsl'] > 0) | (data_by_id['sum_flagftth'] > 0)\n",
    "        data_by_id = data_by_id.withColumn('is_convergent', when(co_condition, True).otherwise(False))\n",
    "        \n",
    "        data_by_id = data_by_id.withColumn('SEGMENTACION',   when(mo_condition, lit('Mobile-Only'))\n",
    "                                                            .when(co_condition, lit('Convergent'))\n",
    "                                                            .otherwise(         lit('Other')))\n",
    "\n",
    "        data_by_id = data_by_id.withColumnRenamed('x_num_ident', 'nif')\n",
    "        data_by_id = data_by_id.select(['nif', 'partitioned_month', 'SEGMENTACION']) # , 'is_mobile_only', 'is_convergent'\n",
    "\n",
    "        # data_by_id.filter('is_mobile_only==FALSE AND is_convergent==FALSE').groupby('partitioned_month').count().sort('partitioned_month').show()\n",
    "        # data_by_id.groupby(['partitioned_month', 'SEGMENTACION']).count().sort(['partitioned_month', 'SEGMENTACION']).show(60)\n",
    "\n",
    "        return data_by_id\n",
    "\n",
    "def calculate_vf_segment_by_id():\n",
    "    data_vfpre_by_id = spark.table('raw_es.vf_pre_ac_final').select(['num_documento_comprador', 'partitioned_month']).distinct().withColumnRenamed('num_documento_comprador', 'nif').withColumn('SEGMENTACION', lit('Prepaid')).select('nif', 'partitioned_month', 'SEGMENTACION')\n",
    "    data_vfpos_by_id = calculate_vfpos_segment_by_id()\n",
    "    data_by_id = data_vfpre_by_id.union(data_vfpos_by_id)\n",
    "    \n",
    "    return data_by_id\n",
    "\n",
    "def calculate_vfpos_segment_by_msisdn():\n",
    "    data_by_msisdn = spark.table('raw_es.vf_pos_ac_final').select(['x_num_ident', 'x_id_red', 'partitioned_month']).withColumnRenamed('x_id_red', 'msisdn').withColumnRenamed('x_num_ident', 'nif')\n",
    "    data_by_id = calculate_vfpos_segment_by_id()\n",
    "    data_by_msisdn = data_by_msisdn.join(data_by_id, ['nif', 'partitioned_month'])\n",
    "    data_by_msisdn = data_by_msisdn.select('msisdn', 'nif', 'partitioned_month', 'SEGMENTACION')\n",
    "    \n",
    "    return data_by_msisdn\n",
    "\n",
    "def calculate_vf_segment_by_msisdn():\n",
    "    data_vfpre_by_msisdn = spark.table('raw_es.vf_pre_ac_final').select(['msisdn', 'num_documento_comprador', 'partitioned_month']).distinct().withColumnRenamed('num_documento_comprador', 'nif').withColumn('SEGMENTACION', lit('Prepaid')).select('msisdn', 'nif', 'partitioned_month', 'SEGMENTACION')\n",
    "    data_vfpos_by_msisdn = calculate_vfpos_segment_by_msisdn()\n",
    "    data_by_msisdn = data_vfpre_by_msisdn.union(data_vfpos_by_msisdn)\n",
    "    \n",
    "    return data_by_msisdn\n",
    "\n",
    "# TODO: Ono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+\n",
      "|partitioned_month|  count|\n",
      "+-----------------+-------+\n",
      "|           201801|7054125|\n",
      "|           201712|7453117|\n",
      "|           201711|7607784|\n",
      "|           201710|7585021|\n",
      "|           201709|7530387|\n",
      "|           201708|7484317|\n",
      "|           201707|7466648|\n",
      "|           201706|7508354|\n",
      "|           201705|7415714|\n",
      "|           201704|7420572|\n",
      "|           201703|7425614|\n",
      "|           201702|7449182|\n",
      "|           201701|7414137|\n",
      "|           201612|7338397|\n",
      "|           201611|7269925|\n",
      "|           201610|7268701|\n",
      "|           201609|6921939|\n",
      "|           201608|6900407|\n",
      "+-----------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.table('raw_es.vf_pos_ac_final').groupby('partitioned_month').count().sort('partitioned_month', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+\n",
      "|partitioned_month|  count|\n",
      "+-----------------+-------+\n",
      "|           201801|2708572|\n",
      "|           201712|2730651|\n",
      "|           201711|2777228|\n",
      "|           201710|2825192|\n",
      "|           201709|2821122|\n",
      "|           201708|2821362|\n",
      "|           201707|2884347|\n",
      "|           201706|2874127|\n",
      "|           201705|2871628|\n",
      "|           201704|2886848|\n",
      "|           201703|2916068|\n",
      "|           201702|2965506|\n",
      "|           201701|3022831|\n",
      "|           201612|3030962|\n",
      "|           201611|3049511|\n",
      "|           201610|3082074|\n",
      "|           201609|3115148|\n",
      "|           201608|3111525|\n",
      "+-----------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.table('raw_es.vf_pre_ac_final').groupby('partitioned_month').count().sort('partitioned_month', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+-------+\n",
      "|partitioned_month|SEGMENTACION|  count|\n",
      "+-----------------+------------+-------+\n",
      "|           201801| Mobile-Only|6921064|\n",
      "|           201801|     Prepaid|2708572|\n",
      "|           201801|  Convergent| 133061|\n",
      "|           201712| Mobile-Only|7315910|\n",
      "|           201712|     Prepaid|2730651|\n",
      "|           201712|  Convergent| 137207|\n",
      "|           201711| Mobile-Only|7471965|\n",
      "|           201711|     Prepaid|2777228|\n",
      "|           201711|  Convergent| 135819|\n",
      "|           201710| Mobile-Only|7452674|\n",
      "|           201710|     Prepaid|2825192|\n",
      "|           201710|  Convergent| 132347|\n",
      "|           201709| Mobile-Only|7398248|\n",
      "|           201709|     Prepaid|2821122|\n",
      "|           201709|  Convergent| 132139|\n",
      "|           201708| Mobile-Only|7353473|\n",
      "|           201708|     Prepaid|2821362|\n",
      "|           201708|  Convergent| 130844|\n",
      "|           201707| Mobile-Only|7335495|\n",
      "|           201707|     Prepaid|2884347|\n",
      "+-----------------+------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "master_by_msisdn = calculate_vf_segment_by_msisdn()\n",
    "master_by_msisdn.groupby('partitioned_month', 'SEGMENTACION').count() \\\n",
    "                .sort('partitioned_month', 'count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_by_msisdn.write.mode('overwrite').format('parquet').save('/tmp/bbergua/master_customers_services/msisdn/')\n",
    "subprocess.call('hdfs dfs -chmod -R o+rx /tmp/bbergua/master_customers_services/msisdn/',  shell=True)\n",
    "subprocess.call('hdfs dfs -chmod    o+r  /tmp/bbergua/master_customers_services/msisdn/*', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+-------+\n",
      "|partitioned_month|SEGMENTACION|  count|\n",
      "+-----------------+------------+-------+\n",
      "|           201801| Mobile-Only|2874140|\n",
      "|           201801|     Prepaid|2247113|\n",
      "|           201801|  Convergent|  55616|\n",
      "|           201712| Mobile-Only|3228366|\n",
      "|           201712|     Prepaid|2267022|\n",
      "|           201712|  Convergent|  57290|\n",
      "|           201711| Mobile-Only|3410091|\n",
      "|           201711|     Prepaid|2303454|\n",
      "|           201711|  Convergent|  55737|\n",
      "|           201710| Mobile-Only|3433925|\n",
      "|           201710|     Prepaid|2339810|\n",
      "|           201710|  Convergent|  53180|\n",
      "|           201709| Mobile-Only|3452036|\n",
      "|           201709|     Prepaid|2329992|\n",
      "|           201709|  Convergent|  53063|\n",
      "|           201708| Mobile-Only|3468005|\n",
      "|           201708|     Prepaid|2324060|\n",
      "|           201708|  Convergent|  52475|\n",
      "|           201707| Mobile-Only|3486883|\n",
      "|           201707|     Prepaid|2376711|\n",
      "+-----------------+------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "master_by_id = calculate_vf_segment_by_id()\n",
    "master_by_id.groupby('partitioned_month', 'SEGMENTACION').count() \\\n",
    "            .sort('partitioned_month', 'count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-------+\n",
      "|partitioned_month|        SEGMENTACION|  count|\n",
      "+-----------------+--------------------+-------+\n",
      "|           201801|       [Mobile-Only]|2634156|\n",
      "|           201801|           [Prepaid]|2001019|\n",
      "|           201801|[Mobile-Only, Pre...| 239984|\n",
      "|           201801|        [Convergent]|  49506|\n",
      "|           201801|[Convergent, Prep...|   6110|\n",
      "|           201712|       [Mobile-Only]|2963508|\n",
      "|           201712|           [Prepaid]|1995780|\n",
      "|           201712|[Mobile-Only, Pre...| 264858|\n",
      "|           201712|        [Convergent]|  50906|\n",
      "|           201712|[Convergent, Prep...|   6384|\n",
      "|           201711|       [Mobile-Only]|3134593|\n",
      "|           201711|           [Prepaid]|2021636|\n",
      "|           201711|[Mobile-Only, Pre...| 275498|\n",
      "|           201711|        [Convergent]|  49417|\n",
      "|           201711|[Convergent, Prep...|   6320|\n",
      "|           201710|       [Mobile-Only]|3151842|\n",
      "|           201710|           [Prepaid]|2051523|\n",
      "|           201710|[Mobile-Only, Pre...| 282083|\n",
      "|           201710|        [Convergent]|  46976|\n",
      "|           201710|[Convergent, Prep...|   6204|\n",
      "+-----------------+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "master_by_id_seg = master_by_id.select('nif', 'partitioned_month', 'SEGMENTACION') \\\n",
    "    .groupby('nif', 'partitioned_month').agg(collect_set('SEGMENTACION').alias('SEGMENTACION'))\n",
    "#master_by_id_seg.show()\n",
    "master_by_id_seg.groupby('partitioned_month', 'SEGMENTACION').count() \\\n",
    "                .sort('partitioned_month', 'count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_by_id.write.mode('overwrite').format('parquet').save('/tmp/bbergua/master_customers_services/id/')\n",
    "subprocess.call('hdfs dfs -chmod -R o+rx /tmp/bbergua/master_customers_services/id/',  shell=True)\n",
    "subprocess.call('hdfs dfs -chmod    o+r  /tmp/bbergua/master_customers_services/id/*', shell=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
