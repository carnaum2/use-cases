{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vodafone COPS. Model designing & training. Distributed version using Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Spark Initialization\n",
    "\n",
    "from common.src.main.python.utils.hdfs_generic import *\n",
    "import os\n",
    "MAX_N_EXECUTORS=15\n",
    "MIN_N_EXECUTORS=1\n",
    "N_CORES_EXECUTOR=4\n",
    "EXECUTOR_IDLE_MAX_TIME=120\n",
    "EXECUTOR_MEMORY='32g'\n",
    "DRIVER_MEMORY='32g'\n",
    "N_CORES_DRIVER=1\n",
    "MEMORY_OVERHEAD=N_CORES_EXECUTOR*2048\n",
    "QUEUE=\"root.datascience.normal\"\n",
    "BDA_CORE_VERSION=\"1.0.0\"\n",
    "SPARK_COMMON_OPTS=os.environ.get('SPARK_COMMON_OPTS', '')\n",
    "SPARK_COMMON_OPTS+=\" --executor-memory %s --driver-memory %s\" % (EXECUTOR_MEMORY, DRIVER_MEMORY)\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.shuffle.manager=tungsten-sort\"\n",
    "SPARK_COMMON_OPTS+=\" --queue %s\" % QUEUE\n",
    "# Dynamic allocation configuration\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.dynamicAllocation.enabled=true\"\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.shuffle.service.enabled=true\"\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.dynamicAllocation.maxExecutors=%s\" % (MAX_N_EXECUTORS)\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.dynamicAllocation.minExecutors=%s\" % (MIN_N_EXECUTORS)\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.dynamicAllocation.executorIdleTimeout=%s\" % (EXECUTOR_IDLE_MAX_TIME)\n",
    "\n",
    "BDA_ENV = os.environ.get('BDA_USER_HOME', '')\n",
    "\n",
    "# Attach bda-core-ra codebase\n",
    "SPARK_COMMON_OPTS+=\" --files \\\n",
    "{}/scripts/properties/red_agent/nodes.properties,\\\n",
    "{}/scripts/properties/red_agent/nodes-de.properties,\\\n",
    "{}/scripts/properties/red_agent/nodes-es.properties,\\\n",
    "{}/scripts/properties/red_agent/nodes-ie.properties,\\\n",
    "{}/scripts/properties/red_agent/nodes-it.properties,\\\n",
    "{}/scripts/properties/red_agent/nodes-pt.properties,\\\n",
    "{}/scripts/properties/red_agent/nodes-uk.properties\".format(*[BDA_ENV]*7)\n",
    "\n",
    "os.environ[\"SPARK_COMMON_OPTS\"] = SPARK_COMMON_OPTS\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"%s pyspark-shell \" %SPARK_COMMON_OPTS\n",
    "\n",
    "sc, sparkSession, sqlContext = run_sc()\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"Vodafone COPS\")\n",
    "         .master(\"yarn\")\n",
    "         .config(\"spark.submit.deployMode\", \"client\")\n",
    "         .config(\"spark.ui.showConsoleProgress\", \"true\")\n",
    "         .enableHiveSupport()\n",
    "         .getOrCreate()\n",
    "         )\n",
    "\n",
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import json\n",
    "import random\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "from itertools import chain\n",
    "from pyspark import keyword_only\n",
    "from pyspark.ml import Pipeline, PipelineModel, Transformer\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder, StandardScaler\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol\n",
    "from pyspark.sql.functions import mean, desc, regexp_replace, udf\n",
    "from pyspark.sql.types import StringType\n",
    "from __future__ import print_function, division\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "%matplotlib inline\n",
    "%autosave 60\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 20, 10\n",
    "plt.rcParams['axes.titlesize'] = 24\n",
    "plt.rcParams['axes.labelsize'] = 20\n",
    "plt.rcParams['xtick.labelsize'] = 16\n",
    "plt.rcParams['ytick.labelsize'] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Utilities\n",
    "\n",
    "def get_mean(sparkdf, colname):\n",
    "    \"\"\"\n",
    "    Calculate the mean of a Spark DataFrame column\n",
    "    and retunrs value as float.\n",
    "    \"\"\"\n",
    "    logging.info(\"Computing mean of column {colname}\".format(colname=colname))\n",
    "    mean_row = sparkdf.select(mean(sparkdf[colname])).first()\n",
    "    mean_value = mean_row['avg({colname})'.format(colname=colname)]\n",
    "    return mean_value\n",
    "\n",
    "def load_train_params():\n",
    "    \"\"\"\n",
    "    Loads training params json file from disk.\n",
    "    \"\"\"\n",
    "    logging.info(\"Loading training params...\")\n",
    "    with open('./train_params.json', 'r') as json_file:\n",
    "        train_params = json.loads(json_file.read())\n",
    "        return train_params\n",
    "\n",
    "def save_train_params(train_params_dict):\n",
    "    \"\"\"\n",
    "    Saves training params to json file in disk.\n",
    "    \"\"\"\n",
    "    logging.info(\"Saving training params...\")\n",
    "    with open('./train_params.json', 'w') as json_file:\n",
    "        json.dump(train_params_dict, json_file)\n",
    "\n",
    "# Spark User Defined Function to replace null strings\n",
    "empty_string_filter = udf(lambda string: 'null_value' if string == '' else string, StringType())\n",
    "\n",
    "def clean(sparkdf, \n",
    "          string_cols_imput_null, \n",
    "          numeric_cols_imput_mean, \n",
    "          numeric_cols_imput_zero, \n",
    "          refresh=False):\n",
    "    \"\"\"\n",
    "    Performs previous cleaning using stored parameters (means to replace, most frequent value).\n",
    "    In case there is no stored parameters, it computes needed info and save in disk.\n",
    "    \"\"\"\n",
    "    logging.info(\"Cleaning data...\")\n",
    "    if refresh:\n",
    "        train_params = dict()\n",
    "    else:\n",
    "        try:\n",
    "            train_params = load_train_params()\n",
    "        except Exception:\n",
    "            logging.error(\"No training params found! Creating empty params dict...\")\n",
    "            train_params = dict()\n",
    "    sparkdf = sparkdf.fillna('null_value', subset=string_cols_imput_null)\n",
    "    sparkdf = sparkdf.fillna(0, subset=numeric_cols_imput_zero)\n",
    "    for col in string_cols_imput_null:\n",
    "        sparkdf = sparkdf.withColumn(col, empty_string_filter(sparkdf[col]))\n",
    "    for col in numeric_cols_imput_mean:\n",
    "        try:\n",
    "            col_params = train_params[col]\n",
    "        except KeyError:\n",
    "            logging.error(\"No training parameters found for this column! Creating empty params dict...\")\n",
    "            col_params = dict()\n",
    "            train_params[col] = col_params\n",
    "        try:\n",
    "            mean_value = col_params['mean']\n",
    "        except KeyError:\n",
    "            mean_value = get_mean(sparkdf, col)\n",
    "            col_params['mean'] = mean_value\n",
    "        sparkdf = sparkdf.fillna(mean_value)\n",
    "    save_train_params(train_params)\n",
    "    return sparkdf\n",
    "\n",
    "def plot_roc(true_labels, scores):\n",
    "    fpr, tpr, thr = roc_curve(true_labels, scores)\n",
    "    area_under_curve = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, \n",
    "             tpr, \n",
    "             color='darkorange',\n",
    "             label='ROC curve (area = %0.2f)' % area_under_curve)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "It creates a balanced Spark DataFrame readinf Analytics Datamart in tests_es.dacc_analytics_panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Analytics panel load\n",
    "\n",
    "string_cols_imput_null = ['data_plan_c', 'voice_plan_c', 'promo_code_vf', 'promo_code_tarif', 'zip_code', 'region_code',\n",
    "                          'gender', 'type_ident', 'nationality']\n",
    "\n",
    "numeric_cols_imput_mean = ['n_lines', 'n_lines_pre', 'n_lines_post', 'age', 'months_to_end_promo_tarif', \n",
    "                           'months_to_end_promo_vf']\n",
    "\n",
    "numeric_cols_imput_zero = ['voice_plan_change', 'data_plan_change', 'n_calls_billing_c', 'n_calls_billing_c_minus_1', \n",
    "                           'n_calls_churn_c', 'n_calls_churn_c_minus_1', 'n_calls_tariff_c', 'n_calls_tariff_c_minus_1', \n",
    "                           'n_calls_dsl_inc_c', 'n_calls_dsl_inc_c_minus_1', 'n_calls_mobile_inc_c', \n",
    "                           'n_calls_mobile_inc_c_minus_1', 'n_calls_device_upgr_c', 'n_calls_device_upgr_c_minus_1', \n",
    "                           'n_calls_device_del_rep_c', 'n_calls_device_del_rep_c_minus_1', 'n_calls_new_adds_c',\n",
    "                           'n_calls_new_adds_c_minus_1', 'n_calls_ser_man_c', 'n_calls_ser_man_c_minus_1']\n",
    "\n",
    "targetcol = 'n_calls_billing_c_plus_1'\n",
    "\n",
    "datamart_name = 'tests_es.dacc_cops_datamart'\n",
    "\n",
    "featurecols = ','.join(string_cols_imput_null + numeric_cols_imput_mean + numeric_cols_imput_zero)\n",
    "\n",
    "sql_positive = \"\"\"\n",
    "select\n",
    "billing_cycle_id,\n",
    "{featurecols},\n",
    "1 as label\n",
    "from {datamart}\n",
    "where {targetcol} > 0\n",
    "\"\"\".format(featurecols=featurecols, targetcol=targetcol, datamart=datamart_name)\n",
    "\n",
    "sql_negative = \"\"\"\n",
    "select\n",
    "billing_cycle_id,\n",
    "{featurecols},\n",
    "0 as label\n",
    "from {datamart}\n",
    "where {targetcol} = 0\n",
    "\"\"\".format(featurecols=featurecols, targetcol=targetcol, datamart=datamart_name)\n",
    "\n",
    "analytics_panel_positive = spark.sql(sql_positive)\n",
    "analytics_panel_negative_full = spark.sql(sql_negative)\n",
    "whole_data = analytics_panel_positive.union(analytics_panel_negative_full)\n",
    "sample_fraction = analytics_panel_positive.count() / analytics_panel_negative_full.count()\n",
    "analytics_panel_negative = analytics_panel_negative_full.sample(False, sample_fraction)\n",
    "analytics_panel = analytics_panel_positive.union(analytics_panel_negative)\n",
    "\n",
    "analytics_panel[['billing_cycle_id', 'n_calls_billing_c', 'n_calls_billing_c_minus_1', 'label']].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logging.info(\"Defining Train - Test split...\")\n",
    "train = analytics_panel.where('billing_cycle_id < 20171201')\n",
    "test_1 = whole_data.where('billing_cycle_id >= 20171201 and billing_cycle_id < 20180101')\n",
    "test_2 = whole_data.where('billing_cycle_id >= 20180101 and billing_cycle_id < 20180201')\n",
    "\n",
    "# logging.info(\"Saving data to csv to testing and processing outside this notebook...\")\n",
    "# train.toPandas().to_csv('./data/train.csv', encoding='utf-8')\n",
    "# test_1.toPandas().to_csv('./data/test_1.csv', encoding='utf-8')\n",
    "# test_2.toPandas().to_csv('./data/test_2.csv', encoding='utf-8')\n",
    "\n",
    "# Set refresh=True for train if data changes\n",
    "logging.info(\"Performing cleaning to train and test sets...\")\n",
    "train = clean(train, string_cols_imput_null, numeric_cols_imput_mean, numeric_cols_imput_zero, refresh=False)\n",
    "test_1 = clean(test_1, string_cols_imput_null, numeric_cols_imput_mean, numeric_cols_imput_zero, refresh=False)\n",
    "test_2 = clean(test_2, string_cols_imput_null, numeric_cols_imput_mean, numeric_cols_imput_zero, refresh=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Number of training observations: {n}'.format(n=train.count()))\n",
    "print('Number of test set 1 observations: {n}'.format(n=test_1.count()))\n",
    "print('Number of test set 2 observations: {n}'.format(n=test_2.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Indexers + Encoders for categorical columns\n",
    "\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=col + '_index', handleInvalid='skip') for col in string_cols_imput_null]\n",
    "\n",
    "encoders = [OneHotEncoder(inputCol=col + '_index', outputCol=col + '_vect') for col in string_cols_imput_null]\n",
    "\n",
    "# Features data assembly\n",
    "\n",
    "featurecols = numeric_cols_imput_zero + numeric_cols_imput_mean + [col + '_vect' for col in string_cols_imput_null]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=featurecols,\n",
    "    \n",
    "    outputCol=\"features\")\n",
    "\n",
    "# Data normalization\n",
    "\n",
    "# Standarization\n",
    "standarizer = StandardScaler(inputCol=\"features\", outputCol=\"normFeatures\")\n",
    "\n",
    "# Model\n",
    "lr = LogisticRegression(featuresCol=\"normFeatures\")\n",
    "\n",
    "# Standarization included in algorithm\n",
    "\n",
    "stages = indexers + encoders + [assembler] + [standarizer] + [lr]\n",
    "# stages = indexers + encoders + [assembler] + [lr]\n",
    "\n",
    "pipeline_lr = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model training and tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters settings\n",
    "regparam_max = 0.5\n",
    "regparam_min = 0.0\n",
    "regparam_n = 10\n",
    "elasticnetparam_max = 1.0\n",
    "elasticnetparam_min = 0.0\n",
    "elasticnetparam_n = 5\n",
    "\n",
    "regparam_values = np.linspace(regparam_min, regparam_max, regparam_n)\n",
    "elasticnetparam_values = np.linspace(elasticnetparam_min, elasticnetparam_max, elasticnetparam_n)\n",
    "\n",
    "# Search Grid definition\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.regParam, regparam_values)\\\n",
    "    .addGrid(lr.elasticNetParam, elasticnetparam_values)\\\n",
    "    .addGrid(lr.fitIntercept, [False, True])\\\n",
    "    .build()\n",
    "\n",
    "# Validation Split definition\n",
    "tvs = TrainValidationSplit(estimator=pipeline_lr, \n",
    "                           estimatorParamMaps=paramGrid, \n",
    "                           evaluator=BinaryClassificationEvaluator(metricName='areaUnderROC'), \n",
    "                           trainRatio=0.8)\n",
    "\n",
    "# Model training\n",
    "logging.info(\"Training model {n} times... better grab a coffee or go doing something else :-D\".format(n=elasticnetparam_n*regparam_n))\n",
    "model_lr = tvs.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_model_lr = model_lr.bestModel\n",
    "print(\"Best regularization parameter: {regparam}\".format(regparam=best_model_lr.stages[-1]._java_obj.getRegParam()))\n",
    "print(\"Best elasticnet parameter: {elasticnetparam}\".format(elasticnetparam=best_model_lr.stages[-1]._java_obj.getElasticNetParam()))\n",
    "print(\"Best elasticnet parameter: {fitintercept}\".format(fitintercept=best_model_lr.stages[-1]._java_obj.getFitIntercept()))\n",
    "#print(\"Best model training AUC: {AUC}\".format(AUC=best_model_lr.stages[-1].summary.areaUnderROC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logging.info(\"Saving model to hdfs...\")\n",
    "best_model_lr.write().overwrite().save('./cops/output/model.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logging.info(\"Loading model to hdfs...\")\n",
    "best_model_lr = PipelineModel.load('./cops/output/model.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model performance testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logging.info(\"Computing predictions for tests set 1\")\n",
    "predictions_1 = best_model_lr.transform(test_1)[['rawPrediction', 'probability', 'prediction', 'label']]\n",
    "logging.info(\"Computing predictions for tests set 2\")\n",
    "predictions_2 = best_model_lr.transform(test_2)[['rawPrediction', 'probability', 'prediction', 'label']]\n",
    "\n",
    "logging.info(\"Saving predictions as parquet files...\")\n",
    "predictions_1.write.mode('overwrite').csv(\"/user/adesant3/cops/data/test_1_pred.csv\")\n",
    "predictions_2.write.mode('overwrite').csv(\"/user/adesant3/cops/data/test_2_pred.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model Most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrm = best_model_lr.stages[-1]\n",
    "attrs = sorted((attr['idx'], attr['name']) for attr in chain(*predictions_1.schema['features'].metadata['ml_attr']['attrs'].values()))\n",
    "coeffs_importance = [(name, lrm.coefficients[idx]) for idx, name in attrs[:]]\n",
    "coefficients_importance = pd.DataFrame(columns=['coef', 'coef_value'], data=coeffs_importance).sort_values('coef_value', ascending=False)\n",
    "coefficients_importance.to_csv('./coefficients_importance.csv', encoding='utf-8')\n",
    "display(coefficients_importance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
