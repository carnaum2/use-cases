{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20200211-160429 [INFO ] Logging to file /var/SP/data/home/csanc109/logging/out_20200211_160429.log\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import datetime as dt\n",
    "DEVEL_SRC = os.path.join(os.environ.get('BDA_USER_HOME', ''), \"src\", \"devel\")\n",
    "if DEVEL_SRC not in sys.path:\n",
    "    sys.path.append(DEVEL_SRC)\n",
    "\n",
    "USECASES_SRC = os.path.join(DEVEL_SRC, \"use-cases\") # TODO when - is removed, remove also this line and adapt imports\n",
    "if USECASES_SRC not in sys.path: \n",
    "    sys.path.append(USECASES_SRC)\n",
    "    \n",
    "AMDOCS_SRC = os.path.join(DEVEL_SRC, \"amdocs_informational_dataset\") # TODO when - is removed, remove also this line and adapt imports\n",
    "if AMDOCS_SRC not in sys.path: \n",
    "    sys.path.append(AMDOCS_SRC)\n",
    "    \n",
    "import pykhaos.utils.custom_logger as clogger\n",
    "logging_file = os.path.join(os.environ.get('BDA_USER_HOME', ''), \"logging\",\n",
    "                                    \"out_\" + dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + \".log\")\n",
    "logger = clogger.configure_logger(log_filename=logging_file, std_channel=sys.stderr, logger_name=\"\")\n",
    "logger.info(\"Logging to file {}\".format(logging_file))    \n",
    "    \n",
    "#EXTERNAL_PATH = os.path.join(os.environ.get('BDA_USER_HOME', ''), \"src\", \"devel\", \"pykhaos\", \"external_lib\")\n",
    "EXTERNAL_PATH = \"/var/SP/data/bdpmdses/churn/lib\"\n",
    "if EXTERNAL_PATH not in sys.path:\n",
    "    sys.path.append(EXTERNAL_PATH)\n",
    "\n",
    "import logging\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "\n",
    "    \n",
    "import pykhaos.utils.notebooks as nb\n",
    "\n",
    "\n",
    "RUNNING_FROM_NOTEBOOK = nb.isnotebook()\n",
    "import matplotlib.pyplot as plt\n",
    "if RUNNING_FROM_NOTEBOOK:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    %matplotlib inline  \n",
    "    \n",
    "    \n",
    "    \n",
    "#logger = my_project.logger\n",
    "\n",
    "if not RUNNING_FROM_NOTEBOOK:\n",
    "    args = my_project.arg_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "app_name = \"scores\"\n",
    "\n",
    "from churn_nrt.src.utils.spark_session import get_spark_session\n",
    "\n",
    "sc, spark, sql_context = get_spark_session(\"scores\")\n",
    "sc.setLogLevel('WARN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amdocs_informational_dataset.engine.call_centre_calls import CallCentreCalls\n",
    "from pyspark.sql.functions import collect_set, concat, size, coalesce, col, lpad, struct, count as sql_count, lit, min as sql_min, max as sql_max, collect_list, udf, \\\n",
    "        desc, asc, to_date, create_map, sum as sql_sum, substring, sort_array, split, month, dayofmonth\n",
    "from pyspark.sql.types import StringType, ArrayType, MapType, StructType, StructField, IntegerType, DateType\n",
    "from pyspark.sql.functions import array, regexp_extract\n",
    "from itertools import chain\n",
    "import argparse\n",
    "import csv\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "\n",
    "from pyspark.sql.functions import concat_ws, date_format, from_unixtime, \\\n",
    "    length, lit, lower, lpad, month, regexp_replace, translate, udf, unix_timestamp, year, when, upper\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "from engine.general_functions import format_date, compute_diff_days, sum_horizontal\n",
    "from collections import Counter\n",
    "from pyspark.sql.types import StringType\n",
    "from pykhaos.utils.date_functions import get_last_day_of_month, move_date_n_days, move_date_n_cycles, move_date_n_yearmonths\n",
    "from churn.analysis.ccc_churn.engine.data_loader import get_port, get_ccc_data, get_tgs, get_all_ports\n",
    "from churn.datapreparation.general.data_loader import get_active_services\n",
    "from churn.analysis.ccc_churn.engine.reporter import compute_results, SAVING_PATH, init_writer, print_sheet\n",
    "from churn.analysis.ccc_churn.app.run_ccc_churn_analysis import join_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+-------+------------+------+-------+-------+----------+\n",
      "|predict_closing_date|training_closing_date|onlymob|mobileandfbb|others|    fbb|  deliv|deliv_date|\n",
      "+--------------------+---------------------+-------+------------+------+-------+-------+----------+\n",
      "|            20200207|   20191207to20191207|1303194|     3780223|671113|2222775|5754530|  20200214|\n",
      "|            20200131|   20191130to20191130|1302108|     3782148|671112|2224387|5755368|  20200207|\n",
      "|            20200121|   20191121to20191121|1305146|     3787517|671973|2227765|5764636|  20200131|\n",
      "|            20200114|   20191114to20191114|1306227|     3792449|672478|2230165|5771154|  20200124|\n",
      "|            20200107|   20191107to20191107|1307608|     3796679|673204|2232737|5777491|  20200117|\n",
      "|            20191231|   20191031to20191031|1309533|     3799572|673658|2234718|5782763|  20200110|\n",
      "|            20191221|   20191021to20191021|1309918|     3803404|674033|2237498|5787355|  20200103|\n",
      "|            20191214|   20191014to20191014|1310341|     3806134|674517|2239078|5790992|  20200103|\n",
      "|            20191207|   20191007to20191007|1309997|     3810066|674726|2242222|5794789|  20191220|\n",
      "|            20191130|   20190930to20190930|1309688|     3814198|674395|2245116|5798281|  20191213|\n",
      "|            20191121|   20190921to20190921|1312853|     3820521|675529|2249654|5808903|  20191129|\n",
      "|            20191114|   20190914to20190914|1314464|     3823851|675462|2251945|5813777|  20191122|\n",
      "|            20191107|   20190907to20190907|1315391|     3827390|676180|2254747|5818961|  20191115|\n",
      "|            20191031|   20190831to20190831|1316445|     3830733|676344|2257012|5823522|  20191108|\n",
      "|            20191021|   20190821to20190821|1320865|     3837103|677749|2261938|5835717|  20191101|\n",
      "|            20191014|   20190814to20190814|1323132|     3838548|678122|2263305|5839802|  20191025|\n",
      "|            20191007|   20190807to20190807|1323634|     3841039|678072|2264689|   null|      null|\n",
      "|            20190930|   20190731to20190731|1325666|     3843091|678838|2267342|5847595|  20191011|\n",
      "|            20190921|   20190721to20190721|1330543|     3847755|679665|2271828|5857963|  20190927|\n",
      "|            20190914|   20190714to20190714|1338643|     4005057|695930|2369824|6039630|  20190920|\n",
      "+--------------------+---------------------+-------+------------+------+-------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    " \n",
    "df_onlymob = (spark.read.load(\"/data/attributes/vf_es/model_outputs/model_scores/model_name=churn_preds_onlymob\")\n",
    "              .select(\"executed_at\", \"predict_closing_date\").groupby(\"executed_at\", \"predict_closing_date\").agg(sql_count(\"*\").alias(\"onlymob\")))\n",
    "df_onlymob_params = spark.read.load(\"/data/attributes/vf_es/model_outputs/model_parameters/model_name=churn_preds_onlymob\").select(\"executed_at\", \"training_closing_date\")\n",
    "df_onlymob = df_onlymob.join(df_onlymob_params, on=[\"executed_at\"], how=\"outer\")\n",
    "df_onlymob = df_onlymob.select(\"training_closing_date\", \"predict_closing_date\", \"onlymob\")\n",
    "\n",
    "\n",
    "df_mobandfbb = (spark.read.load(\"/data/attributes/vf_es/model_outputs/model_scores/model_name=churn_preds_mobileandfbb\")\n",
    "                .select(\"executed_at\", \"predict_closing_date\").groupby(\"executed_at\", \"predict_closing_date\").agg(sql_count(\"*\").alias(\"mobileandfbb\")))\n",
    "\n",
    "df_mobandfbb_params = spark.read.load(\"/data/attributes/vf_es/model_outputs/model_parameters/model_name=churn_preds_mobileandfbb\").select(\"executed_at\", \"training_closing_date\")\n",
    "df_mobandfbb = df_mobandfbb.join(df_mobandfbb_params, on=[\"executed_at\"], how=\"outer\")\n",
    "df_mobandfbb = df_mobandfbb.select(\"training_closing_date\", \"predict_closing_date\", \"mobileandfbb\")\n",
    "\n",
    "\n",
    "df_others = (spark.read.load(\"/data/attributes/vf_es/model_outputs/model_scores/model_name=churn_preds_others\")\n",
    "              .select(\"executed_at\", \"predict_closing_date\").groupby(\"executed_at\", \"predict_closing_date\").agg(sql_count(\"*\").alias(\"others\")))\n",
    "df_others_params = spark.read.load(\"/data/attributes/vf_es/model_outputs/model_parameters/model_name=churn_preds_others\").select(\"executed_at\", \"training_closing_date\")\n",
    "df_others = df_others.join(df_others_params, on=[\"executed_at\"], how=\"outer\")\n",
    "df_others = df_others.select(\"training_closing_date\", \"predict_closing_date\", \"others\")\n",
    "\n",
    "\n",
    "df_fbb = (spark.read.load(\"/data/attributes/vf_es/model_outputs/model_scores/model_name=churn_preds_fbb\")\n",
    "            .select(\"executed_at\", \"predict_closing_date\").groupby(\"executed_at\", \"predict_closing_date\").agg(sql_count(\"*\").alias(\"fbb\")))\n",
    "df_fbb_params = spark.read.load(\"/data/attributes/vf_es/model_outputs/model_parameters/model_name=churn_preds_fbb\").select(\"executed_at\", \"training_closing_date\")\n",
    "df_fbb = df_fbb.join(df_fbb_params, on=[\"executed_at\"], how=\"outer\")\n",
    "df_fbb = df_fbb.select(\"training_closing_date\", \"predict_closing_date\", \"fbb\")\n",
    "\n",
    "\n",
    "df_deliv = (spark.read.load(\"/data/attributes/vf_es/model_outputs/model_scores/model_name=delivery_churn\")\n",
    "            .withColumn(\"deliv_date\", concat(col(\"year\"), lpad(col(\"month\"), 2, '0'), lpad(col(\"day\"), 2, '0')))\n",
    "            .select(\"executed_at\", \"predict_closing_date\", \"deliv_date\").groupby(\"deliv_date\", \"executed_at\", \"predict_closing_date\").agg(sql_count(\"*\").alias(\"deliv\")))\n",
    "df_deliv_params = spark.read.load(\"/data/attributes/vf_es/model_outputs/model_parameters/model_name=delivery_churn\").select(\"executed_at\", \"training_closing_date\")\n",
    "df_deliv = df_deliv.join(df_deliv_params, on=[\"executed_at\"], how=\"outer\")\n",
    "df_deliv = df_deliv.select(\"training_closing_date\", \"predict_closing_date\", \"deliv\", \"deliv_date\")\n",
    "\n",
    "\n",
    "\n",
    "df_all = df_onlymob.join(df_mobandfbb, on=[\"predict_closing_date\", \"training_closing_date\"], how=\"outer\")\n",
    "df_all = df_all.join(df_others, on=[\"predict_closing_date\", \"training_closing_date\"], how=\"outer\")\n",
    "df_all = df_all.join(df_fbb, on=[\"predict_closing_date\", \"training_closing_date\"], how=\"outer\")\n",
    "df_all = df_all.join(df_deliv, on=[\"predict_closing_date\", \"training_closing_date\"], how=\"outer\")\n",
    "\n",
    "\n",
    "df_all.sort(desc(\"predict_closing_date\"), desc(\"training_closing_date\")).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASE COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DataTemplate] __init__ | module name = customer_base | path = /data/udf/vf_es/churn_nrt/customer_base | verbose = True\n",
      "[DataTemplate] get_module | module customer_base - for closing_day=20190930 save=False save_others=False force_gen=False\n",
      "[DataTemplate] get_module | args: () | kwargs: {}\n",
      "[CustomerBase] is_default_module | args: () | kwargs: {}\n",
      "[DataTemplate] get_module | Not found a module - '/data/udf/vf_es/churn_nrt/customer_base/year=2019/month=9/day=30'. Starting generation...\n",
      "[CustomerBase] Get get_customer_base_segment base segment | date 20190930 save_others False\n",
      "[CustomerBase] __get_customer_base date_=20190930 save_others=False add_columns_customer=None\n",
      "[DataTemplate] __init__ | module name = customer | path = /data/udf/vf_es/churn_nrt/customer | verbose = True\n",
      "[DataTemplate] get_module | module customer - for closing_day=20190930 save=False save_others=False force_gen=False\n",
      "[DataTemplate] get_module | args: () | kwargs: {'add_columns': None}\n",
      "[Customer] is_default_module | args: () | kwargs: {'add_columns': None}\n",
      "[DataTemplate] get_module | Not found a module - '/data/udf/vf_es/churn_nrt/customer/year=2019/month=9/day=30'. Starting generation...\n",
      "[Customer] build_module | Requested additional_columns None\n",
      "[DataTemplate] get_module | module 'customer' | Elapsed time in build_module function: 0.0948360641797 minutes\n",
      "[DataTemplate] get_module | module 'customer' | Module will not be saved (save=False and is_default_module()=True)\n",
      "[DataTemplate] __init__ | module name = service | path = /data/udf/vf_es/churn_nrt/service | verbose = True\n",
      "[DataTemplate] get_module | module service - for closing_day=20190930 save=False save_others=False force_gen=False\n",
      "[DataTemplate] get_module | args: () | kwargs: {}\n",
      "[DataTemplate] get_module | Not found a module - '/data/udf/vf_es/churn_nrt/service/year=2019/month=9/day=30'. Starting generation...\n",
      "[DataTemplate] get_module | module 'service' | Elapsed time in build_module function: 0.131417183081 minutes\n",
      "[DataTemplate] get_module | module 'service' | Module will not be saved (save=False and is_default_module()=True)\n",
      "[CustomerBase] build_module | Found extra feats for tgs - 20190930\n",
      "[DataTemplate] get_module | module 'customer_base' | Elapsed time in build_module function: 0.443937865893 minutes\n",
      "[DataTemplate] get_module | module 'customer_base' | Module will not be saved (save=False and is_default_module()=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5871315"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from churn_nrt.src.data.customer_base import CustomerBase\n",
    "from churn_nrt.src.data_utils.base_filters import get_mobile_base\n",
    "\n",
    "\n",
    "df_bd = get_mobile_base(spark, date_=\"20190930\", save=False)\n",
    "#df_bd.where(col(\"NUM_CLIENTE\")==\"954345290\").show()\n",
    "df_bd.count()\n",
    "\n",
    "\n",
    "# df_nrt_cust_base = spark.read.load(\"/data/udf/vf_es/churn_nrt/customer_base/year=2019/month=9/day=30\")\n",
    "# df_nrt_cust_base.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5842368"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bd_anon = spark.read.load(\"/data/attributes/vf_es/model_outputs/model_scores/model_name=mobile_base/year=2019/month=9/day=30\") #\"/user/csanc109/data/mobile_base_20190930_parquet/\")\n",
    "df_bd_anon.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bd = spark.read.option(\"delimeter\", \"|\").option(\"header\",False).csv(\"/user/csanc109/data/mobile_base_20190930_desanonim/Mobile_Base-20190930.csv\")\n",
    "headers = ['executed_at',\n",
    " 'model_executed_at',\n",
    " 'predict_closing_date',\n",
    "        'msisdn',   \n",
    "        'client_id'  , \n",
    "           'nif',\n",
    " 'model_output',\n",
    " 'scoring',\n",
    " 'prediction',\n",
    " 'extra_info',\n",
    " 'time',\n",
    " \n",
    " \n",
    " ]\n",
    "df_bd=df_bd.toDF(*headers)\n",
    "# df_bd.count() # 5842368\n",
    "from pyspark.sql.functions import substring_index, posexplode, split\n",
    "EXTRA_INFO_COLS = ['srv_basic',\n",
    " 'rgu',\n",
    " 'CLASE_CLI_COD_CLASE_CLIENTE',\n",
    " 'COD_ESTADO_GENERAL',\n",
    " 'TARIFF']\n",
    "\n",
    "for ii, col_ in enumerate(EXTRA_INFO_COLS):\n",
    "    df_bd = df_bd.withColumn(col_, split(\"extra_info\", \";\")[ii])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_insi = spark.read.option(\"delimiter\", \"|\").option(\"header\",True).csv(\"/user/csanc109/data/mobile_base_20190930_insigths/mobile_base_20190930_insights.csv\")\n",
    "# for col_ in df_insi.columns:\n",
    "#     if col_ == \"MSISDN\":\n",
    "#         df_insi = df_insi.withColumnRenamed(col_, col_.lower())\n",
    "#     else:\n",
    "#         df_insi = df_insi.withColumnRenamed(col_, col_.lower()+\"_insi\")\n",
    "        \n",
    "# df_insi.count() # 5583563\n",
    "# df_insi = df_insi.withColumn(\"campo1\", col(\"msisdn\"))\n",
    "# df_insi = df_insi.withColumn(\"campo2\", col(\"num_cliente\"))\n",
    "# df_insi = df_insi.withColumn(\"campo3\", col(\"nif_cliente\"))\n",
    "# df_insi.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5502418"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_insi_anon = spark.read.load(\"/data/raw/vf_es/lookup/MOBILE_BASE/1.0/parquet/year=2020/month=1/day=17\")\n",
    "\n",
    "df_insi_anon.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En BD y no en Insi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('volumen en BD y no en Insi', 561072)\n"
     ]
    }
   ],
   "source": [
    "df_labels_cross = df_insi_anon.join(df_bd, ['msisdn'], 'right').where(df_insi_anon['msisdn'].isNull())\n",
    "df_labels_cross = df_labels_cross.cache()\n",
    "#df_labels_cross.select(\"msisdn\").show()\n",
    "\n",
    "print(\"volumen en BD y no en Insi\", df_labels_cross.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En Insi y no en BD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('volumen en Insi y no en BD', 192197)\n"
     ]
    }
   ],
   "source": [
    "df_labels_cross2 = df_bd.select(\"msisdn\").join(df_insi_anon, ['msisdn'], 'right').where(df_bd['msisdn'].isNull())\n",
    "df_labels_cross2 = df_labels_cross2.cache()\n",
    "#df_labels_cross2.select(\"msisdn\", \"nif_cliente\", \"num_cliente\").show()\n",
    "print(\"volumen en Insi y no en BD\", df_labels_cross2.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volumen comun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('volumen comun', 5310242)\n"
     ]
    }
   ],
   "source": [
    "df_labels_cross3 = df_insi_anon.join(df_bd, ['msisdn'], 'inner')\n",
    "df_labels_cross3 = df_labels_cross3.cache()\n",
    "print(\"volumen comun\", df_labels_cross3.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_cross3.select(\"msisdn\", \"nif_cliente\", \"num_cliente\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_cross3.select(\"msisdn\", \"clase_cli_cod_clase_cliente\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_cross.groupby(\"CLASE_CLI_COD_CLASE_CLIENTE\", 'COD_ESTADO_GENERAL').agg(sql_count(\"*\").alias(\"count\")).sort(desc(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_cross2.groupby('serv_basico_insi','tarifa_insi',).agg(sql_count(\"*\").alias(\"count\")).sort(desc(\"count\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# navcomp exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pasoprevio = spark.read.load(\"/data/udf/vf_es/netscout/dailyMSISDNApplicationName/year=2019/month=4/day=7\")\n",
    "df_pasoprevio.columns\n",
    "df_pasoprevio2 = spark.read.load(\"/data/udf/vf_es/netscout/dailyMSISDNApplicationName/year=2019/month=10/day=7\")\n",
    "df_pasoprevio2.columns\n",
    "\n",
    "set(df_pasoprevio.columns) ^ set(df_pasoprevio2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_limit200 = spark.read.load(\"/data/attributes/vf_es/return_feed/data_navigation/year=2019/month=10/day=7\").limit(200)\n",
    "msisdns = list(set(df_data_limit200.select(\"subscriber_msisdn\").rdd.map(lambda x: x['subscriber_msisdn']).collect()))\n",
    "#msisdns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_names = list(set(spark.read.load(\"/data/attributes/vf_es/return_feed/data_navigation/year=2019/month=10/day=7\").select(\"application_name\").rdd.map(lambda x: x['application_name']).collect()))\n",
    "apps_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(spark.read.load(\"/data/udf/vf_es/netscout/dailyMSISDNApplicationName/year=2019/month=10/day=7\")\n",
    " .where(col(\"subscriber_msisdn\").isin([\"34683771231\", \"34695709335\"]))\n",
    " .where( (col(\"SUM_userplane_upload_bytes_count\") + col(\"SUM_userplane_download_bytes_count\"))> 524288)\n",
    " .where(col(\"application_name\").isin(apps_names)).sort(desc(\"subscriber_msisdn\")).show())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(spark.read.load(\"/data/attributes/vf_es/return_feed/data_navigation/year=2019/month=10/day=7\")\n",
    " .where(col(\"subscriber_msisdn\").isin([\"34683771231\", \"34695709335\"]))\n",
    " .where(col(\"application_name\").isin(apps_names)).sort(desc(\"subscriber_msisdn\")).show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.load(\"/data/attributes/vf_es/return_feed/data_navigation/year=2019/month=10/day=7\").where(col(\"subscriber_msisdn\").isin([\"34683771231\", \"34695709335\"])).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operators = [\"JAZZTEL\", \"LOWI\", \"MASMOVIL\", \"MOVISTAR\", \"O2\", \"ORANGE\", \"PEPEPHONE\", \"VODAFONE\", \"YOIGO\"]\n",
    "apps_names = [\"WEB_\"+op+\"_\"+p for op in operators for p in [\"HTTP\", \"HTTPS\"]]\n",
    "apps_names\n",
    "\n",
    "\n",
    "# apps_names = [u'WEB_O2_HTTPS',\n",
    "#  u'WEB_MOVISTAR_HTTPS',\n",
    "#  u'WEB_VODAFONE_HTTPS',\n",
    "#  u'WEB_YOIGO_HTTP',\n",
    "#  u'WEB_LOWI_HTTPS',\n",
    "#  u'WEB_ORANGE_HTTP',\n",
    "#  u'WEB_JAZZTEL_HTTP',\n",
    "#  u'WEB_MASMOVIL_HTTP',\n",
    "#  u'WEB_VODAFONE_HTTP',\n",
    "#  u'WEB_MOVISTAR_HTTP',\n",
    "#  u'WEB_ORANGE_HTTPS',\n",
    "#  u'WEB_PEPEPHONE_HTTPS',\n",
    "#  u'WEB_PEPEPHONE_HTTP',\n",
    "#  u'WEB_JAZZTEL_HTTPS',\n",
    "#  u'WEB_LOWI_HTTP',\n",
    "#  u'WEB_MASMOVIL_HTTPS',\n",
    "#  u'WEB_YOIGO_HTTPS',\n",
    "#  u'WEB_O2_HTTP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(spark.read.load(\"/data/udf/vf_es/netscout/dailyMSISDNApplicationName/year=2019/month=10/day=17\").where(col(\"application_name\").isin(apps_names)).where(col(\"subscriber_msisdn\").isNotNull())\n",
    "           .withColumn(\"data\",col(\"SUM_userplane_upload_bytes_count\")+col(\"SUM_userplane_download_bytes_count\"))\n",
    "           .where(col(\"data\")>lit(524288))\n",
    "           .count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(spark.read.load(\"/data/udf/vf_es/netscout/dailyMSISDNApplicationName/year=2019/month=10/day=17\").where(col(\"application_name\").isin(apps_names))\n",
    "           .withColumn(\"data\",col(\"SUM_userplane_upload_bytes_count\")+col(\"SUM_userplane_download_bytes_count\"))\n",
    "           .where(col(\"data\")>lit(524288)).where(col(\"subscriber_msisdn\").isNull()).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(spark.read.load(\"/data/attributes/vf_es/return_feed/data_navigation/year=2019/month=10/day=17\")\n",
    "           .where(col(\"application_name\").isin(apps_names)).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(msisdns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.load(\"/data/udf/vf_es/netscout/dailyMSISDNApplicationName/year=2019/month=10/day=7\").where( (col(\"application_name\").isin(apps_names)) & (col(\"subscriber_msisdn\").isNotNull())).withColumn(\"data\",col(\"SUM_userplane_upload_bytes_count\")+col(\"SUM_userplane_download_bytes_count\")).where(col(\"data\")>lit(524288)).agg(sql_sum(\"data\")).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.load(\"/data/attributes/vf_es/return_feed/data_navigation/year=2019/month=10/day=7\").withColumn(\"data\",col(\"SUM_userplane_upload_bytes_count\")+col(\"SUM_userplane_download_bytes_count\")).agg(sql_sum(\"data\")).show(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from churn.analysis.triggers.navcomp.navcomp_utils import get_navcomp_attributes\n",
    "\n",
    "starting_date = \"20191001\"\n",
    "process_date = \"20191015\"\n",
    "\n",
    "df_orig = get_navcomp_attributes(spark, starting_date, process_date, level=\"msisdn\", suffix=\"\", orig_path=True)\n",
    "df_new = get_navcomp_attributes(spark, starting_date, process_date, level=\"msisdn\", suffix=\"\", orig_path=False)\n",
    "\n",
    "\n",
    "msisdns = [u'34602579459',\n",
    " u'34699265865',\n",
    " u'34637118046',\n",
    " u'34643541635',\n",
    " u'34667016219',\n",
    " u'34603522398',\n",
    " u'34612028463',\n",
    " u'34602172915',\n",
    " u'34638122635',\n",
    " u'34612661085',\n",
    " u'34621389630',\n",
    " u'34626735798',\n",
    " u'34683771231',\n",
    " u'34664804027',\n",
    " u'34612610069',\n",
    " u'34639483976',\n",
    " u'34652601172',\n",
    " u'34609921178',\n",
    " u'34661956702',\n",
    " u'882393230430821',\n",
    " u'34639513800',\n",
    " u'34603357360',\n",
    " u'34652976638',\n",
    " u'34653975428',\n",
    " u'34612139344',\n",
    " u'34657565248',\n",
    " u'34656504103',\n",
    " u'34615956180',\n",
    " u'34608183564',\n",
    " u'34658555004',\n",
    " u'34650548809',\n",
    " u'34603997436',\n",
    " u'34694917249',\n",
    " u'34655457739',\n",
    " u'34679067766',\n",
    " u'34655551506',\n",
    " u'4534296369',\n",
    " u'34688510057',\n",
    " u'34692843710',\n",
    " u'34615977864',\n",
    " u'34694252365',\n",
    " u'34750363217',\n",
    " u'34621848425',\n",
    " u'34647631129',\n",
    " u'34661980383',\n",
    " u'34698409737',\n",
    " u'34655950914',\n",
    " u'34670819047',\n",
    " u'34602342056',\n",
    " u'34672405851',\n",
    " u'34697093354',\n",
    " u'34676843005',\n",
    " u'34607755410',\n",
    " u'34643746223',\n",
    " u'34624075045',\n",
    " u'34664164957',\n",
    " u'34640055967',\n",
    " u'34699436991',\n",
    " u'34615040780',\n",
    " u'34649505208',\n",
    " u'34630228529',\n",
    " u'34641787568',\n",
    " u'34695261294',\n",
    " u'34650852676',\n",
    " u'34651786844',\n",
    " u'34615406433',\n",
    " u'34661414103',\n",
    " u'34635496504',\n",
    " u'34650886571',\n",
    " u'34684878681',\n",
    " u'34679830577',\n",
    " u'34624664265',\n",
    " u'34686333247',\n",
    " u'34619574709',\n",
    " u'34661626345',\n",
    " u'34698930485',\n",
    " u'34643290334',\n",
    " u'34607224467',\n",
    " u'34611273565',\n",
    " u'34659755182',\n",
    " u'34626409295',\n",
    " u'34625087446',\n",
    " u'34697793869',\n",
    " u'34620566839',\n",
    " u'34647541941',\n",
    " u'34605096525',\n",
    " u'34650504179',\n",
    " u'34625289088',\n",
    " u'34683210998',\n",
    " u'34656319159',\n",
    " u'34630720603',\n",
    " u'447741382752',\n",
    " u'34683152899',\n",
    " u'34602929199',\n",
    " u'34692822948',\n",
    " u'34622813172',\n",
    " u'34670572823',\n",
    " u'34789958445',\n",
    " u'34688965869',\n",
    " u'34680347447',\n",
    " u'34664508482',\n",
    " u'491789031376',\n",
    " u'34609848759',\n",
    " u'34627904079',\n",
    " u'34655266152',\n",
    " u'34610455798',\n",
    " u'34695261579',\n",
    " u'34682884563',\n",
    " u'34666763747',\n",
    " u'34604753014',\n",
    " u'34682473201',\n",
    " u'34631727443',\n",
    " u'34610441363',\n",
    " u'882396873366857',\n",
    " u'34636544644',\n",
    " u'34679518709',\n",
    " u'34649438836',\n",
    " u'34654761792',\n",
    " u'34640763250',\n",
    " u'34693958858',\n",
    " u'34634959019',\n",
    " u'34642901478',\n",
    " u'34606813261',\n",
    " u'34635773177',\n",
    " u'34667060855',\n",
    " u'34628330469',\n",
    " u'34627906966',\n",
    " u'34609348547',\n",
    " u'34699593370',\n",
    " u'34601186557',\n",
    " u'34684669501',\n",
    " u'34693123558',\n",
    " u'34653037531',\n",
    " u'34679250802',\n",
    " u'34688200353',\n",
    " u'34611425181',\n",
    " u'34696064244',\n",
    " u'34676455684',\n",
    " u'34693045687',\n",
    " u'34683627907',\n",
    " u'34645462158',\n",
    " u'34601143234',\n",
    " u'34648188487',\n",
    " u'34629999175',\n",
    " u'34625299080',\n",
    " u'34693494584',\n",
    " u'491795499178',\n",
    " u'34692124140',\n",
    " u'34683818952',\n",
    " u'34600503065',\n",
    " u'34611822026',\n",
    " u'34613046218',\n",
    " u'34699581645',\n",
    " u'34664571843',\n",
    " u'34662072310',\n",
    " u'34656348015',\n",
    " u'34616934022',\n",
    " u'34636099471',\n",
    " u'34666271584',\n",
    " u'34670942078',\n",
    " u'34670472204',\n",
    " u'34663565093',\n",
    " u'34667039830',\n",
    " u'34688385443',\n",
    " u'34640854236',\n",
    " u'34609934152',\n",
    " u'34628964902',\n",
    " u'34620534832',\n",
    " u'34619282211',\n",
    " u'34640265051',\n",
    " u'34632300147',\n",
    " u'34691150155',\n",
    " u'34681535231',\n",
    " u'34693190094',\n",
    " u'34644285982',\n",
    " u'34620270626',\n",
    " u'34654243256',\n",
    " u'34662901998',\n",
    " u'34600732856',\n",
    " u'34656334691',\n",
    " u'34658894953',\n",
    " u'34610703900',\n",
    " u'34601426823',\n",
    " u'34601761332',\n",
    " u'34675069520',\n",
    " u'34654207810',\n",
    " u'34694845333',\n",
    " u'34613742893',\n",
    " u'34600038285',\n",
    " u'34606950109',\n",
    " u'34624679794',\n",
    " u'34637879188',\n",
    " u'34689218659',\n",
    " u'34643243869',\n",
    " u'34601168324',\n",
    " u'34669574220',\n",
    " u'34648207731',\n",
    " u'34613234875',\n",
    " u'34683590410',\n",
    " u'34634399909']\n",
    "\n",
    "\n",
    "msisdns = [re.sub(r'^34', '', mm) for mm in msisdns]\n",
    "\n",
    "df_orig = df_orig.where(col(\"msisdn\").isin(msisdns))\n",
    "df_new = df_new.where(col(\"msisdn\").isin(msisdns))\n",
    "\n",
    "df_orig = df_orig.show(200, truncate=False)\n",
    "df_new = df_new.show(200, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_service_param.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_table.count(), df_table.distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_service_param.count(), data_service_param.distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOC_RT_PATH = '/data/udf/vf_es/ref_tables/amdocs_ids/'\n",
    "LOC_RT_PARAM_OW_SERVICES= LOC_RT_PATH + 'PARAM_OW_SERVICES.TXT'\n",
    "data_service_param = spark.read.csv(LOC_RT_PARAM_OW_SERVICES, header=True,sep='\\t')\n",
    "data_service_param.where(col(\"COD_SERVICIO\").isin(\"TRDNP\", \"VFETC\", \"TESTH\", \"DTVC5\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import  (sum as sql_sum, countDistinct, trim\n",
    "                                    ,max, greatest , split,desc, col, current_date\n",
    "                                    , datediff, lit, translate, udf\n",
    "                                    , when, concat_ws, concat, decode, length\n",
    "                                    , substring, to_date, regexp_replace, lpad\n",
    "                                    , hour, date_format, row_number\n",
    "                                    , expr, coalesce, udf, year)\n",
    "from pyspark.sql.window import Window\n",
    "import datetime\n",
    "from engine.constants import UNKNOWN_TAG, OTHERS_TAG, L2_SUFFIX, DESC_TARIFF\n",
    "from engine.general_functions import norm_values, format_date, compute_diff_days, sum_horizontal\n",
    "from engine.amdocs_ids_config import path_customer\n",
    "def is_null_date(fecha):\n",
    "    return year(fecha) == 1753"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOC_RT_PATH = '/data/udf/vf_es/ref_tables/amdocs_ids/'\n",
    "LOC_RT_PARAM_OW_SERVICES = LOC_RT_PATH + 'PARAM_OW_SERVICES.TXT'\n",
    "data_service_param =  spark.read.format('com.databricks.spark.csv').options(header='true', inferschema='true',delimiter='\\t').load(LOC_RT_PARAM_OW_SERVICES).select(\"RGU\", \"COD_SERVICIO\", \"TIPO\").distinct()\n",
    "df_table = spark.read.load(\"/data/raw/vf_es/customerprofilecar/WEBSERVICES/1.0/parquet\").select(\"COD_SERVICIO\", \"RGU\", \"AMBITO\").withColumnRenamed(\"RGU\", \"RGU_table\").distinct()\n",
    "df_table = df_table.withColumn(\"RGU_table\", when(col(\"RGU_table\")==\"F - Internet (BA)\", \"fbb\").when(col(\"RGU_table\")==\"F - Televisión (TV)\", \"tv\").when(col(\"RGU_table\")==\"M - Móvil (MV)\", \"mobile\").otherwise(col(\"RGU_table\")))\n",
    "\n",
    "df_all = df_table.join(data_service_param, on=[\"COD_SERVICIO\"], how=\"outer\")\n",
    "df_all = df_all.where( ~((col(\"RGU_table\")==\"mobile\") & (col(\"RGU\")==\"mobile\")))\n",
    "df_all = df_all.where(col(\"RGU\") == \"mobile\")\n",
    "\n",
    "df_all.show(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = ['nif_cliente',\n",
    " 'msisdn',\n",
    " 'rgu',\n",
    " 'NUM_CLIENTE',\n",
    " 'cod_estado_general',\n",
    " 'srv_basic',\n",
    " 'clase_cli_cod_clase_cliente',\n",
    " 'segment_nif',\n",
    " 'nb_fbb_services_nif',\n",
    " 'nb_mobile_services_nif',\n",
    " 'nb_tv_services_nif',\n",
    " 'nb_prepaid_services_nif',\n",
    " 'nb_bam_mobile_services_nif',\n",
    " 'nb_fixed_services_nif',\n",
    " 'nb_bam_services_nif',\n",
    " 'nb_rgus_nif',\n",
    " 'rgus_list',\n",
    " 'tgs_days_until_fecha_fin_dto',\n",
    " 'tgs_has_discount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DataTemplate] module name = scores | path = /data/udf/vf_es/churn_nrt/scores | verbose = True\n",
      "[Metadata] Adding Scores metadata\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'latest_score']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_sources =  ['navcomp', 'customer', 'ccc', 'spinners', \"scores\"]\n",
    "from churn_nrt.src.projects.models.navcomp.metadata import METADATA_STANDARD_MODULES, get_metadata\n",
    "\n",
    "\n",
    "from churn_nrt.src.data_utils.Metadata import Metadata\n",
    "metadata_obj = Metadata(spark, get_metadata, [\"msisdn\"], metadata_sources)\n",
    "\n",
    "#navcomp_tr_df = self.METADATA.fillna(navcomp_tr_df, sources=['scores'])\n",
    "\n",
    "cols = None\n",
    "sources = [\"scores\"]\n",
    "\n",
    "if not cols and not sources:\n",
    "    print(\"Calling fillna with sources=None and cols=Non. Filling nans for all sources ({})\".format(\",\".join(self.METADATA_SOURCES)))\n",
    "    sources = metadata_sources\n",
    "\n",
    "if sources:\n",
    "    df_metadata = metadata_obj.get_metadata_df(sources=sources)\n",
    "    cols_sources = df_metadata.rdd.map(lambda x: x['feature']).collect()\n",
    "else:\n",
    "    cols_sources = []\n",
    "\n",
    "cols = cols_sources if not cols else list(set(cols) | set(cols_sources))\n",
    "\n",
    "cols\n",
    "\n",
    "#apply_metadata(df_metadata, df, cols)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
