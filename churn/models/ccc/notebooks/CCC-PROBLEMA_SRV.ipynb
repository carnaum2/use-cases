{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20181122-104858 [INFO ] Logging to file /var/SP/data/home/csanc109/logging/out_20181122_104858.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_initialize spark\n",
      "Ended spark session: 35.9672298431 secs | default parallelism=2\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import datetime as dt\n",
    "DEVEL_SRC = os.path.join(os.environ.get('BDA_USER_HOME', ''), \"src\", \"devel\")\n",
    "if DEVEL_SRC not in sys.path:\n",
    "    sys.path.append(DEVEL_SRC)\n",
    "\n",
    "USECASES_SRC = os.path.join(DEVEL_SRC, \"use-cases\") # TODO when - is removed, remove also this line and adapt imports\n",
    "if USECASES_SRC not in sys.path: \n",
    "    sys.path.append(USECASES_SRC)\n",
    "    \n",
    "AMDOCS_SRC = os.path.join(DEVEL_SRC, \"amdocs_informational_dataset\") # TODO when - is removed, remove also this line and adapt imports\n",
    "if AMDOCS_SRC not in sys.path: \n",
    "    sys.path.append(AMDOCS_SRC)\n",
    "    \n",
    "import pykhaos.utils.custom_logger as clogger\n",
    "logging_file = os.path.join(os.environ.get('BDA_USER_HOME', ''), \"logging\",\n",
    "                                    \"out_\" + dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + \".log\")\n",
    "logger = clogger.configure_logger(log_filename=logging_file, std_channel=sys.stderr, logger_name=\"\")\n",
    "logger.info(\"Logging to file {}\".format(logging_file))    \n",
    "    \n",
    "    \n",
    "from project.project_generic import Project\n",
    "\n",
    "\n",
    "import pykhaos.utils.notebooks as nb\n",
    "\n",
    "project_obj = Project(\"CCC model\", \"CCC model\")   \n",
    "\n",
    "RUNNING_FROM_NOTEBOOK = nb.isnotebook()\n",
    "import matplotlib.pyplot as plt\n",
    "if RUNNING_FROM_NOTEBOOK:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    %matplotlib inline  \n",
    "    \n",
    "#logger = my_project.logger\n",
    "\n",
    "if not RUNNING_FROM_NOTEBOOK:\n",
    "    args = my_project.arg_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spark=project_obj.spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline \n",
    "from churn.datapreparation.data_loader import get_port_requests_table\n",
    "from churn.datapreparation.config import Config\n",
    "\n",
    "# config_obj = Config(None)\n",
    "\n",
    "port_start_date = \"20180901\"\n",
    "port_end_date = \"20180930\"\n",
    "ref_date = \"20181021\"\n",
    "\n",
    "select_cols = [\"portout_date\",  \"msisdn_a\", \"label\", \"days_from_portout\"]\n",
    "\n",
    "#df_port = get_port_requests_table(spark, config_obj, port_start_date, port_end_date, ref_date, select_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_port' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8c209dbc9839>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mportout_dates_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_port\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'portout_date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistinct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mportout_dates_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mportout_dates_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mportout_dates_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mportout_dates_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mccc_start_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"20180801\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_port' is not defined"
     ]
    }
   ],
   "source": [
    "portout_dates_list = df_port.select('portout_date').distinct().collect()\n",
    "portout_dates_min = min(portout_dates_list)\n",
    "portout_dates_max = max(portout_dates_list)\n",
    "\n",
    "ccc_start_date = \"20181008\"\n",
    "ccc_end_date = \"20180930\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from engine.call_centre_calls import CallCentreCalls\n",
    "\n",
    "#Call Centre Calls\n",
    "ccc = CallCentreCalls(spark)\n",
    "df_ccc = ccc.get_ccc_service_df(ccc_end_date,ccc_start_date)\n",
    "df_all = ccc.all_interactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HDFS_DIR_DATA = '/user/csanc109/projects/churn/data/ccc_model/'\n",
    "# df_all = df_all.repartition(1)\n",
    "# df_all.write.mode('overwrite').format('csv').option(\"header\", \"true\").save('/user/csanc109/projects/churn/data/ccc_model/all_interactions_20181114.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LAS QUE NO CRUZAN\n",
    "# from pyspark.sql.functions import desc, upper\n",
    "# df_nocruzan=df_all.where(col(\"Bucket\")==\"NA\").groupby(\"source\", \"INT_Tipo\", \"INT_Subtipo\", \"INT_Razon\", \"INT_Resultado\", \"X_WORKGROUP\", \"direction\", \"type_td\").agg(sql_count(\"*\").alias(\"count\")).sort(desc(\"count\"))\n",
    "# df_nocruzan.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### EJECUTAR SOLO EN CASO DE NECESIDAD!!!!!!\n",
    "# df_pandas=df_nocruzan.limit(100).toPandas()\n",
    "# writer = pd.ExcelWriter(\"/var/SP/data/home/csanc109/data/churn/ccc/nocruzan_20181114.xlsx\", engine='xlsxwriter')\n",
    "# df_pandas.to_excel(writer, startrow = 0, sheet_name='Bucket NA')\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|              Bucket|  count|\n",
      "+--------------------+-------+\n",
      "|             Bucket_|     76|\n",
      "|Bucket_Billing - ...| 887119|\n",
      "|Bucket_Churn/Canc...|1409282|\n",
      "|  Bucket_Collections| 273738|\n",
      "|Bucket_DSL/FIBER ...| 781377|\n",
      "|Bucket_Device del...| 179853|\n",
      "|Bucket_Device upg...| 259134|\n",
      "|Bucket_New adds p...| 707436|\n",
      "|Bucket_Other cust...| 630229|\n",
      "|Bucket_Prepaid ba...|  10286|\n",
      "|Bucket_Product an...| 927302|\n",
      "|Bucket_Quick Closing|  76563|\n",
      "|Bucket_Tariff man...| 169176|\n",
      "|Bucket_Voice and ...| 251504|\n",
      "|                  NA|2210417|\n",
      "+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Para ver los buckets a NA NA|2269376\n",
    "df_all.select('Bucket').groupby('Bucket').count().sort('Bucket').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1847227"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum as sql_sum\n",
    "# df_all distinct count 2719030 df_sinNA distinct count 1836042\n",
    "df_sinNA = ((df_all\n",
    "            .groupby('msisdn')\n",
    "            .agg(sql_sum(when(col('Bucket')==\"NA\", lit(1)).otherwise(lit(0))).alias(\"bucket_sum\")))\n",
    "            .where(col(\"bucket_sum\")==0))\n",
    "df_sinNA.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import collect_set, concat, size, coalesce, col, lpad, struct, count as sql_count, lit, min as sql_min, max as sql_max, collect_list, udf, when\n",
    "from pyspark.sql.types import StringType, ArrayType, MapType, StructType, StructField, IntegerType\n",
    "\n",
    "from engine.general_functions import format_date, compute_diff_days\n",
    "\n",
    "\n",
    "df_agg = (df_all.where(col(\"Bucket\")!=\"NA\")\\\n",
    "            .withColumn(\"fx_interaction\",concat(col('year'),lpad(col('month'),2, '0'),lpad(col('day'),2, '0')))\n",
    "            .withColumn(\"tuples\", struct([\"fx_interaction\",\"Bucket\"]))\n",
    "            .groupby('msisdn')\n",
    "            .agg(sql_count(lit(1)).alias(\"num_interactions\"),\n",
    "                 sql_min(col('fx_interaction')).alias(\"first_interaction\"),\n",
    "                 sql_max(col('fx_interaction')).alias(\"latest_interaction\"),\n",
    "                 sql_max(col(\"tuples\")).alias(\"tuples_max\"), # latest interaction: [max(fx_interaction), bucket]\n",
    "                 sql_min(col(\"tuples\")).alias(\"tuples_min\"), # first interaction: [min(fx_interaction), bucket]\n",
    "                 collect_list('Bucket').alias(\"bucket_list\"),\n",
    "                 collect_set('Bucket').alias(\"bucket_set\")\n",
    "             ))\n",
    "\n",
    "df_agg = df_agg.withColumn(\"ref_date\", format_date(lit(ref_date)))\n",
    "df_agg = (df_agg.withColumn(\"bucket_1st_interaction\", col(\"tuples_min\")[\"Bucket\"])\n",
    "                .withColumn(\"bucket_latest_interaction\", col(\"tuples_max\")[\"Bucket\"])\n",
    "                .withColumn(\"nb_diff_buckets\", size(\"bucket_set\"))\n",
    "                .withColumn(\"num_interactions\", size(\"bucket_list\"))\n",
    "          .drop(*['tuples_max','tuples_min'])\n",
    "         )\n",
    "\n",
    "for cc in [\"first_interaction\", \"latest_interaction\"]:\n",
    "    df_agg = (df_agg.withColumn(\"fx_{}\".format(cc), format_date(cc, filter_dates_1900=True))  # days before 1900 converted to None\n",
    "                    .withColumn(\"days_since_{}\".format(cc), compute_diff_days(\"fx_{}\".format(cc), \"ref_date\")))\n",
    "    \n",
    "from collections import Counter\n",
    "from pyspark.sql.types import StringType, ArrayType, MapType, StructType, StructField\n",
    "\n",
    "def get_mode(lst):\n",
    "    dd = Counter(lst).most_common(2)\n",
    "    return dd[0][0] if (len(dd)==1 or dd[0][1] > dd[1][1]) else \"TIE\"\n",
    "def get_mode_freq(lst):\n",
    "    dd = Counter(lst).most_common(2)\n",
    "    return dd[0][1] # value\n",
    "\n",
    "get_mode_udf = udf(lambda lst: get_mode(lst), StringType())\n",
    "get_mode_freq_udf = udf(lambda lst: get_mode_freq(lst), IntegerType())\n",
    "\n",
    "df_agg = (df_agg.withColumn(\"most_common_bucket_with_ties\", when(coalesce(size(col(\"bucket_list\")),lit(0))==0,\"None\").otherwise(get_mode_udf(col(\"bucket_list\"))))\n",
    "                .withColumn(\"most_common_bucket\", when(col(\"most_common_bucket_with_ties\").rlike(\"^TIE\"), col('bucket_latest_interaction')).otherwise(col(\"most_common_bucket_with_ties\")))\n",
    "                .withColumn(\"most_common_bucket_interactions\", when(coalesce(size(col(\"bucket_list\")),lit(0))==0,-1).otherwise(get_mode_freq_udf(col(\"bucket_list\"))))\n",
    "          )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+-------------------------+----------------------------+-------------------------+\n",
      "|bucket_list                                                                                                             |bucket_latest_interaction|most_common_bucket_with_ties|most_common_bucket       |\n",
      "+------------------------------------------------------------------------------------------------------------------------+-------------------------+----------------------------+-------------------------+\n",
      "|[Bucket_Product and Service management, Bucket_Billing - Postpaid, Bucket_Tariff management, Bucket_Churn/Cancellations]|Bucket_Billing - Postpaid|TIE                         |Bucket_Billing - Postpaid|\n",
      "+------------------------------------------------------------------------------------------------------------------------+-------------------------+----------------------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_agg.where(col(\"msisdn\")==605256544).select(\"bucket_list\",\"bucket_latest_interaction\",\"most_common_bucket_with_ties\", \"most_common_bucket\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tablita = spark.read.load('/user/csanc109/projects/churn/port/mobileandfbb/df_port_mobileandfbb_service_20181021_c8_d4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('20180731', 8, '20180930')\n"
     ]
    }
   ],
   "source": [
    "from churn.utils.constants import *\n",
    "import os\n",
    "import sys\n",
    "from pykhaos.utils.date_functions import move_date_n_cycles\n",
    "import datetime as dt       \n",
    "    \n",
    "closing_day = \"20180731\"\n",
    "cycles_horizon = 8\n",
    "end_date = move_date_n_cycles(closing_day, n=cycles_horizon)\n",
    "print(closing_day, cycles_horizon, end_date)\n",
    "\n",
    "if end_date > dt.date.today().strftime(\"%Y%m%d\"):\n",
    "    print(\"Program cannot be run with cycles={0} since closing_day + {0} cycles is in the future {1}\".format(cycles_horizon, end_date))\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading config from file /var/SP/data/home/csanc109/src/devel/use-cases/churn/models/ccc/input/ccc_train_test.yaml\n",
      "Reading internal config from file /var/SP/data/home/csanc109/src/devel/use-cases/churn/datapreparation/config/internal_config.yaml\n",
      "{'campaign_creation': {'campaign_date': '201810',\n",
      "                       'create_csv_file': True,\n",
      "                       'storage_format': 'hdfs'},\n",
      " 'data_preparation': {'ccc_period': 60,\n",
      "                      'force_generation': False,\n",
      "                      'level': 'service',\n",
      "                      'model_target': 'port',\n",
      "                      'port_period': [20180901, 20180930],\n",
      "                      'save': 'true,',\n",
      "                      'segment_filter': 'mobileandfbb',\n",
      "                      'service_set': 'mobile'},\n",
      " 'internal_config_file': '/var/SP/data/home/csanc109/src/devel/use-cases/churn/datapreparation/config/internal_config.yaml',\n",
      " 'predict': {'dd_prepago': [201808],\n",
      "             'do_predict': 'true,',\n",
      "             'use_train_model_predict': True},\n",
      " 'sources': {'ids': {'address': False,\n",
      "                     'billing': True,\n",
      "                     'call_centre_calls': False,\n",
      "                     'campaigns': True,\n",
      "                     'customer': True,\n",
      "                     'customer_aggregations': True,\n",
      "                     'customer_penalties': True,\n",
      "                     'device_catalogue': True,\n",
      "                     'geneva': True,\n",
      "                     'netscout': False,\n",
      "                     'orders': True,\n",
      "                     'spinners': True,\n",
      "                     'tnps': True}},\n",
      " 'train': {'do_train': True, 'save_train_results': True, 'train_alg': 0},\n",
      " 'user_config_file': '/var/SP/data/home/csanc109/src/devel/use-cases/churn/models/ccc/input/ccc_train_test.yaml'}\n",
      "Get port requests table: start=20180901 end=20180930 ref_date=20181021\n",
      "Number of portouts in range 221704\n"
     ]
    }
   ],
   "source": [
    "from churn.datapreparation.config import Config\n",
    "config_obj = Config(filename='/var/SP/data/home/csanc109/src/devel/use-cases/churn/models/ccc/input/ccc_train_test.yaml',\n",
    "                   check_args=False)\n",
    "\n",
    "from churn.datapreparation.data_loader import get_port_requests_table\n",
    "select_cols = [\"msisdn_a\", \"portout_date\"]\n",
    "df_port = get_port_requests_table(spark, config_obj=config_obj, start_date=\"20180901\", end_date=\"20180930\",\n",
    "                                  ref_date=\"20181021\", select_cols=select_cols)\n",
    "\n",
    "print(\"Number of portouts in range {}\".format(df_port.count()))\n",
    "dist_portouts_dates = df_port.select(\"portout_date\").distinct().rdd.map(lambda x: x[\"portout_date\"]).collect()\n",
    "\n",
    "from amdocs_informational_dataset.engine.call_centre_calls import CallCentreCalls\n",
    "ccc = CallCentreCalls(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def union_all(dfs):\n",
    "    if len(dfs) > 1:\n",
    "        return dfs[0].unionAll(union_all(dfs[1:]))\n",
    "    else:\n",
    "        return dfs[0]\n",
    "\n",
    "from pykhaos.utils.date_functions import move_date_n_days\n",
    "n_ccc = -60 # FIXME -abs(config_obj.['data_preparation'][60])\n",
    "dfs = []\n",
    "from pyspark.sql.functions import col\n",
    "from churn.models.ccc.data.ccc_preparation import fill_missing_buckets\n",
    "counter = 0\n",
    "\n",
    "for port_date in dist_portouts_dates:\n",
    "    \n",
    "    print(port_date)\n",
    "    msisdn_list = df_port.where(col(\"portout_date\")==port_date).select(\"msisdn_a\").distinct().rdd.map(lambda x: x[\"msisdn_a\"]).collect()\n",
    "    yyyymmdd_portout_date = str(port_date.split(\" \")[0].replace(\"-\",\"\"))\n",
    "    \n",
    "    print(\"There are {} services with portout_date {}\".format(len(msisdn_list), yyyymmdd_portout_date))\n",
    "    \n",
    "    ccc_start_date = move_date_n_days(yyyymmdd_portout_date, n=n_ccc, str_fmt=\"%Y%m%d\")\n",
    "    ccc_end_date = yyyymmdd_portout_date\n",
    "    _ = ccc.get_ccc_service_df(ccc_end_date, ccc_start_date).where(col(\"msisdn\").isin(msisdn_list))\n",
    "    \n",
    "    df_all = fill_missing_buckets(spark, ccc.all_interactions)\n",
    "    ccc.all_interactions = df_all\n",
    "    df_agg = ccc.add_l2_ccc_variables(self, closing_day)\n",
    "    \n",
    "    dfs.append(df_agg)\n",
    "    counter = counter+1\n",
    "    \n",
    "    if counter==2: break\n",
    "\n",
    "df_agg_all = union_all(dfs)\n",
    "\n",
    "print(\"Number of rows {}\".format(df_agg_all.count()))\n",
    "\n",
    "df_all_model = df_all.select(\"msisdn\", \"most_common_bucket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add data to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from amdocs_informational_dataset.engine.call_centre_calls import CallCentreCalls\n",
    "from pyspark.sql.functions import collect_set, concat, size, coalesce, col, lpad, struct, count as sql_count, lit, min as sql_min, max as sql_max, collect_list, udf, when\n",
    "from pyspark.sql.types import StringType, ArrayType, MapType, StructType, StructField, IntegerType, FloatType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Call Centre Calls Information...\n",
      "Calling to add_l2_ccc_variables....\n"
     ]
    }
   ],
   "source": [
    "from amdocs_informational_dataset.engine.call_centre_calls import CallCentreCalls\n",
    "from pyspark.sql.functions import collect_set, concat, size, coalesce, col, lpad, struct, count as sql_count, lit, min as sql_min, max as sql_max, collect_list, udf, when\n",
    "from pyspark.sql.types import StringType, ArrayType, MapType, StructType, StructField, IntegerType\n",
    "\n",
    "#ccc = CallCentreCalls(spark)\n",
    "ccc_start_date_ = \"20181008\"\n",
    "ccc_end_date_ = \"20181107\"\n",
    "\n",
    "closing_day = ccc_end_date_\n",
    "ccc = CallCentreCalls(spark)\n",
    "df_agg = ccc.get_ccc_service_df(ccc_end_date_, ccc_start_date_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all = ccc.all_interactions\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import array, regexp_extract, concat_ws, upper, sum as sql_sum\n",
    "\n",
    "fichero=\"/user/csanc109/projects/churn/tipis_uci.csv\" # msisdn es msisdn_d\n",
    "df_tipis_uci = spark.read.option(\"delimiter\", \";\").option(\"header\", True).csv(fichero)\n",
    "df_tipis_uci = df_tipis_uci.withColumn(\"tres_tipis\", concat_ws(\"__\",upper(col(\"tipo\")),\n",
    "                                                                    upper(col(\"subtipo\")),\n",
    "                                                                    upper(col(\"razon\"))))\n",
    "df_tipis_uci = df_tipis_uci.withColumn(\"dos_tipis\", concat_ws(\"__\",upper(col(\"tipo\")),\n",
    "                                                                    upper(col(\"subtipo\"))))\n",
    "\n",
    "lista_tipis = df_tipis_uci.select(\"tres_tipis\").distinct().rdd.map(lambda x: x[\"tres_tipis\"]).collect()\n",
    "lista_tipis_dos = df_tipis_uci.select(\"dos_tipis\").distinct().rdd.map(lambda x: x[\"dos_tipis\"]).collect()\n",
    "\n",
    "\n",
    "df_all = df_all.withColumn(\"tres\", concat_ws(\"__\",upper(col(\"INT_Tipo\")),upper(col(\"INT_Subtipo\")),upper(col(\"INT_Razon\"))))\n",
    "df_all = df_all.withColumn(\"dos\", concat_ws(\"__\",upper(col(\"INT_Tipo\")),upper(col(\"INT_Subtipo\"))))\n",
    "\n",
    "# la llamada esta en la lista de tipis que generan churn\n",
    "df_all = df_all.withColumn(\"IS_TIPIS_CHURN\", when(col(\"tres\").isin(lista_tipis), 1).otherwise(0))\n",
    "\n",
    "\n",
    "df_agg = (df_all.groupby('msisdn')\n",
    "                .agg(sql_sum(col(\"IS_TIPIS_CHURN\")).alias(\"NUM_PBMA_SRV\"),\n",
    "                     collect_list('dos').alias(\"lista_de_dos\"))\n",
    "         )\n",
    "\n",
    "df_agg = df_agg.fillna({'NUM_PBMA_SRV': 0})\n",
    "\n",
    "from collections import Counter\n",
    "def get_mode(lst):\n",
    "    if not lst: return None\n",
    "    lst = [ll for ll in lst if ll in lista_tipis_dos]\n",
    "    if not lst: return None\n",
    "    dd = Counter(lst).most_common(2)\n",
    "    return dd[0][0] #if (len(dd) == 1 or dd[0][1] > dd[1][1]) else \"TIE\"\n",
    "\n",
    "get_mode_udf = udf(lambda lst: get_mode(lst), StringType())\n",
    "\n",
    "df_agg = df_agg.withColumn(\"DETALLE_PBMA_SRV\", when(coalesce(size(col(\"lista_de_dos\")), lit(0)) == 0, \"None\").otherwise(get_mode_udf(col(\"lista_de_dos\"))))\n",
    "df_agg = df_agg.withColumn(\"IND_PBMA_SRV\", when(col(\"NUM_PBMA_SRV\")>0, 1).otherwise(0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252961"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg.select(sql_sum(\"IND_PBMA_SRV\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------+------------+\n",
      "|msisdn   |NUM_PBMA_SRV|lista_de_dos                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |DETALLE_PBMA_SRV           |IND_PBMA_SRV|\n",
      "+---------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------+------------+\n",
      "|114518929|0           |[BAJAS/PORTA SALIENTE__BAJA VOZ MOVIL]                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |null                       |0           |\n",
      "|201994397|1           |[PRODUCTOS/SERVICIOS__AHORRO, COBROS/PAGOS__GESTION COBROS, FACTURA__CONSUMOS FUERA TARIFA, FACTURA__DESCUENTOS]                                                                                                                                                                                                                                                                                                                                                                                       |FACTURA__DESCUENTOS        |1           |\n",
      "|374342741|0           |[TARIFAS__DATOS MOVILES]                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |null                       |0           |\n",
      "|437549652|0           |[DESACTIVACION MOVIL__NO USO, NO PROCEDE__INFORMACION PRODUCTOS Y SERVICIOS, ALTA NO RECONOCIDA__OTROS CANALES]                                                                                                                                                                                                                                                                                                                                                                                        |null                       |0           |\n",
      "|600002051|0           |[OTROS__OTROS, RECLAM BAJAS/PORTA__OTROS, FACTURACION__ERROR FACTURA]                                                                                                                                                                                                                                                                                                                                                                                                                                  |null                       |0           |\n",
      "|600009508|0           |[CONS TEC FIBRA TF__NO EMITE/ NO RECIBE, PRODUCTOS/SERVICIOS__TELÉFONO FIJO]                                                                                                                                                                                                                                                                                                                                                                                                                           |null                       |0           |\n",
      "|600011294|0           |[CUELGUE__ANI, CUELGUE__ANI, CUELGUE__BIENVENIDA, INFORMACION__NO COMPLETADA]                                                                                                                                                                                                                                                                                                                                                                                                                          |null                       |0           |\n",
      "|600015335|0           |[INFORMACION__ANI]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |null                       |0           |\n",
      "|600021796|0           |[CUELGUE__MENU PYMES, PROVISION FIBRA__INFO/ DUDAS PROCESO, INFORMACION__CANCELA PORTAB, PROVISION NEBA FIBRA/XDSL__TECNICO NO ASISTE, PROVISION NEBA FIBRA/XDSL__INFO/ DUDAS PROCESO, PROVISION FIBRA__INFO/ DUDAS PROCESO, BAJA__BAJA FIBRA, PROVISION NEBA FIBRA/XDSL__INFO/ DUDAS PROCESO, PROVISION NEBA FIBRA/XDSL__INFO/ DUDAS PROCESO, PROVISION FIBRA__CAMBIO DOMICILIO, DATOS CLIENTE__AREA CLIENTES/MI VF, PROVISION NEBA FIBRA/XDSL__ALTA/AUMENTO, PROVISION NEBA FIBRA/XDSL__ALTA/AUMENTO]|null                       |0           |\n",
      "|600030553|0           |[INFORMACION__NO COMPLETADA, INFORMACION__NO COMPLETADA, DUDAS SOBRE LA INSTALACION__PLAZOS PARA INSTALAR FTTH, DUDAS AUTOINSTALACION__MIGRACION CAMBIO SIM, DUDAS AUTOINSTALACION__MIGRACION CAMBIO SIM]                                                                                                                                                                                                                                                                                              |null                       |0           |\n",
      "|600042920|0           |[SE CORTA__BROMA/SE CORTA/CUELGA, CIERRE RAPIDO__PREGUNTA ABIERTA, TRANSFERENCIA__TARIFAS, TRANSFERENCIA__FACTURA, MODIFICACIÓN__PUNTOS/PEDIDO, INFORMACION__COMPLETADA, INFORMACION__MCARE ROAMING]                                                                                                                                                                                                                                                                                                   |null                       |0           |\n",
      "|600045238|0           |[BAJAS EMPRESAS__BAJA VOZ MOVIL, BAJAS EMPRESAS__BAJA PAQUETE FIBRA]                                                                                                                                                                                                                                                                                                                                                                                                                                   |null                       |0           |\n",
      "|600059955|0           |[INFORMACION__NO COMPLETADA]                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |null                       |0           |\n",
      "|600060835|0           |[TRANSFERENCIA__TRIGGER, TRANSFERENCIA__TRIGGER, INFORMACION__MACROCODIGOS, INFORMACION__PREGUNTA  ABIERTA, CUELGUE__TRIGGER, TRANSFERENCIA__QUIERO COMPRAR, INFORMACION__POLITICA SEGURIDAD, INFORMACION__POLITICA SEGURIDAD, INFORMACION__TRIGGER, INFORMACION__TRIGGER, SI PREST. NO ACEPTA__BLINDAJE, CIERRE RAPIDO__SE CORTA O CUELGA, TRANSFERENCIA__MENU SBR, TRANSFERENCIA__PREGUNTA ABIERTA, TRANSFERENCIA__PREGUNTA ABIERTA, TRANSFERENCIA__PREGUNTA ABIERTA, INFORMACION__COMPLETADA]       |null                       |0           |\n",
      "|600069613|1           |[TRANSFERENCIA__FACREC, TRANSFERENCIA__FACREC, INFORMACION__COMPLETADA, TRANSFERENCIA__FACREC, BAJA__ERROR SISTEMAS]                                                                                                                                                                                                                                                                                                                                                                                   |BAJA__ERROR SISTEMAS       |1           |\n",
      "|600071198|0           |[INFORMACION__NO COMPLETADA]                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |null                       |0           |\n",
      "|600074420|0           |[INFORMACION__NO COMPLETADA]                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |null                       |0           |\n",
      "|600087302|0           |[TERMINAL__FACTURA IMEI, TRANSFERENCIA__DEVOLUCIONES]                                                                                                                                                                                                                                                                                                                                                                                                                                                  |TRANSFERENCIA__DEVOLUCIONES|0           |\n",
      "|600088877|0           |[INFORMACION__COMPLETADA, PROVISION MOVIL__INFO/ DUDAS PROCESO, FACTURACION__FORMATO FACTURA]                                                                                                                                                                                                                                                                                                                                                                                                          |null                       |0           |\n",
      "|600096904|0           |[INFORMACION__PINPUK]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |null                       |0           |\n",
      "+---------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_agg.select(\"msisdn\", \"NUM_PBMA_SRV\", \"lista_de_dos\", \"DETALLE_PBMA_SRV\", \"IND_PBMA_SRV\").show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fichero=\"/user/csanc109/projects/churn/preds_comb_20181107_all.txt\" # msisdn es msisdn_d\n",
    "df_scores = spark.read.option(\"delimiter\", \"|\").option(\"header\", True).csv(fichero)\n",
    "df_scores = df_scores.withColumnRenamed(\"msisdn\", \"msisdn_d_scores\")\n",
    "df_scores = df_scores.where(col(\"msisdn\").isNotNull())\n",
    "\n",
    "hdfs_write_path_common = '/data/udf/vf_es/amdocs_ids/'\n",
    "hdfs_partition_path = 'year=' + str(int(ccc_end_date_[:4])) + '/month=' + str(int(ccc_end_date_[4:6])) + '/day=' + str(int(ccc_end_date_[6:8]))\n",
    "path_service = hdfs_write_path_common +'service/'+hdfs_partition_path\n",
    "df_service = (spark.read.load(path_service)).select(\"msisdn\", \"campo2\").withColumnRenamed(\"msisdn\", \"msisdn_a_service\")\n",
    "\n",
    "df_scores_join = df_scores.join(df_service, on=df_scores[\"msisdn_d_scores\"]==df_service[\"campo2\"], how=\"left\")\n",
    "\n",
    "df_scores_incidencias = df_scores_join.join(df_agg, on=df_scores_join[\"msisdn_a_service\"]==df_agg[\"msisdn\"], how=\"left\")\n",
    "\n",
    "# pyspark cannot write arrays to csv's\n",
    "from pyspark.sql.functions import concat_ws\n",
    "# df_scores_incidencias = df_scores_incidencias.withColumn('bucket_list', concat_ws(\",\", col('bucket_list'))).withColumn('bucket_set', concat_ws(\",\", col('bucket_set')))\n",
    "\n",
    "df_scores_incidencias = df_scores_incidencias.fillna( { 'IND_PBMA_SRV':0, 'DETALLE_PBMA_SRV':\"None\" } )\n",
    "# for col_ in cols_averia+cols_incidencia+[\"num_incidencias\", \"num_averias\", \"num_interactions\", \n",
    "#                                          \"days_since_first_interaction\", \"days_since_latest_interaction\", \n",
    "#                                          \"num_ivr_interactions\"]:\n",
    "#     df_scores_incidencias = df_scores_incidencias.fillna( { col_:0} )\n",
    "    \n",
    "# cols_problemas = [] # Rename columns to make names more readable\n",
    "# for col_ in cols_averia+cols_incidencia:\n",
    "#     col_renamed=re.match(\"^ccc_Raw_(.*)$\", col_).group(1)\n",
    "#     df_scores_incidencias = df_scores_incidencias.withColumnRenamed(col_, col_renamed)\n",
    "#     cols_problemas.append(col_renamed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_scores_incidencias = df_scores_incidencias.drop(\"msisdn\") # anonimized\n",
    "df_scores_incidencias = df_scores_incidencias.withColumnRenamed(\"msisdn_d_scores\", \"msisdn\") # deanonimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_scores_incidencias = df_scores_incidencias.withColumn(\"comb_score\", col(\"comb_score\").cast(FloatType()))\n",
    "df_scores_incidencias = df_scores_incidencias.orderBy('comb_score', ascending=False)\n",
    "\n",
    "df_scores_incidencias = df_scores_incidencias.repartition(1)\n",
    "df_scores_incidencias = df_scores_incidencias.where(col(\"msisdn\").isNotNull())\n",
    "# df_scores_incidencias.select(*['msisdn', 'comb_score', 'comb_decile', 'IND_PBMA_SRV', 'DETALLE_PBMA_SRV', 'num_averias', 'num_incidencias', 'num_interactions', 'days_since_first_interaction',\n",
    "#  'days_since_latest_interaction', 'num_ivr_interactions'] + cols_problemas).write.mode('overwrite').format('csv').option('sep', '|').option('header', 'true').save('/tmp/csanc109/churn/preds_comb_20181031_all_incidences.csv.v13')\n",
    "\n",
    "df_scores_incidencias.select(*['msisdn', 'comb_score', 'comb_decile', 'IND_PBMA_SRV', 'DETALLE_PBMA_SRV']).write.mode('overwrite').format('csv').option('sep', '|').option('header', 'true').save('/tmp/csanc109/churn/preds_comb_20181107_all_incidences.csv.20181122_vtipis1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|comb_score|\n",
      "+----------+\n",
      "|       1.0|\n",
      "|       1.0|\n",
      "|       1.0|\n",
      "|  0.999999|\n",
      "|  0.999999|\n",
      "|  0.999999|\n",
      "|  0.999999|\n",
      "|  0.999998|\n",
      "|  0.999998|\n",
      "|  0.999998|\n",
      "+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_scores_incidencias.select(\"comb_score\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'show'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-852525e3b454>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mrdd_histogram_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_scores_incidencias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mrdd_histogram_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'show'"
     ]
    }
   ],
   "source": [
    "# def create_hist(rdd_histogram_data):\n",
    "#     heights = np.array(rdd_histogram_data[1])\n",
    "#     full_bins = rdd_histogram_data[0]\n",
    "#     mid_point_bins = full_bins[:-1]\n",
    "#     widths = [abs(i - j) for i, j in zip(full_bins[:-1], full_bins[1:])]\n",
    "#     bar = plt.bar(mid_point_bins, heights, width=widths, color='b')\n",
    "#     return bar\n",
    "\n",
    "# rdd_histogram_data = df_scores_incidencias.select(\"score\").rdd.flatMap(lambda x: x).histogram(20)\n",
    "# rdd_histogram_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
