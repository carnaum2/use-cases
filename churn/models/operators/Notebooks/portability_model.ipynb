{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "USECASES_SRC = os.path.join(os.environ.get('BDA_USER_HOME', ''), \"repositorios\", \"use-cases\")\n",
    "if USECASES_SRC not in sys.path: \n",
    "    sys.path.append(USECASES_SRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PYKHAOS_SRC = os.path.join(os.environ.get('BDA_USER_HOME', ''), \"repositorios\")\n",
    "if PYKHAOS_SRC not in sys.path: \n",
    "    sys.path.append(PYKHAOS_SRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from common.src.main.python.utils.hdfs_generic import *\n",
    "import os\n",
    "\n",
    "MAX_N_EXECUTORS=15\n",
    "MIN_N_EXECUTORS=1\n",
    "N_CORES_EXECUTOR=4\n",
    "EXECUTOR_IDLE_MAX_TIME=120\n",
    "EXECUTOR_MEMORY='32g'\n",
    "DRIVER_MEMORY='16g'\n",
    "N_CORES_DRIVER=1\n",
    "MEMORY_OVERHEAD=N_CORES_EXECUTOR*2048\n",
    "#QUEUE=\"root.datascience.normal\"\n",
    "QUEUE=\"root.BDPtenants.es.medium\"\n",
    "\n",
    "BDA_CORE_VERSION=\"1.0.0\"\n",
    "\n",
    "SPARK_COMMON_OPTS=os.environ.get('SPARK_COMMON_OPTS', '')\n",
    "SPARK_COMMON_OPTS+=\" --executor-memory %s --driver-memory %s\" % (EXECUTOR_MEMORY, DRIVER_MEMORY)\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.shuffle.manager=tungsten-sort\"\n",
    "SPARK_COMMON_OPTS+=\"  --queue %s\" % QUEUE\n",
    "APP_NAME='new_portability_model'\n",
    "\n",
    "# Dynamic allocation configuration\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.driver.allowMultipleContexts=true\"\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.dynamicAllocation.enabled=true\"\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.shuffle.service.enabled=true\"\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.dynamicAllocation.maxExecutors=%s\" % (MAX_N_EXECUTORS)\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.dynamicAllocation.minExecutors=%s\" % (MIN_N_EXECUTORS)\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.dynamicAllocation.executorIdleTimeout=%s\" % (EXECUTOR_IDLE_MAX_TIME)\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.ui.port=58201\"\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.port.maxRetries=200\"\n",
    "SPARK_COMMON_OPTS+=\" --executor-cores=%s\" % (N_CORES_EXECUTOR)\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.app.name=%s\" % (APP_NAME)\n",
    "\n",
    "BDA_ENV = os.environ.get('BDA_USER_HOME', '')\n",
    "\n",
    "# Attach bda-core-ra codebase\n",
    "SPARK_COMMON_OPTS+=\" --files \\\n",
    "{}/scripts/properties/red_agent/nodes.properties,\\\n",
    "{}/scripts/properties/red_agent/nodes-de.properties,\\\n",
    "{}/scripts/properties/red_agent/nodes-es.properties,\\\n",
    "{}/scripts/properties/red_agent/nodes-ie.properties,\\\n",
    "{}/scripts/properties/red_agent/nodes-it.properties,\\\n",
    "{}/scripts/properties/red_agent/nodes-pt.properties,\\\n",
    "{}/scripts/properties/red_agent/nodes-uk.properties\".format(*[BDA_ENV]*7)\n",
    "\n",
    "os.environ[\"SPARK_COMMON_OPTS\"] = SPARK_COMMON_OPTS\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"%s pyspark-shell \" % SPARK_COMMON_OPTS\n",
    "\n",
    "#print os.environ.get('SPARK_COMMON_OPTS', '')\n",
    "#print os.environ.get('PYSPARK_SUBMIT_ARGS', '')\n",
    "\n",
    "sc, sparkSession, sqlContext = run_sc()\n",
    "print sc.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This literal_eval is needed since \n",
    "# we have to read from a textfile\n",
    "# which is formatted as python objects.\n",
    "# It is totally safe.\n",
    "from ast import literal_eval\n",
    "\n",
    "# Standard Library stuff:\n",
    "from functools import partial\n",
    "from datetime import date, timedelta, datetime\n",
    "\n",
    "# Numpy stuff\n",
    "from numpy import (nan as np_nan, round as np_round, int64 as np_int64)\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Spark stuff\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import StorageLevel\n",
    "from pyspark.sql.functions import (udf, col, decode, when, lit, lower, upper, concat,\n",
    "                                   translate, count, sum as sql_sum, max as sql_max, min as sql_min,\n",
    "                                   round, \n",
    "                                   mean, stddev, datediff,\n",
    "                                   length,\n",
    "                                   countDistinct,\n",
    "                                   hour, date_format, collect_set, collect_list,\n",
    "                                   year, month, dayofmonth,\n",
    "                                   rank, expr, lag, coalesce, row_number,\n",
    "                                   isnull, isnan,\n",
    "                                   unix_timestamp,\n",
    "                                   regexp_replace\n",
    "                                  )\n",
    "\n",
    "from pyspark.sql.types import DoubleType, StringType, IntegerType, ArrayType, FloatType, StructType, StructField\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from pyspark.sql.functions import row_number, col\n",
    "\n",
    "from pyspark.sql import DataFrameStatFunctions as statFunc\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "from subprocess import Popen, PIPE\n",
    "import datetime, calendar\n",
    "from pyspark.sql import functions as F\n",
    "import datetime as dt\n",
    "\n",
    "from pyspark.ml.feature import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from common.src.main.python.utils.hdfs_generic import *\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "# Spark utils\n",
    "from pyspark.sql.functions import (udf, col, decode, when, lit, lower, concat,\n",
    "                                   translate, count, max, avg, min as sql_min,\n",
    "                                   greatest,\n",
    "                                   least,\n",
    "                                   isnull,\n",
    "                                   isnan,\n",
    "                                   struct,\n",
    "                                   substring,\n",
    "                                   size,\n",
    "                                   length,\n",
    "                                   year,\n",
    "                                   month,\n",
    "                                   dayofmonth,\n",
    "                                   unix_timestamp,\n",
    "                                   date_format,\n",
    "                                   from_unixtime,\n",
    "                                   datediff,\n",
    "                                   to_date,\n",
    "                                   desc,\n",
    "                                   asc,\n",
    "                                   countDistinct,\n",
    "                                   row_number,\n",
    "                                   regexp_replace,\n",
    "                                   lpad,\n",
    "                                   rpad,\n",
    "                                   trim,\n",
    "                                   split,\n",
    "                                   coalesce,\n",
    "                                   array)\n",
    "from pyspark.sql import Row, DataFrame, Column, Window\n",
    "from pyspark.sql.types import DoubleType, StringType, IntegerType, DateType, ArrayType\n",
    "# from pyspark.ml import Pipeline\n",
    "# from pyspark.ml.classification import RandomForestClassifier\n",
    "# from pyspark.ml.feature import StringIndexer, VectorIndexer, VectorAssembler, SQLTransformer, OneHotEncoder\n",
    "# from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "# from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder\n",
    "         .master(\"yarn\")\n",
    "         .config(\"spark.submit.deployMode\", \"client\")\n",
    "         .config(\"spark.ui.showConsoleProgress\", \"true\")\n",
    "         .enableHiveSupport()\n",
    "         .getOrCreate()\n",
    "         )\n",
    "\n",
    "# sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#import re\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "\n",
    "def printHTML(df, sample=7):\n",
    "    display(HTML(tabulate.tabulate([df.columns]+df.take(sample), tablefmt='html', headers='firstrow')))\n",
    "    \n",
    "# Spark utils\n",
    "from pyspark.sql.functions import (array_contains, bround, col, collect_set, concat, count, decode, desc, \n",
    "                                   isnull, length, lit, lower, lpad, max as sql_max, \n",
    "                                   size, struct, substring, sum as sql_sum, \n",
    "                                   translate, trim, udf, upper, when\n",
    "                                  )\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType, StructField, StructType\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos ids con las columnas que nos interesan: HAY QUE AUTOMATIZARLO TAMBIÉN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/var/SP/data/home/carnaum2/ids/amdocs_inf_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.main.python.configuration.constants import ENVIRONMENT\n",
    "from src.main.python.utils.spark_creator import SparkCreator\n",
    "from src.main.python.pipelines.billing import Billing\n",
    "from src.main.python.pipelines.breakdowns import Breakdowns\n",
    "from src.main.python.pipelines.call_centre_calls import CallCentreCalls\n",
    "from src.main.python.pipelines.campaigns import Campaigns\n",
    "from src.main.python.pipelines.claims import Claims\n",
    "from src.main.python.pipelines.competitors_web import CompWeb\n",
    "from src.main.python.pipelines.customer import Customer\n",
    "from src.main.python.pipelines.customer_aggregations import Customer_Aggregations\n",
    "from src.main.python.pipelines.penalties import PenaltiesCustomer, PenaltiesServices\n",
    "from src.main.python.pipelines.device_catalogue import Device_Catalogue\n",
    "from src.main.python.pipelines.geneva_traffic import GenevaVoiceTypeUsage\n",
    "from src.main.python.pipelines.geneva_traffic import GenevaVoiceUsage\n",
    "from src.main.python.pipelines.geneva_traffic import GenevaRoamVoiceUsage\n",
    "from src.main.python.pipelines.geneva_traffic import GenevaDataUsage\n",
    "from src.main.python.pipelines.geneva_traffic import GenevaRoamDataUsage\n",
    "from src.main.python.pipelines.mobile_spinners_extractor import Mobile_spinners_extractor\n",
    "from src.main.python.pipelines.netscout import Netscout\n",
    "from src.main.python.pipelines.orders import Orders\n",
    "from src.main.python.pipelines.orders_aggregations import OrdersAgg\n",
    "from src.main.python.pipelines.permsandprefs import Perms_and_prefs\n",
    "from src.main.python.pipelines.services import Services\n",
    "from src.main.python.pipelines.services_problems import ServiceProblems\n",
    "from src.main.python.pipelines.tech_suprt import TechSupport\n",
    "from src.main.python.pipelines.tgs import Tgs\n",
    "from src.main.python.pipelines.tnps import Tnps\n",
    "from src.main.python.pipelines.orders_sla import Orders_sla\n",
    "from src.main.python.pipelines.tickets import Tickets\n",
    "from src.main.python.pipelines.refund import Refund\n",
    "sc = SparkCreator()\n",
    "date = \"20191014\"\n",
    "module_constructors = (Customer(sc, date, ENVIRONMENT),\n",
    "                       Services(sc, date, ENVIRONMENT),\n",
    "                       Customer_Aggregations(sc, date, ENVIRONMENT),\n",
    "                       Billing(sc, date, ENVIRONMENT),\n",
    "                       Campaigns(sc, date, date, ENVIRONMENT),\n",
    "                       GenevaVoiceTypeUsage(sc, date, date, ENVIRONMENT),\n",
    "                       GenevaVoiceUsage(sc, date, date, ENVIRONMENT),\n",
    "                       GenevaDataUsage(sc, date, date, ENVIRONMENT),\n",
    "                       #GenevaRoamVoiceUsage(sc, date, date, ENVIRONMENT),\n",
    "                       #GenevaRoamDataUsage(sc, date, date, ENVIRONMENT),\n",
    "                       Orders(sc, date, date, ENVIRONMENT),\n",
    "                       OrdersAgg(sc, date, date, ENVIRONMENT),\n",
    "                       PenaltiesCustomer(sc, date, ENVIRONMENT),\n",
    "                       PenaltiesServices(sc, date, ENVIRONMENT),\n",
    "                       Device_Catalogue(sc, date, date, ENVIRONMENT),\n",
    "                       Perms_and_prefs(sc, date, ENVIRONMENT),\n",
    "                       CallCentreCalls(sc, date, date, ENVIRONMENT),\n",
    "                       Tnps(sc, date, date, ENVIRONMENT),\n",
    "                       Tgs(sc, date, ENVIRONMENT),\n",
    "                       Claims(sc, date, ENVIRONMENT),\n",
    "                       Breakdowns(sc, date, ENVIRONMENT),\n",
    "                       TechSupport(sc, date, ENVIRONMENT),\n",
    "                       Netscout(sc, date, date, ENVIRONMENT),\n",
    "                       CompWeb(sc, date, date, ENVIRONMENT),\n",
    "                       ServiceProblems(sc, date, ENVIRONMENT),\n",
    "                       Mobile_spinners_extractor(sc, date, ENVIRONMENT),\n",
    "                       Orders_sla(sc, date, ENVIRONMENT),\n",
    "                       Refund(sc, date, ENVIRONMENT),\n",
    "                       #Tickets(sc, date, ENVIRONMENT)\n",
    "                       )\n",
    "na_map = {}\n",
    "for module in module_constructors:\n",
    "    metadata = module.set_module_metadata()\n",
    "    na_map.update(metadata)\n",
    "final_map = {colmn: na_map[colmn][0] for colmn in na_map.keys()\n",
    "             if colmn in na_map.keys() and na_map[colmn][1] != \"id\"}\n",
    "categ_map = {colmn: na_map[colmn][0] for colmn in na_map.keys()\n",
    "             if colmn in na_map.keys() and na_map[colmn][1] == \"categorical\"}\n",
    "numeric_map = {colmn: na_map[colmn][0] for colmn in na_map.keys()\n",
    "               if colmn in na_map.keys() and na_map[colmn][1] == \"numerical\"}\n",
    "date_map = {colmn: na_map[colmn][0] for colmn in na_map.keys()\n",
    "            if colmn in na_map.keys() and na_map[colmn][1] == \"date\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_variables=numeric_map.keys()\n",
    "numeric_variables.append('msisdn') #añado el msisdn para hacer el join después"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_numeric_selection(year_, month_, day_):\n",
    "\n",
    "    ids_completo = (spark.read.load(\n",
    "            '/data/udf/vf_es/amdocs_inf_dataset/amdocs_ids_service_level/year=' + year_ + '/month=' + month_ + '/day=' + day_))\n",
    "\n",
    "    ids_numeric=ids_completo.select(numeric_variables) #aqui cojo las variables que se han seleccionado\n",
    "\n",
    "    return ids_numeric\n",
    "\n",
    "#Guardo este ids para train y test y luego hago inner join on msisdn con las columnas de target que habiamos creado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_julio_numeric=ids_numeric_selection('2019','7','31')\n",
    "ids_sept_numeric=ids_numeric_selection('2019','9','30') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricas=[item[0] for item in ids_julio_numeric.dtypes if item[1].startswith('string')] #elimino estas variables que no son numericas: no deberian aparecer (carlos lo va a corregir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_julio_numeric=ids_julio_numeric.drop('tgs_ind_riesgo_o2',\n",
    " 'tgs_ind_riesgo_mm',\n",
    " 'tgs_ind_riesgo_mv',\n",
    " 'tgs_meses_fin_dto_ok',\n",
    " 'CCC_L2_bucket_1st_interaction',\n",
    " 'CCC_L2_bucket_latest_interaction',\n",
    " 'CCC_L2_first_interaction',\n",
    " 'Cust_Agg_flag_prepaid_nc',\n",
    " 'tgs_ind_riesgo_max',\n",
    " 'tgs_sol_24m',\n",
    " 'CCC_L2_latest_interaction',\n",
    " 'tgs_tg_marta',\n",
    " 'tgs_blinda_bi_pos_n12')\n",
    "\n",
    "ids_sept_numeric=ids_sept_numeric.drop('tgs_ind_riesgo_o2',\n",
    " 'tgs_ind_riesgo_mm',\n",
    " 'tgs_ind_riesgo_mv',\n",
    " 'tgs_meses_fin_dto_ok',\n",
    " 'CCC_L2_bucket_1st_interaction',\n",
    " 'CCC_L2_bucket_latest_interaction',\n",
    " 'CCC_L2_first_interaction',\n",
    " 'Cust_Agg_flag_prepaid_nc',\n",
    " 'tgs_ind_riesgo_max',\n",
    " 'tgs_sol_24m',\n",
    " 'CCC_L2_latest_interaction',\n",
    " 'tgs_tg_marta',\n",
    " 'tgs_blinda_bi_pos_n12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Una vez tenemos el ids con las columnas que necesitamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from churn.analysis.triggers.base_utils.base_utils import get_customer_base, _is_null_date, get_customers, get_services\n",
    "from pykhaos.utils.date_functions import move_date_n_yearmonths, get_last_day_of_month\n",
    "from pykhaos.utils.date_functions import get_next_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Filtro por clientes activos desde hace más de 3 meses y con línea móvil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_filter(ids_completo,fecha):\n",
    "    \n",
    "    #Filtramos por clientes activos y con línea móvil\n",
    "    \n",
    "    ids_filtered=ids_completo.filter((col('Serv_RGU')=='mobile')&\n",
    "                                   ((col('Cust_COD_ESTADO_GENERAL')=='01')|(col('Cust_COD_ESTADO_GENERAL')=='09')))\n",
    "    \n",
    "    #Filtramos por clientes que estuvieran en cartera hace 3 meses\n",
    "    \n",
    "    year_month_previo=move_date_n_yearmonths(fecha[0:6], -3) #obtenemos yyyymm de 3 meses antes\n",
    "    \n",
    "    fecha_previa=get_last_day_of_month(year_month_previo+'01') #Given a string date (format YYYY-MM-DD or YYYYMMDD) or a datetime object,returns the last day of the month. Eg. mydate=2018-03-01 --> returns 2018-03-31\n",
    "    \n",
    "    #cartera de la foto de hace 3 meses\n",
    "    \n",
    "    base_previa=get_customer_base(spark,fecha_previa, add_columns = None, active_filter = True, add_columns_customer=None)\n",
    "\n",
    "    msisdn_fecha_previa=base_previa.select('msisdn').distinct() \n",
    "\n",
    "    #me quedo con los clientes que estén en la cartera de hace 3 meses\n",
    "    \n",
    "    df_activos=ids_filtered.join(msisdn_fecha_previa, on='msisdn',how='inner') #nos quedamos con los que estaban hace 3 meses\n",
    "    \n",
    "    return df_activos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got columns from customers: 'NUM_CLIENTE,CLASE_CLI_COD_CLASE_CLIENTE,COD_ESTADO_GENERAL,NIF_CLIENTE,X_CLIENTE_PRUEBA,NIF_FACTURACION,FECHA_MIGRACION,SUPEROFERTA'\n",
      "Requested additional columns: ''\n"
     ]
    }
   ],
   "source": [
    "df_no_etiquetado_julio=ids_filter(ids_julio_numeric,'20190731')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got columns from customers: 'NUM_CLIENTE,CLASE_CLI_COD_CLASE_CLIENTE,COD_ESTADO_GENERAL,NIF_CLIENTE,X_CLIENTE_PRUEBA,NIF_FACTURACION,FECHA_MIGRACION,SUPEROFERTA'\n",
      "Requested additional columns: ''\n"
     ]
    }
   ],
   "source": [
    "df_no_etiquetado_sept=ids_filter(ids_sept_numeric,'20190930')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_etiquetado_julio.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_etiquetado_sept.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estas funciones se utilizan luego en la función finañ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_portab_next_month(fecha,spark):  #devuelve la tabla de portabilidades del mes siguiente al especificado, eliminando las repetidas y quedándose con la última solicitud realizada\n",
    "    \n",
    "    solicitudes_portab_complete= spark.read.table('raw_es.portabilitiesinout_sopo_solicitud_portabilidad') #lectura de tabla de portabilidad\n",
    "    \n",
    "    if (int(fecha[4:6]))=='12':\n",
    "\n",
    "        solicitudes_portab_fecha =solicitudes_portab_complete.filter((col('year') == int(fecha[0:4])+1)&(col('month') == 1))                                           \n",
    "\n",
    "    else:  \n",
    "        \n",
    "        solicitudes_portab_fecha =solicitudes_portab_complete.filter((col('year') == int(fecha[0:4]))& (col('month') == int(fecha[4:6])+1))\n",
    "\n",
    "    #Aplicamos regla para que no se repitan msisdn: si un cliente ha solicitado porta más de una vez, nos quedamos con la última solicitud realizada\n",
    "    \n",
    "    window = Window.partitionBy('SOPO_DS_MSISDN1').orderBy(col('SOPO_DS_FECHA_SOLICITUD').desc())\n",
    "\n",
    "    solicitudes_portab=solicitudes_portab_fecha.withColumn(\"rank\", row_number().over(window)).filter(col(\"rank\") == 1)\n",
    "\n",
    "    return solicitudes_portab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_portab_operators(operator,portab_total): #te da los msisdn que hacen portabilidad a un operador especificado dada una tabla de portabilidades\n",
    "\n",
    "    if operator=='masmovil':\n",
    "        \n",
    "        portab_masmovil=portab_total.filter((col(\"SOPO_CO_RECEPTOR\") == \"AMENA\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"735014\")\n",
    "            | (col(\"SOPO_CO_RECEPTOR\") == \"AMENA\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"735044\")\n",
    "            | (col(\"SOPO_CO_RECEPTOR\") == \"AIRTEL\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"725303\")\n",
    "            | (col(\"SOPO_CO_RECEPTOR\") == \"AMENA\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"735054\")\n",
    "            | (col(\"SOPO_CO_RECEPTOR\") == \"MOVISTAR\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"715501\")\n",
    "            | (col(\"SOPO_CO_RECEPTOR\") == \"YOIGO\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"0\")\n",
    "            | (col(\"SOPO_CO_RECEPTOR\") == \"AIRTEL\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"725503\")                      \n",
    "            | (col(\"SOPO_CO_RECEPTOR\") == \"VIZZAVI\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"970513\")                      \n",
    "            | (col(\"SOPO_CO_RECEPTOR\") == \"AIRTEL\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"725203\") \n",
    "            | (col(\"SOPO_CO_RECEPTOR\") == \"VIZZAVI\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"970213\"))\n",
    "\n",
    "\n",
    "        id_masmovil=portab_masmovil.select('SOPO_DS_MSISDN1').collect() #seleccionamos msisdn\n",
    "\n",
    "        clientes_masmovil=[] #guardamos msisdn en una lista\n",
    "\n",
    "        for i in range(0,len(id_masmovil)):\n",
    "            v=str(id_masmovil[i][0])\n",
    "            clientes_masmovil.append(v)\n",
    "\n",
    "        \n",
    "        return clientes_masmovil\n",
    "\n",
    "\n",
    "\n",
    "    if operator=='movistar':\n",
    "        \n",
    "        portab_movistar=portab_total.filter((col(\"SOPO_CO_RECEPTOR\") == \"MOVISTAR\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"0\")\n",
    "            | (col(\"SOPO_CO_RECEPTOR\") == \"MOVISTAR\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"715401\")\n",
    "            | (col(\"SOPO_CO_RECEPTOR\") == \"TUENTI_MOVIL\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"0\"))\n",
    "\n",
    "\n",
    "        id_movistar=portab_movistar.select('SOPO_DS_MSISDN1').collect()\n",
    "\n",
    "        clientes_movistar=[]\n",
    "\n",
    "        for i in range(0,len(id_movistar)):\n",
    "            v=str(id_movistar[i][0])\n",
    "            clientes_movistar.append(v)\n",
    "            \n",
    "        return clientes_movistar\n",
    "    \n",
    "    \n",
    "    if operator=='orange':\n",
    "        \n",
    "        \n",
    "        portab_orange=portab_total.filter((col(\"SOPO_CO_RECEPTOR\") == \"AMENA\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"0\")\n",
    "        | (col(\"SOPO_CO_RECEPTOR\") == \"JAZZTEL\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"0\")\n",
    "        | (col(\"SOPO_CO_RECEPTOR\") == \"EPLUS\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"0\"))\n",
    "\n",
    "\n",
    "        id_orange=portab_orange.select('SOPO_DS_MSISDN1').collect()\n",
    "\n",
    "        clientes_orange=[]\n",
    "\n",
    "        for i in range(0,len(id_orange)):\n",
    "            v=str(id_orange[i][0])\n",
    "            clientes_orange.append(v)\n",
    "            \n",
    "        return clientes_orange\n",
    "    \n",
    "    if operator=='otros':\n",
    "        \n",
    "        portab_otros=portab_total.filter(~((col(\"SOPO_CO_RECEPTOR\") == \"AMENA\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"735014\")\n",
    "            | (col(\"SOPO_CO_RECEPTOR\") == \"AMENA\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"735044\")\n",
    "            | (col(\"SOPO_CO_RECEPTOR\") == \"AIRTEL\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"725303\")\n",
    "            | (col(\"SOPO_CO_RECEPTOR\") == \"AMENA\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"735054\")\n",
    "            | (col(\"SOPO_CO_RECEPTOR\") == \"MOVISTAR\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"715501\")\n",
    "            | (col(\"SOPO_CO_RECEPTOR\") == \"YOIGO\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"0\")\n",
    "            | (col(\"SOPO_CO_RECEPTOR\") == \"AIRTEL\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"725503\")                      \n",
    "            | (col(\"SOPO_CO_RECEPTOR\") == \"VIZZAVI\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"970513\")                      \n",
    "            | (col(\"SOPO_CO_RECEPTOR\") == \"AIRTEL\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"725203\") \n",
    "            | (col(\"SOPO_CO_RECEPTOR\") == \"VIZZAVI\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"970213\")\n",
    "            | (col(\"SOPO_CO_RECEPTOR\") == \"AMENA\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"0\")\n",
    "            | (col(\"SOPO_CO_RECEPTOR\") == \"JAZZTEL\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"0\")\n",
    "            | (col(\"SOPO_CO_RECEPTOR\") == \"EPLUS\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"0\")\n",
    "            |(col(\"SOPO_CO_RECEPTOR\") == \"MOVISTAR\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"0\")\n",
    "            | (col(\"SOPO_CO_RECEPTOR\") == \"MOVISTAR\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"715401\")\n",
    "            | (col(\"SOPO_CO_RECEPTOR\") == \"TUENTI_MOVIL\") & (col(\"SOPO_CO_NRN_RECEPTORVIR\") == \"0\")))\n",
    "    \n",
    "\n",
    "        id_otros=portab_otros.select('SOPO_DS_MSISDN1').collect()\n",
    "\n",
    "        clientes_otros=[]\n",
    "\n",
    "        for i in range(0,len(id_otros)):\n",
    "            v=str(id_otros[i][0])\n",
    "            clientes_otros.append(v)\n",
    "        \n",
    "        return clientes_otros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_multiclase(df_no_etiquetado,fecha,spark): #devuelve el dataframe con un target multiclase y uno para cada clase y elimina los que no hacen porta\n",
    "    \n",
    "    portab_total=get_portab_next_month(fecha,spark)\n",
    "    \n",
    "    clientes_masmovil=get_portab_operators('masmovil',portab_total)\n",
    "    clientes_movistar=get_portab_operators('movistar',portab_total)\n",
    "    clientes_orange=get_portab_operators('orange',portab_total)\n",
    "    clientes_otros=get_portab_operators('otros',portab_total)\n",
    "\n",
    "    \n",
    "    df_etiquetado=df_no_etiquetado.withColumn('Operador_target',\n",
    "                when(df_no_etiquetado['msisdn'].isin(clientes_masmovil),1).otherwise(\n",
    "                    when(df_no_etiquetado['msisdn'].isin(clientes_movistar),2).otherwise(\n",
    "                        when(df_no_etiquetado['msisdn'].isin(clientes_orange),3).otherwise(\n",
    "                            when(df_no_etiquetado['msisdn'].isin(clientes_otros),4).otherwise(0))))) \n",
    "    \n",
    "    df_etiquetado=df_etiquetado.filter(col('Operador_target')!=0) #elimino los que no hacen porta\n",
    "\n",
    "    df_etiquetado_operadores=df_etiquetado.withColumn('masmovil',when(df_etiquetado['Operador_target']==1,1).otherwise(0)).withColumn('movistar',when(df_etiquetado['Operador_target']==2,1).otherwise(0)).withColumn('orange',when(df_etiquetado['Operador_target']==3,1).otherwise(0)).withColumn('otros',when(df_etiquetado['Operador_target']==4,1).otherwise(0))\n",
    "    \n",
    "    return df_etiquetado_operadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final=get_target_multiclase(df_no_etiquetado_julio,'20190731',spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final=get_target_multiclase(df_no_etiquetado_sept,'20190930',spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final.groupby('Operador_target').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final.groupby('Operador_target').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_elim=['msisdn','Operador_target','masmovil','movistar','orange','otros']\n",
    "\n",
    "variables = [i for i in train_final.columns if i not in variables_elim] #cojo las variables predictoras para el assemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexer_assembler(df_no_transformed): \n",
    "    \n",
    "    assembler = VectorAssembler(inputCols=variables, outputCol=\"features\")\n",
    "\n",
    "    stages = [assembler]\n",
    "\n",
    "    pipeline = Pipeline(stages = stages)\n",
    "    \n",
    "    pipeline_fit = pipeline.fit(df_no_transformed)\n",
    "    \n",
    "    df_transformed=pipeline_fit.transform(df_no_transformed)\n",
    "    \n",
    "    return df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model2=indexer_assembler(train_final)\n",
    "test_model2=indexer_assembler(test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier\n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "#LIFT\n",
    "\n",
    "import utils_model\n",
    "from utils_model import get_lift\n",
    "getScore = udf(lambda prob: float(prob[1]), DoubleType())\n",
    "\n",
    "#FEATURE IMPORTANCE\n",
    "\n",
    "def ExtractFeatureImp(featureImp, dataset, featuresCol):\n",
    "   list_extract = []\n",
    "   for i in dataset.schema[featuresCol].metadata[\"ml_attr\"][\"attrs\"]:\n",
    "       list_extract = list_extract + dataset.schema[featuresCol].metadata[\"ml_attr\"][\"attrs\"][i]\n",
    "   varlist = pd.DataFrame(list_extract)\n",
    "   varlist['score'] = varlist['idx'].apply(lambda x: featureImp[x])\n",
    "   return(varlist.sort_values('score', ascending = False))\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MasMóvil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balanceando clases:\n",
    "\n",
    "n=float(21508)/float(99265-21508) #proporcion que hay que coger de los que no solicitan porta a masmovil (misma que los que sí: nº clientes que van a masmovil)\n",
    "\n",
    "train_masmovil=train_model2.filter(train_model2['Operador_target']==1).union(train_model2.filter(train_model2['Operador_target']!=1).sample(False, n,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-39925ff537b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGBTClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeaturesCol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'features'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxDepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxIter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel2_masmovil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_masmovil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/cloudera/parcels/SPARK2/lib/spark2/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/opt/cloudera/parcels/SPARK2/lib/spark2/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/SPARK2/lib/spark2/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \"\"\"\n\u001b[1;32m    284\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda-2.5.0/lib/python2.7/site-packages/py4j/java_gateway.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda-2.5.0/lib/python2.7/site-packages/py4j/java_gateway.pyc\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda-2.5.0/lib/python2.7/site-packages/py4j/java_gateway.pyc\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda-2.5.0/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "target='masmovil'\n",
    "\n",
    "#model = RandomForestClassifier(featuresCol = 'features', labelCol = target, maxDepth=8, numTrees=3000)\n",
    "\n",
    "model = GBTClassifier(featuresCol = 'features',labelCol=target, maxDepth=5,maxIter=20)\n",
    "\n",
    "model2_masmovil = model.fit(train_masmovil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_masmovil_train=model2_masmovil.transform(train_masmovil)\n",
    "pred_masmovil_test=model2_masmovil.transform(test_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol= 'masmovil' , metricName='areaUnderROC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_masmovil_train = evaluator.evaluate(pred_masmovil_train)\n",
    "auc_masmovil_test = evaluator.evaluate(pred_masmovil_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_masmovil_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_masmovil_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_masmovil_test=pred_masmovil_test.withColumn(\"score\", getScore(col(\"probability\")).cast(DoubleType()))\n",
    "pred_masmovil_test=pred_masmovil_test.orderBy('score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift_masmovil = get_lift(pred_masmovil_test, 'score', target, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d ,l in lift_masmovil:\n",
    "   print str(d) + \": \" + str(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_masmovil = ExtractFeatureImp(model2_masmovil.featureImportances ,pred_masmovil_test, \"features\")[0:30]\n",
    "feat_imp_masmovil = feat_imp_masmovil.sort_values(by = ['score'], ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp=feat_imp_masmovil\n",
    "\n",
    "features = feat_imp['name']\n",
    "importances = feat_imp['score']\n",
    "indices = feat_imp['idx']\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOVISTAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=float(33103)/float(99265-33103) #proporcion que hay que coger de los que no solicitan porta a masmovil (misma que los que sí: nº clientes que van a masmovil)\n",
    "\n",
    "train_movistar=train_model2.filter(train_model2['Operador_target']==2).union(train_model2.filter(train_model2['Operador_target']!=2).sample(False, n,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target='movistar'\n",
    "#model = RandomForestClassifier(featuresCol = 'features', labelCol = target, maxDepth=8, numTrees=3000)\n",
    "model = GBTClassifier(featuresCol = 'features',labelCol=target, maxDepth=5,maxIter=20)\n",
    "model2_movistar = model.fit(train_movistar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_movistar_train=model2_movistar.transform(train_movistar)\n",
    "pred_movistar_test=model2_movistar.transform(test_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol= 'movistar' , metricName='areaUnderROC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_movistar_train = evaluator.evaluate(pred_movistar_train)\n",
    "auc_movistar_test = evaluator.evaluate(pred_movistar_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_movistar_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_movistar_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_movistar_test=pred_movistar_test.withColumn(\"score\", getScore(col(\"probability\")).cast(DoubleType()))\n",
    "pred_movistar_test=pred_movistar_test.orderBy('score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift_movistar = get_lift(pred_movistar_test, 'score', target, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d ,l in lift_movistar:\n",
    "   print str(d) + \": \" + str(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_movistar = ExtractFeatureImp(model2_movistar.featureImportances ,pred_movistar_test, \"features\")[0:30]\n",
    "feat_imp_movistar = feat_imp_movistar.sort_values(by = ['score'], ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feat_imp=feat_imp_movistar\n",
    "\n",
    "features = feat_imp['name']\n",
    "importances = feat_imp['score']\n",
    "indices = feat_imp['idx']\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=float(26206)/float(99265-26206) #proporcion que hay que coger de los que no solicitan porta a masmovil (misma que los que sí: nº clientes que van a masmovil)\n",
    "\n",
    "train_orange=train_model2.filter(train_model2['Operador_target']==3).union(train_model2.filter(train_model2['Operador_target']!=3).sample(False, n,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target='orange'\n",
    "#model = RandomForestClassifier(featuresCol = 'features', labelCol = target, maxDepth=8, numTrees=3000)\n",
    "model = GBTClassifier(featuresCol = 'features',labelCol=target, maxDepth=5,maxIter=20)\n",
    "model2_orange = model.fit(train_orange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_orange_train=model2_orange.transform(train_orange)\n",
    "pred_orange_test=model2_orange.transform(test_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol= 'orange' , metricName='areaUnderROC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_orange_train = evaluator.evaluate(pred_orange_train)\n",
    "auc_orange_test = evaluator.evaluate(pred_orange_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_orange_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_orange_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_orange_test=pred_orange_test.withColumn(\"score\", getScore(col(\"probability\")).cast(DoubleType()))\n",
    "pred_orange_test=pred_orange_test.orderBy('score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift_orange= get_lift(pred_orange_test, 'score', target, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d ,l in lift_orange:\n",
    "   print str(d) + \": \" + str(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_orange= ExtractFeatureImp(model2_orange.featureImportances ,pred_orange_test, \"features\")[0:30]\n",
    "feat_imp_orange = feat_imp_orange.sort_values(by = ['score'], ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp=feat_imp_orange\n",
    "\n",
    "features = feat_imp['name']\n",
    "importances = feat_imp['score']\n",
    "indices = feat_imp['idx']\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=float(18448)/float(99265-18448) #proporcion que hay que coger de los que no solicitan porta a masmovil (misma que los que sí: nº clientes que van a masmovil)\n",
    "\n",
    "train_otros=train_model2.filter(train_model2['Operador_target']==4).union(train_model2.filter(train_model2['Operador_target']!=4).sample(False, n,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target='otros'\n",
    "#model = RandomForestClassifier(featuresCol = 'features', labelCol = target, maxDepth=8, numTrees=3000)\n",
    "model = GBTClassifier(featuresCol = 'features',labelCol=target, maxDepth=5,maxIter=20)\n",
    "model2_otros = model.fit(train_otros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_otros_train=model2_otros.transform(train_otros)\n",
    "pred_otros_test=model2_otros.transform(test_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol= 'otros' , metricName='areaUnderROC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_otros_train = evaluator.evaluate(pred_otros_train)\n",
    "auc_otros_test = evaluator.evaluate(pred_otros_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_otros_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_otros_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_otros_test=pred_otros_test.withColumn(\"score\", getScore(col(\"probability\")).cast(DoubleType()))\n",
    "pred_otros_test=pred_otros_test.orderBy('score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift_otros= get_lift(pred_otros_test, 'score', target, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d ,l in lift_otros:\n",
    "   print str(d) + \": \" + str(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_otros= ExtractFeatureImp(model2_otros.featureImportances ,pred_otros_test, \"features\")[0:30]\n",
    "feat_imp_otros = feat_imp_otros.sort_values(by = ['score'], ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp=feat_imp_otros\n",
    "\n",
    "features = feat_imp['name']\n",
    "importances = feat_imp['score']\n",
    "indices = feat_imp['idx']\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
