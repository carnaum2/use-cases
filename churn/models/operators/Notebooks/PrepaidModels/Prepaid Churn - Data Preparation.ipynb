{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPAID CHURN - Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of the Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from common.src.main.python.utils.hdfs_generic import *\n",
    "import os\n",
    "\n",
    "MAX_N_EXECUTORS=15\n",
    "MIN_N_EXECUTORS=1\n",
    "N_CORES_EXECUTOR=4\n",
    "EXECUTOR_IDLE_MAX_TIME=120\n",
    "EXECUTOR_MEMORY='32g'\n",
    "DRIVER_MEMORY='16g'\n",
    "N_CORES_DRIVER=1\n",
    "MEMORY_OVERHEAD=N_CORES_EXECUTOR*2048\n",
    "#QUEUE=\"root.datascience.normal\"\n",
    "QUEUE=\"root.BDPtenants.es.medium\"\n",
    "\n",
    "BDA_CORE_VERSION=\"1.0.0\"\n",
    "\n",
    "SPARK_COMMON_OPTS=os.environ.get('SPARK_COMMON_OPTS', '')\n",
    "SPARK_COMMON_OPTS+=\" --executor-memory %s --driver-memory %s\" % (EXECUTOR_MEMORY, DRIVER_MEMORY)\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.shuffle.manager=tungsten-sort\"\n",
    "SPARK_COMMON_OPTS+=\"  --queue %s\" % QUEUE\n",
    "APP_NAME='PrepaidChurnDataPreparation'\n",
    "\n",
    "# Dynamic allocation configuration\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.dynamicAllocation.enabled=true\"\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.shuffle.service.enabled=true\"\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.dynamicAllocation.maxExecutors=%s\" % (MAX_N_EXECUTORS)\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.dynamicAllocation.minExecutors=%s\" % (MIN_N_EXECUTORS)\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.dynamicAllocation.executorIdleTimeout=%s\" % (EXECUTOR_IDLE_MAX_TIME)\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.ui.port=58201\"\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.port.maxRetries=200\"\n",
    "SPARK_COMMON_OPTS+=\" --executor-cores=%s\" % (N_CORES_EXECUTOR)\n",
    "SPARK_COMMON_OPTS+=\" --conf spark.app.name=%s\" % (APP_NAME)\n",
    "\n",
    "BDA_ENV = os.environ.get('BDA_USER_HOME', '')\n",
    "\n",
    "# Attach bda-core-ra codebase\n",
    "SPARK_COMMON_OPTS+=\" --files \\\n",
    "{}/scripts/properties/red_agent/nodes.properties,\\\n",
    "{}/scripts/properties/red_agent/nodes-de.properties,\\\n",
    "{}/scripts/properties/red_agent/nodes-es.properties,\\\n",
    "{}/scripts/properties/red_agent/nodes-ie.properties,\\\n",
    "{}/scripts/properties/red_agent/nodes-it.properties,\\\n",
    "{}/scripts/properties/red_agent/nodes-pt.properties,\\\n",
    "{}/scripts/properties/red_agent/nodes-uk.properties\".format(*[BDA_ENV]*7)\n",
    "\n",
    "os.environ[\"SPARK_COMMON_OPTS\"] = SPARK_COMMON_OPTS\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"%s pyspark-shell \" % SPARK_COMMON_OPTS\n",
    "\n",
    "#print os.environ.get('SPARK_COMMON_OPTS', '')\n",
    "#print os.environ.get('PYSPARK_SUBMIT_ARGS', '')\n",
    "\n",
    "sc, sparkSession, sqlContext = run_sc()\n",
    "print sc.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This literal_eval is needed since \n",
    "# we have to read from a textfile\n",
    "# which is formatted as python objects.\n",
    "# It is totally safe.\n",
    "from ast import literal_eval\n",
    "\n",
    "# Standard Library stuff:\n",
    "from functools import partial\n",
    "from datetime import date, timedelta, datetime\n",
    "\n",
    "# Numpy stuff\n",
    "from numpy import (nan as np_nan, round as np_round, int64 as np_int64)\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Spark stuff\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import StorageLevel\n",
    "from pyspark.sql.functions import (udf, col, decode, when, lit, lower, upper, concat,\n",
    "                                   translate, count, sum as sql_sum, max as sql_max, min as sql_min,\n",
    "                                   round, \n",
    "                                   mean, stddev, datediff,\n",
    "                                   length,\n",
    "                                   countDistinct,\n",
    "                                   hour, date_format, collect_set, collect_list,\n",
    "                                   year, month, dayofmonth,\n",
    "                                   rank, expr, lag, coalesce, row_number,\n",
    "                                   isnull, isnan,\n",
    "                                   unix_timestamp,\n",
    "                                   regexp_replace\n",
    "                                  )\n",
    "from pyspark.sql.types import DoubleType, StringType, IntegerType, ArrayType, FloatType\n",
    "\n",
    "from pyspark.sql import DataFrameStatFunctions as statFunc\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "from subprocess import Popen, PIPE\n",
    "import datetime, calendar\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder\n",
    "         .appName(\"Prepaid Churn Model - Data Preparation\")\n",
    "         .master(\"yarn\")\n",
    "         .config(\"spark.submit.deployMode\", \"client\")\n",
    "         .config(\"spark.ui.showConsoleProgress\", \"true\")\n",
    "         .enableHiveSupport()\n",
    "         .getOrCreate()\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "start_time = dt.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de fechas para la preparación de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "from pyspark.sql.functions import substring\n",
    "from pyspark.sql.functions import (unix_timestamp, udf,col,max as sql_max, avg, stddev as sql_stddev, when, count, isnull, concat, lpad, trim, lit, sum as sql_sum, length, upper)\n",
    "\n",
    "right_now = dt.datetime.now()\n",
    "today = right_now.day\n",
    "\n",
    "#Mirar en hue para ver de qué meses tenemos datos\n",
    "\n",
    "MONTH_ANALYSIS = \"20191130\"\n",
    "\n",
    "MONTH_BEFORE_M_1 = \"20190930\"\n",
    "MONTH_BEFORE_M_2 = \"20190831\"\n",
    "MONTH_BEFORE_M_3 = \"20190731\" \n",
    "MONTH_BEFORE_M_4 = \"20190630\"\n",
    "MONTH_BEFORE_M_5 = \"20190531\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comenzamos obteniendo aquellos clientes cuyas líneas llevan al menos 4 meses activas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Month M-1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs_partition_path = 'year=' + str(int(MONTH_BEFORE_M_1[:4])) + '/month=' + str(int(MONTH_BEFORE_M_1[4:6])) + '/day=14' # Cogemos la 'foto' de mitad de mes\n",
    "\n",
    "hdfs_write_path_common='/data/udf/vf_es/amdocs_ids/'\n",
    "\n",
    "path_customer = hdfs_write_path_common +'customer/'+hdfs_partition_path\n",
    "path_service = hdfs_write_path_common +'service/'+hdfs_partition_path\n",
    "\n",
    "customerDF_load = (spark.read.load(path_customer))\n",
    "serviceDF_load = (spark.read.load(path_service))\n",
    "\n",
    "month_M_1 = (customerDF_load\n",
    "              .join(serviceDF_load, 'NUM_CLIENTE', 'inner')\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_M_1 = month_M_1.filter(col('RGU') == 'prepaid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Month M-2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_to_predict_M_2 = (sqlContext.read.format('csv')\n",
    "                    .options(header='false', inferSchema='true', delimiter = '\\t')\n",
    "                    .load('/data/raw/vf_es/cvm/ES_CVM_PREPFINAL_DATALAB_M/1.1/csv/partitioned_month='+MONTH_BEFORE_M_2[0:6]+'/year='+MONTH_BEFORE_M_2[0:4]+'/month='+str(int(MONTH_BEFORE_M_2[4:6])))\n",
    "                   ) #buscar en hue para ver de qué meses tenemos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_to_predict_clean_M_2= month_to_predict_M_2.drop(*[ '_c37','_c38','_c39','_c40','_c41','_c42', '_c43', '_c44', '_c45', '_c46', '_c47', '_c48', '_c49', '_c50',\n",
    "                                                '_c51', '_c52', '_c53', '_c54', '_c55', '_c56', '_c57', '_c58', 'day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_previo = spark.read.table('raw_es.vf_pre_ac_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_previo_clean = month_previo.drop(*['sfid_canje',\n",
    " 'partitioned_month',\n",
    " 'year',\n",
    " 'month',\n",
    " 'day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < len(month_to_predict_clean_M_2.columns):\n",
    "    month_to_predict_clean_M_2 = month_to_predict_clean_M_2.withColumnRenamed(month_to_predict_clean_M_2.columns[i], month_previo_clean.columns[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_M_2 = (month_to_predict_clean_M_2\n",
    "           .where(col(\"estado_servicio\") == 'AC')\n",
    "           .select([\"Fecha_ejecucion\", 'num_documento_cliente', \"msisdn\", \"num_prepago\", \"estado_servicio\",\n",
    "                      \"num_pospago\",\"tipo_documento_comprador\", \"codigo_plan_precios\",\n",
    "                      \"x_fecha_nacimiento\", \"fx_1llamada\", 'min_llam_ultmes', 'num_sms_ultmes', 'ult3meses_total', 'media_ult3meses', 'diasdesdeultrecarga',\n",
    "                      'numrecargasult3meses_total', 'cobertura_4g', 'lortad', 'deuda', 'flag_huella_ono',\n",
    "                      'flag_4g_aperturas', 'flag_4g_nodos', 'flag_huella_vf', 'flag_huella_neba', 'flag_huella_euskaltel',\n",
    "                      'flag_beneficio_activo'])\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Month M-3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_to_predict_M_3 = (sqlContext.read.format('csv')\n",
    "                    .options(header='false', inferSchema='true', delimiter = '\\t')\n",
    "                    .load('/data/raw/vf_es/cvm/ES_CVM_PREPFINAL_DATALAB_M/1.1/csv/partitioned_month='+MONTH_BEFORE_M_3[0:6]+'/year='+MONTH_BEFORE_M_3[0:4]+'/month='+str(int(MONTH_BEFORE_M_3[4:6])))\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_to_predict_clean_M_3 = month_to_predict_M_3.drop(*[ '_c37','_c38','_c39','_c40','_c41','_c42', '_c43', '_c44', '_c45', '_c46', '_c47', '_c48', '_c49', '_c50',\n",
    "                                                '_c51', '_c52', '_c53', '_c54', '_c55', '_c56', '_c57', '_c58', 'day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < len(month_to_predict_clean_M_3.columns):\n",
    "    month_to_predict_clean_M_3 = month_to_predict_clean_M_3.withColumnRenamed(month_to_predict_clean_M_3.columns[i], month_previo_clean.columns[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_M_3 = (month_to_predict_clean_M_3\n",
    "           .where(col(\"estado_servicio\") == 'AC')\n",
    "           .select([\"msisdn\"])\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Month M-4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_to_predict_M_4 = (sqlContext.read.format('csv')\n",
    "                    .options(header='false', inferSchema='true', delimiter = '\\t')\n",
    "                    .load('/data/raw/vf_es/cvm/ES_CVM_PREPFINAL_DATALAB_M/1.1/csv/partitioned_month='+MONTH_BEFORE_M_4[0:6]+'/year='+MONTH_BEFORE_M_4[0:4]+'/month='+str(int(MONTH_BEFORE_M_4[4:6])))\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_to_predict_clean_M_4 = month_to_predict_M_4.drop(*[ '_c37','_c38','_c39','_c40','_c41','_c42', '_c43', '_c44', '_c45', '_c46', '_c47', '_c48', '_c49', '_c50',\n",
    "                                                '_c51', '_c52', '_c53', '_c54', '_c55', '_c56', '_c57', '_c58', 'day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < len(month_to_predict_clean_M_4.columns):\n",
    "    month_to_predict_clean_M_4 = month_to_predict_clean_M_4.withColumnRenamed(month_to_predict_clean_M_4.columns[i], month_previo_clean.columns[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_M_4 = (month_to_predict_clean_M_4\n",
    "           .where(col(\"estado_servicio\") == 'AC')\n",
    "           .select([\"msisdn\"])\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Month M-5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_to_predict_M_5 = (sqlContext.read.format('csv')\n",
    "                    .options(header='false', inferSchema='true', delimiter = '\\t')\n",
    "                    .load('/data/raw/vf_es/cvm/ES_CVM_PREPFINAL_DATALAB_M/1.1/csv/partitioned_month='+MONTH_BEFORE_M_5[0:6]+'/year='+MONTH_BEFORE_M_5[0:4]+'/month='+str(int(MONTH_BEFORE_M_5[4:6])))\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_to_predict_clean_M_5 = month_to_predict_M_5.drop(*[ '_c37','_c38','_c39','_c40','_c41','_c42', '_c43', '_c44', '_c45', '_c46', '_c47', '_c48', '_c49', '_c50',\n",
    "                                                '_c51', '_c52', '_c53', '_c54', '_c55', '_c56', '_c57', '_c58', 'day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < len(month_to_predict_clean_M_5.columns):\n",
    "    month_to_predict_clean_M_5 = month_to_predict_clean_M_5.withColumnRenamed(month_to_predict_clean_M_5.columns[i], month_previo_clean.columns[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_M_5 = (month_to_predict_clean_M_5\n",
    "           .where(col(\"estado_servicio\") == 'AC')\n",
    "           .select([\"msisdn\"])\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join de tablas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined_pre1 = month_M_1.join(month_M_2, on = 'msisdn', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined_pre2 = df_joined_pre1.join(month_M_3, on = 'msisdn', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepago_pre3 = df_joined_pre2.join(month_M_4, on = 'msisdn', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepago_PREVIOS = df_prepago_pre3.join(month_M_5, on = 'msisdn', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1521622"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prepago_PREVIOS.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de nacionalidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_countries = [\n",
    "                           u\"marruecos\",\n",
    "                           u\"argelia\",\n",
    "                           u\"rumania\",\n",
    "                           u\"colombia\",\n",
    "                           u\"italia\",\n",
    "                           u\"ecuador\",\n",
    "                           u\"alemania\",\n",
    "                           u\"bulgaria\",\n",
    "                           u\"francia\",\n",
    "                           u\"brasil\",\n",
    "                           u\"argentina\",\n",
    "                           u\"bolivia\",\n",
    "                           u\"portugal\",\n",
    "                           u\"paraguay\",\n",
    "                           u\"china\",\n",
    "                           u\"venezuela\",\n",
    "                           u\"honduras\",\n",
    "                           u\"india\",\n",
    "                           u\"corea del sur\"\n",
    "                          ]\n",
    "\n",
    "espana = [\"españa\", \"espana\"]\n",
    "pakistan = [\"pakistán\", \"pakistan\"]\n",
    "mexico = ['mejico', 'méjico', 'mexico', 'méxico']\n",
    "peru = ['peru', 'perú']\n",
    "japon = ['japón', 'japon']\n",
    "ucrania = ['ukrania', 'ucrania']\n",
    "dominicanos = ['república dominicana', 'rep. dominicana', 'republica dominicana', 'r. dominicana']\n",
    "afganistan = ['afganistan', 'afganistán']\n",
    "rusia = ['rusia', 'rusia blanca']\n",
    "reino_unido = ['reino unido', 'gran bretaña', 'united kingdom', 'uk', 'u.k.']\n",
    "estados_unidos = ['estados unidos', 'estados unidos de america', 'estados unidos de américa',\n",
    "                  'united states', 'united states of america', 'usa', 'u.s.a.']\n",
    "\n",
    "df_prepago_PREVIOS = df_prepago_PREVIOS.withColumn(\"nacionalidad\",\n",
    "                                       when(lower(col(\"nacionalidad\"))\n",
    "                                            .isin(most_frequent_countries+espana+reino_unido+estados_unidos+peru+pakistan+mexico+japon+ucrania+dominicanos+afganistan+rusia),\n",
    "                                            lower(col(\"nacionalidad\")))\n",
    "                                       .otherwise(lit(\"Other\")))\n",
    "\n",
    "df_prepago_PREVIOS = df_prepago_PREVIOS.withColumn('nacionalidad_final', \n",
    "                                                           when(lower(col('nacionalidad')).isin(reino_unido), 'REINO UNIDO')\n",
    "                                               .when(lower(col('nacionalidad')).isin(espana), 'ESPAÑA')\n",
    "                                               .when(lower(col('nacionalidad')).isin(estados_unidos), 'ESTADOS UNIDOS')\n",
    "                                               .when(lower(col('nacionalidad')).isin(mexico), 'MEXICO')\n",
    "                                               .when(lower(col('nacionalidad')).isin(rusia), 'RUSIA')\n",
    "                                               .when(lower(col('nacionalidad')).isin(japon), 'JAPON')\n",
    "                                               .when(lower(col('nacionalidad')).isin(ucrania), 'UCRANIA')\n",
    "                                               .when(lower(col('nacionalidad')).isin(dominicanos), 'R. DOMINICANA')\n",
    "                                               .when(lower(col('nacionalidad')).isin(afganistan), 'AFGANISTAN')\n",
    "                                               .when(lower(col('nacionalidad')).isin(pakistan), 'PAKISTAN')\n",
    "                                               .when(lower(col('nacionalidad')).isin(peru), 'PERU').otherwise(\"OTHER\")\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepago_PREVIOS = df_prepago_PREVIOS.withColumn('tipo_documento_comprador',\n",
    "                                       when(upper(df_prepago_PREVIOS['tipo_documento_comprador']).like('N%I%F%'), 'N.I.F.')\n",
    "                                       .when(upper(df_prepago_PREVIOS['tipo_documento_comprador']).like('D%N%I%'), 'N.I.F.')\n",
    "                                       .when(upper(df_prepago_PREVIOS['tipo_documento_comprador']).like('C%I%F%'), 'C.I.F.')\n",
    "                                       .when(upper(df_prepago_PREVIOS['tipo_documento_comprador']).like('N%I%E%'), 'N.I.E.')\n",
    "                                       .when(upper(df_prepago_PREVIOS['tipo_documento_comprador']).like('TARJ%RESI%'), 'N.I.E.')\n",
    "                                       .when(upper(df_prepago_PREVIOS['tipo_documento_comprador']).like('PAS%'), 'Pasaporte')\n",
    "                                       .otherwise(''))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de target con tabla de portabilidades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ejecutar sólo cuando preparemos el IDS de predicción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepago_labeled = df_prepago_PREVIOS.withColumn('Churned', lit(None).cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ejecutar sólo cuando preparemos el IDS de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "portados = (sqlContext.read.format('csv')\n",
    "                    .options(header='false', inferSchema='true', delimiter = '\\t')\n",
    "                    .load('/data/raw/vf_es/cvm/ES_CVM_PREDNOACTIV_DATALAB_M/1.1/csv/partitioned_month='+ \n",
    "                          str(MONTH_ANALYSIS[0:6])+'/year='+MONTH_ANALYSIS[0:4]+'/month='+str(int(MONTH_ANALYSIS[4:6]))\n",
    "                         )\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "portados = (portados\n",
    "            .withColumnRenamed('_c0', 'msisdn')\n",
    "            .withColumnRenamed('_c1', 'motivo_desactivacion')\n",
    "            .withColumnRenamed('_c2', 'extractdate')\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_definitivo = df_prepago_PREVIOS.join(portados.select('msisdn', 'motivo_desactivacion'), how = 'leftouter', on = 'msisdn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepago_labeled = df_definitivo.withColumn('Churned', when(col('motivo_desactivacion') == 'PORTADO', 1).otherwise(0)).drop(*['motivo_desactivacion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|Churned|  count|\n",
      "+-------+-------+\n",
      "|      1|  10766|\n",
      "|      0|1629660|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_prepago_labeled.groupBy('Churned').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Añadimos información de diferentes fuentes para ir construyendo nuestro IDS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Cálculos agregados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura de tabla de transferencias de saldo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import unix_timestamp, from_unixtime, struct, concat_ws\n",
    "from pyspark.sql.types import TimestampType\n",
    "\n",
    "conv_to_timestamp_udf = udf(lambda x: from_unixtime(unix_timestamp(str(x[0])+\"/\"+str(x[1])+\"/\"+str(x[2]), 'dd/MM/yyy')), TimestampType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balance_receptor_M_1 = (spark.read.table(\"raw_es.prepaid_transfbalance\")\n",
    "                        .withColumn('entry_ts', from_unixtime(unix_timestamp(concat_ws('/',\"day\", \"month\", \"year\"), 'dd/MM/yyy')))\n",
    "                        .filter(col(\"year\") == (int(MONTH_BEFORE_M_1[:4])))\n",
    "                        .filter(col(\"month\") == (int(MONTH_BEFORE_M_1[4:6])))\n",
    "                        .filter(col(\"day\") <= 15)\n",
    "                        .groupBy([\"msisdn_receptor\", \"month\", \"year\"])\n",
    "                        .agg(sql_sum(\"importe_traspasado\").alias(\"importe_traspasado_receptor_M-1\"),\n",
    "                                count(\"importe_traspasado\").alias(\"num_rec_M-1\"))\n",
    "                        .withColumnRenamed('msisdn_receptor', 'msisdn')\n",
    "                        .select(col(\"msisdn\"),\n",
    "                                col(\"importe_traspasado_receptor_M-1\"),\n",
    "                               col(\"num_rec_M-1\")))\n",
    "    \n",
    "df_balance_receptor_M_2 = (spark.read.table(\"raw_es.prepaid_transfbalance\")\n",
    "              .withColumn('entry_ts', from_unixtime(unix_timestamp(concat_ws('/',\"day\", \"month\", \"year\"), 'dd/MM/yyy')))\n",
    "                        .filter(col(\"year\") == (int(MONTH_BEFORE_M_2[:4])))\n",
    "                        .filter(col(\"month\") == (int(MONTH_BEFORE_M_2[4:6])))\n",
    "                                      .groupBy([\"msisdn_receptor\", \"month\", \"year\"])\n",
    "                                      .agg(sql_sum(\"importe_traspasado\").alias(\"importe_traspasado_receptor_M-2\"),\n",
    "                                           count(\"importe_traspasado\").alias(\"num_rec_M-2\"))\n",
    "                                      .withColumnRenamed('msisdn_receptor', 'msisdn')\n",
    "                                      .select(col(\"msisdn\"),\n",
    "                                              col(\"importe_traspasado_receptor_M-2\"),\n",
    "                                             col(\"num_rec_M-2\")))\n",
    "    \n",
    "df_balance_receptor_M_3 = (spark.read.table(\"raw_es.prepaid_transfbalance\")\n",
    "              .withColumn('entry_ts', from_unixtime(unix_timestamp(concat_ws('/',\"day\", \"month\", \"year\"), 'dd/MM/yyy')))\n",
    "                        .filter(col(\"year\") == (int(MONTH_BEFORE_M_3[:4])))\n",
    "                        .filter(col(\"month\") == (int(MONTH_BEFORE_M_3[4:6])))\n",
    "                                      .groupBy([\"msisdn_receptor\", \"month\", \"year\"])\n",
    "                                      .agg(sql_sum(\"importe_traspasado\").alias(\"importe_traspasado_receptor_M-3\"),\n",
    "                                           count(\"importe_traspasado\").alias(\"num_rec_M-3\"))\n",
    "                                      .withColumnRenamed('msisdn_receptor', 'msisdn')\n",
    "                                      .select(col(\"msisdn\"),\n",
    "                                              col(\"importe_traspasado_receptor_M-3\"),\n",
    "                                             col(\"num_rec_M-3\")))\n",
    "    \n",
    "df_balance_receptor_M_4 = (spark.read.table(\"raw_es.prepaid_transfbalance\")\n",
    "              .withColumn('entry_ts', from_unixtime(unix_timestamp(concat_ws('/',\"day\", \"month\", \"year\"), 'dd/MM/yyy')))\n",
    "                        .filter(col(\"year\") == (int(MONTH_BEFORE_M_4[:4])))\n",
    "                        .filter(col(\"month\") == (int(MONTH_BEFORE_M_4[4:6])))\n",
    "                                      .groupBy([\"msisdn_receptor\", \"month\", \"year\"])\n",
    "                                      .agg(sql_sum(\"importe_traspasado\").alias(\"importe_traspasado_receptor_M-4\"),\n",
    "                                           count(\"importe_traspasado\").alias(\"num_rec_M-4\"))\n",
    "                                      .withColumnRenamed('msisdn_receptor', 'msisdn')\n",
    "                                      .select(col(\"msisdn\"),\n",
    "                                              col(\"importe_traspasado_receptor_M-4\"),\n",
    "                                             col(\"num_rec_M-4\")))\n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balance_receptor_pre1 = (df_balance_receptor_M_1\n",
    "                       .join(df_balance_receptor_M_2, on = 'msisdn' ,how = 'left'))\n",
    "\n",
    "df_balance_receptor_pre2 = (df_balance_receptor_pre1\n",
    "                            .join(df_balance_receptor_M_3, on = 'msisdn' ,how = 'left'))\n",
    "\n",
    "df_balance_receptor = (df_balance_receptor_pre2\n",
    "                       .join(df_balance_receptor_M_4, on = 'msisdn' ,how = 'left'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balance_emisor_M_1 = (spark.read.table(\"raw_es.prepaid_transfbalance\")\n",
    "                        .withColumn('entry_ts', from_unixtime(unix_timestamp(concat_ws('/',\"day\", \"month\", \"year\"), 'dd/MM/yyy')))\n",
    "                        .filter(col(\"year\") == (int(MONTH_BEFORE_M_1[:4])))\n",
    "                        .filter(col(\"month\") == (int(MONTH_BEFORE_M_1[4:6])))\n",
    "                        .filter(col(\"day\") < 15)\n",
    "                        .withColumnRenamed('msisdn_emisor', 'msisdn')\n",
    "                                      .groupBy(\"msisdn\")\n",
    "                                      .agg(sql_sum(\"importe_traspasado\").alias(\"importe_traspasado_emisor_M-1\"),\n",
    "                                           sql_sum(\"importe_cargo\").alias(\"importe_cargo_emisor_M-1\"),\n",
    "                                           count(\"importe_traspasado\").alias(\"num_em_M-1\"))\n",
    "                                      .select(col(\"msisdn\"), \n",
    "                                              col(\"importe_traspasado_emisor_M-1\"),\n",
    "                                              col(\"importe_cargo_emisor_M-1\"),\n",
    "                                             col(\"num_em_M-1\")))\n",
    "\n",
    "df_balance_emisor_M_2 = (spark.read.table(\"raw_es.prepaid_transfbalance\")\n",
    "              .withColumn('entry_ts', from_unixtime(unix_timestamp(concat_ws('/',\"day\", \"month\", \"year\"), 'dd/MM/yyy')))\n",
    "                        .filter(col(\"year\") == (int(MONTH_BEFORE_M_2[:4])))\n",
    "                        .filter(col(\"month\") == (int(MONTH_BEFORE_M_2[4:6])))\n",
    "                         .withColumnRenamed('msisdn_emisor', 'msisdn')\n",
    "                                      .groupBy(\"msisdn\")\n",
    "                                      .agg(sql_sum(\"importe_traspasado\").alias(\"importe_traspasado_emisor_M-2\"),\n",
    "                                           sql_sum(\"importe_cargo\").alias(\"importe_cargo_emisor_M-2\"),\n",
    "                                           count(\"importe_traspasado\").alias(\"num_em_M-2\"))\n",
    "                                      .select(col(\"msisdn\"), \n",
    "                                              col(\"importe_traspasado_emisor_M-2\"),\n",
    "                                              col(\"importe_cargo_emisor_M-2\"),\n",
    "                                             col(\"num_em_M-2\")))\n",
    "\n",
    "df_balance_emisor_M_3 = (spark.read.table(\"raw_es.prepaid_transfbalance\")\n",
    "              .withColumn('entry_ts', from_unixtime(unix_timestamp(concat_ws('/',\"day\", \"month\", \"year\"), 'dd/MM/yyy')))\n",
    "                        .filter(col(\"year\") == (int(MONTH_BEFORE_M_3[:4])))\n",
    "                        .filter(col(\"month\") == (int(MONTH_BEFORE_M_3[4:6])))\n",
    "                         .withColumnRenamed('msisdn_emisor', 'msisdn')\n",
    "                                      .groupBy(\"msisdn\")\n",
    "                                      .agg(sql_sum(\"importe_traspasado\").alias(\"importe_traspasado_emisor_M-3\"),\n",
    "                                           sql_sum(\"importe_cargo\").alias(\"importe_cargo_emisor_M-3\"),\n",
    "                                           count(\"importe_traspasado\").alias(\"num_em_M-3\"))\n",
    "                                      .select(col(\"msisdn\"), \n",
    "                                              col(\"importe_traspasado_emisor_M-3\"),\n",
    "                                              col(\"importe_cargo_emisor_M-3\"),\n",
    "                                             col(\"num_em_M-3\")))\n",
    "\n",
    "df_balance_emisor_M_4 = (spark.read.table(\"raw_es.prepaid_transfbalance\")\n",
    "              .withColumn('entry_ts', from_unixtime(unix_timestamp(concat_ws('/',\"day\", \"month\", \"year\"), 'dd/MM/yyy')))\n",
    "                        .filter(col(\"year\") == (int(MONTH_BEFORE_M_4[:4])))\n",
    "                        .filter(col(\"month\") == (int(MONTH_BEFORE_M_4[4:6])))\n",
    "                         .withColumnRenamed('msisdn_emisor', 'msisdn')\n",
    "                                      .groupBy(\"msisdn\")\n",
    "                                      .agg(sql_sum(\"importe_traspasado\").alias(\"importe_traspasado_emisor_M-4\"),\n",
    "                                           sql_sum(\"importe_cargo\").alias(\"importe_cargo_emisor_M-4\"),\n",
    "                                           count(\"importe_traspasado\").alias(\"num_em_M-4\"))\n",
    "                                      .select(col(\"msisdn\"), \n",
    "                                              col(\"importe_traspasado_emisor_M-4\"),\n",
    "                                              col(\"importe_cargo_emisor_M-4\"),\n",
    "                                             col(\"num_em_M-4\")))\n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balance_emisor_pre1 = (df_balance_emisor_M_1\n",
    "                       .join(df_balance_emisor_M_2, on = 'msisdn' ,how = 'left'))\n",
    "\n",
    "df_balance_emisor_pre2 = (df_balance_emisor_pre1\n",
    "                            .join(df_balance_emisor_M_3, on = 'msisdn' ,how = 'left'))\n",
    "\n",
    "df_balance_emisor = (df_balance_emisor_pre2\n",
    "                       .join(df_balance_emisor_M_4, on = 'msisdn' ,how = 'left'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Información de Topups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "udf_parse_importe = udf(lambda x:int(x.replace(\"\\+\",\"\"))/10000,IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topups_M_1 = (spark.read.table(\"raw_es.billingtopsups_rechargescash\")\n",
    "                        .filter(col(\"year\") == (int(MONTH_BEFORE_M_1[:4])))\n",
    "                        .filter(col(\"month\") == (int(MONTH_BEFORE_M_1[4:6])))\n",
    "                        .filter(col(\"day\") <= 15) # El modelo se suele ejecutar el día 20/21 de cada mes, y el retraso con el que llega la información suele ser de 2 o 3 días.\n",
    "                        .withColumnRenamed('ndc_msisdn', 'msisdn')\n",
    "                       .withColumn('importe_int_M-1', regexp_replace('importe', \"\\\\+\", ''))\n",
    "                       .withColumn('importe_int_corrected_M-1', col('importe_int_M-1')/10000)\n",
    "                       .groupBy(\"msisdn\")\n",
    "                        .agg(sql_sum(\"importe_int_corrected_M-1\").alias(\"tu_amount_M-1\"),\n",
    "                               count(\"importe\").alias(\"tu_num_M-1\"))\n",
    "                        .select(col(\"msisdn\"),\n",
    "                                col(\"tu_amount_M-1\"),\n",
    "                                col(\"tu_num_M-1\"))\n",
    "                       .withColumn(\"tu_bin_M-1\", when(col(\"tu_num_M-1\")>0, 1).otherwise(0))\n",
    "                      )\n",
    "\n",
    "df_topups_M_2 = (spark.read.table(\"raw_es.billingtopsups_rechargescash\")\n",
    "                            .filter(col(\"year\") == (int(MONTH_BEFORE_M_2[:4])))\n",
    "                        .filter(col(\"month\") == (int(MONTH_BEFORE_M_2[4:6])))\n",
    "                       .withColumn('importe_int_M-2', regexp_replace('importe', \"\\\\+\", ''))\n",
    "                       .withColumn('importe_int_corrected_M-2', col('importe_int_M-2')/10000)\n",
    "                       .withColumnRenamed('ndc_msisdn', 'msisdn')\n",
    "                       .groupBy(\"msisdn\")\n",
    "                        .agg(sql_sum(\"importe_int_corrected_M-2\").alias(\"tu_amount_M-2\"),\n",
    "                               count(\"importe\").alias(\"tu_num_M-2\"))\n",
    "                        .select(col(\"msisdn\"),\n",
    "                                col(\"tu_amount_M-2\"),\n",
    "                                col(\"tu_num_M-2\"))\n",
    "                       .withColumn(\"tu_bin_M-2\", when(col(\"tu_num_M-2\")>0, 1).otherwise(0))\n",
    "                      )\n",
    "\n",
    "df_topups_M_3 = (spark.read.table(\"raw_es.billingtopsups_rechargescash\")\n",
    "                            .filter(col(\"year\") == (int(MONTH_BEFORE_M_3[:4])))\n",
    "                            .filter(col(\"month\") == (int(MONTH_BEFORE_M_3[4:6])))\n",
    "                            .withColumn('importe_int_M-3', regexp_replace('importe', \"\\\\+\", ''))\n",
    "                            .withColumn('importe_int_corrected_M-3', col('importe_int_M-3')/10000)\n",
    "                            .withColumnRenamed('ndc_msisdn', 'msisdn')\n",
    "                       .groupBy(\"msisdn\")\n",
    "                        .agg(sql_sum(\"importe_int_corrected_M-3\").alias(\"tu_amount_M-3\"),\n",
    "                               count(\"importe\").alias(\"tu_num_M-3\"))\n",
    "                        .select(col(\"msisdn\"),\n",
    "                                col(\"tu_amount_M-3\"),\n",
    "                                col(\"tu_num_M-3\"))\n",
    "                       .withColumn(\"tu_bin_M-3\", when(col(\"tu_num_M-3\")>0, 1).otherwise(0))\n",
    "                      )\n",
    "\n",
    "df_topups_M_4 = (spark.read.table(\"raw_es.billingtopsups_rechargescash\")\n",
    "                        .filter(col(\"year\") == (int(MONTH_BEFORE_M_4[:4])))\n",
    "                        .filter(col(\"month\") == (int(MONTH_BEFORE_M_4[4:6])))\n",
    "                       .withColumn('importe_int_M-4', regexp_replace('importe', \"\\\\+\", ''))\n",
    "                       .withColumn('importe_int_corrected_M-4', col('importe_int_M-4')/10000)\n",
    "                       .withColumnRenamed('ndc_msisdn', 'msisdn')\n",
    "                       .groupBy(\"msisdn\")\n",
    "                        .agg(sql_sum(\"importe_int_corrected_M-4\").alias(\"tu_amount_M-4\"),\n",
    "                               count(\"importe\").alias(\"tu_num_M-4\"))\n",
    "                        .select(col(\"msisdn\"),\n",
    "                                col(\"tu_amount_M-4\"),\n",
    "                                col(\"tu_num_M-4\"))\n",
    "                       .withColumn(\"tu_bin_M-4\", when(col(\"tu_num_M-4\")>0, 1).otherwise(0))\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topups_pre1 = (df_topups_M_1\n",
    "                       .join(df_topups_M_2, on = 'msisdn' ,how = 'left'))\n",
    "\n",
    "df_topups_pre2 = (df_topups_pre1\n",
    "                            .join(df_topups_M_3, on = 'msisdn' ,how = 'left'))\n",
    "\n",
    "df_topups = (df_topups_pre2\n",
    "                       .join(df_topups_M_4, on = 'msisdn' ,how = 'left'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adelantos de saldo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_advance_solicitado_M_1 = (spark.read.table(\"raw_es.prepaid_advancebalance\")\n",
    "                        .filter(col(\"year\") == (int(MONTH_BEFORE_M_1[:4])))\n",
    "                        .filter(col(\"month\") == (int(MONTH_BEFORE_M_1[4:6])))\n",
    "                        .filter(col('day') < 15) # El modelo se suele ejecutar el día 20/21 de cada mes, y el retraso con el que llega la información suele ser de 2 o 3 días.\n",
    "                        .groupBy(\"msisdn\")\n",
    "                        .agg(sql_sum(\"importe_anticipo\").alias(\"abal_amount_M-1\"),\n",
    "                               count(\"importe_anticipo\").alias(\"abal_num_M-1\"))\n",
    "                        .select(col(\"msisdn\"), \n",
    "                                col(\"abal_amount_M-1\"),\n",
    "                                col(\"abal_num_M-1\"))\n",
    "                        )\n",
    "\n",
    "df_advance_solicitado_M_2 = (spark.read.table(\"raw_es.prepaid_advancebalance\")\n",
    "                        .filter(col(\"year\") == (int(MONTH_BEFORE_M_2[:4])))\n",
    "                        .filter(col(\"month\") == (int(MONTH_BEFORE_M_2[4:6])))\n",
    "                       .groupBy(\"msisdn\")\n",
    "                        .agg(sql_sum(\"importe_anticipo\").alias(\"abal_amount_M-2\"),\n",
    "                               count(\"importe_anticipo\").alias(\"abal_num_M-2\"))\n",
    "                        .select(col(\"msisdn\"), \n",
    "                                col(\"abal_amount_M-2\"),\n",
    "                                col(\"abal_num_M-2\"))\n",
    "                        )\n",
    "\n",
    "df_advance_solicitado_M_3 = (spark.read.table(\"raw_es.prepaid_advancebalance\")\n",
    "                        .filter(col(\"year\") == (int(MONTH_BEFORE_M_3[:4])))\n",
    "                        .filter(col(\"month\") == (int(MONTH_BEFORE_M_3[4:6])))\n",
    "                        .groupBy(\"msisdn\")\n",
    "                        .agg(sql_sum(\"importe_anticipo\").alias(\"abal_amount_M-3\"),\n",
    "                               count(\"importe_anticipo\").alias(\"abal_num_M-3\"))\n",
    "                        .select(col(\"msisdn\"), \n",
    "                                col(\"abal_amount_M-3\"),\n",
    "                                col(\"abal_num_M-3\"))\n",
    "                        )\n",
    "\n",
    "df_advance_solicitado_M_4 = (spark.read.table(\"raw_es.prepaid_advancebalance\")\n",
    "                        .filter(col(\"year\") == (int(MONTH_BEFORE_M_4[:4])))\n",
    "                        .filter(col(\"month\") == (int(MONTH_BEFORE_M_4[4:6])))\n",
    "                       .groupBy(\"msisdn\")\n",
    "                        .agg(sql_sum(\"importe_anticipo\").alias(\"abal_amount_M-4\"),\n",
    "                               count(\"importe_anticipo\").alias(\"abal_num_M-4\"))\n",
    "                        .select(col(\"msisdn\"), \n",
    "                                col(\"abal_amount_M-4\"),\n",
    "                                col(\"abal_num_M-4\"))\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_advance_solicitado_pre1 = (df_advance_solicitado_M_1\n",
    "                       .join(df_advance_solicitado_M_2, on = 'msisdn' ,how = 'left'))\n",
    "\n",
    "df_advance_solicitado_pre2 = (df_advance_solicitado_pre1\n",
    "                            .join(df_advance_solicitado_M_3, on = 'msisdn' ,how = 'left'))\n",
    "\n",
    "df_advance_solicitado = (df_advance_solicitado_pre2\n",
    "                       .join(df_advance_solicitado_M_4, on = 'msisdn' ,how = 'left'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_advance_recuperado_M_1 = (spark.read.table(\"raw_es.prepaid_advancebalance\")\n",
    "                       .filter(col(\"year\") == (int(MONTH_BEFORE_M_1[:4])))\n",
    "                       .filter(col(\"month\") == (int(MONTH_BEFORE_M_1[4:6])))\n",
    "                       .filter(col('day') < 15) # El modelo se suele ejecutar el día 20/21 de cada mes, y el retraso con el que llega la información suele ser de 2 o 3 días.\n",
    "                       .groupBy(\"msisdn\")\n",
    "                       .agg(sql_sum(\"imp_recuperado\").alias(\"abal_payment_M-1\"),\n",
    "                            count(\"imp_recuperado\").alias(\"abal_payment_num_M-1\"))\n",
    "                       .select(col(\"msisdn\"), \n",
    "                               col(\"abal_payment_M-1\"),\n",
    "                               col(\"abal_payment_num_M-1\")))\n",
    "\n",
    "df_advance_recuperado_M_2 = (spark.read.table(\"raw_es.prepaid_advancebalance\")\n",
    "                       .filter(col(\"year\") == (int(MONTH_BEFORE_M_2[:4])))\n",
    "                        .filter(col(\"month\") == (int(MONTH_BEFORE_M_2[4:6])))\n",
    "                       .groupBy(\"msisdn\")\n",
    "                       .agg(sql_sum(\"imp_recuperado\").alias(\"abal_payment_M-2\"),\n",
    "                            count(\"imp_recuperado\").alias(\"abal_payment_num_M-2\"))\n",
    "                       .select(col(\"msisdn\"), \n",
    "                               col(\"abal_payment_M-2\"),\n",
    "                               col(\"abal_payment_num_M-2\")))\n",
    "\n",
    "\n",
    "df_advance_recuperado_M_3 = (spark.read.table(\"raw_es.prepaid_advancebalance\")\n",
    "                       .filter(col(\"year\") == (int(MONTH_BEFORE_M_3[:4])))\n",
    "                       .filter(col(\"month\") == (int(MONTH_BEFORE_M_3[4:6])))\n",
    "                       .groupBy(\"msisdn\")\n",
    "                       .agg(sql_sum(\"imp_recuperado\").alias(\"abal_payment_M-3\"),\n",
    "                            count(\"imp_recuperado\").alias(\"abal_payment_num_M-3\"))\n",
    "                       .select(col(\"msisdn\"), \n",
    "                               col(\"abal_payment_M-3\"),\n",
    "                               col(\"abal_payment_num_M-3\")))\n",
    "\n",
    "df_advance_recuperado_M_4 = (spark.read.table(\"raw_es.prepaid_advancebalance\")\n",
    "                       .filter(col(\"year\") == (int(MONTH_BEFORE_M_4[:4])))\n",
    "                        .filter(col(\"month\") == (int(MONTH_BEFORE_M_4[4:6])))\n",
    "                       .groupBy(\"msisdn\")\n",
    "                       .agg(sql_sum(\"imp_recuperado\").alias(\"abal_payment_M-4\"),\n",
    "                            count(\"imp_recuperado\").alias(\"abal_payment_num_M-4\"))\n",
    "                       .select(col(\"msisdn\"), \n",
    "                               col(\"abal_payment_M-4\"),\n",
    "                               col(\"abal_payment_num_M-4\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_advance_recuperado_pre1 = (df_advance_recuperado_M_1\n",
    "                       .join(df_advance_recuperado_M_2, on = 'msisdn',how = 'left'))\n",
    "\n",
    "df_advance_recuperado_pre2 = (df_advance_recuperado_pre1\n",
    "                            .join(df_advance_recuperado_M_3, on = 'msisdn',how = 'left'))\n",
    "\n",
    "df_advance_recuperado = (df_advance_recuperado_pre2\n",
    "                       .join(df_advance_recuperado_M_4, on = 'msisdn',how = 'left'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balances de saldo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balance_M_1 = (spark.read.table(\"raw_es.prepaid_clientbalance\")\n",
    "                    .filter(col(\"year\") == (int(MONTH_BEFORE_M_1[:4])))\n",
    "                    .filter(col(\"month\") == (int(MONTH_BEFORE_M_1[4:6])))\n",
    "                    .filter(col('day') < 15) # El modelo se suele ejecutar el día 20/21 de cada mes, y el retraso con el que llega la información suele ser de 2 o 3 días.\n",
    "                    .groupBy('msisdn')\n",
    "                    .agg(F.max('saldo').alias('max_saldo_M-1'),\n",
    "                        F.min('saldo').alias('min_saldo_M-1'))\n",
    "                    .withColumn('diff_saldo_M-1', col('max_saldo_M-1') - col ('min_saldo_M-1'))\n",
    "                 )\n",
    "\n",
    "df_balance_M_2 = (spark.read.table(\"raw_es.prepaid_clientbalance\")\n",
    "                    .filter(col(\"year\") == (int(MONTH_BEFORE_M_2[:4])))\n",
    "                    .filter(col(\"month\") == (int(MONTH_BEFORE_M_2[4:6])))\n",
    "                    .groupBy('msisdn')\n",
    "                    .agg(F.max('saldo').alias('max_saldo_M-2'),\n",
    "                        F.min('saldo').alias('min_saldo_M-2'))\n",
    "                    .withColumn('diff_saldo_M-2', col('max_saldo_M-2') - col ('min_saldo_M-2'))\n",
    "                 )\n",
    "\n",
    "df_balance_M_3 = (spark.read.table(\"raw_es.prepaid_clientbalance\")\n",
    "                    .filter(col(\"year\") == (int(MONTH_BEFORE_M_3[:4])))\n",
    "                    .filter(col(\"month\") == (int(MONTH_BEFORE_M_3[4:6])))\n",
    "                    .groupBy('msisdn')\n",
    "                    .agg(F.max('saldo').alias('max_saldo_M-3'),\n",
    "                        F.min('saldo').alias('min_saldo_M-3'))\n",
    "                    .withColumn('diff_saldo_M-3', col('max_saldo_M-3') - col ('min_saldo_M-3'))\n",
    "                 )\n",
    "                  \n",
    "df_balance_M_4 = (spark.read.table(\"raw_es.prepaid_clientbalance\")\n",
    "                    .filter(col(\"year\") == (int(MONTH_BEFORE_M_4[:4])))\n",
    "                    .filter(col(\"month\") == (int(MONTH_BEFORE_M_4[4:6])))\n",
    "                    .groupBy('msisdn')\n",
    "                    .agg(F.max('saldo').alias('max_saldo_M-4'),\n",
    "                        F.min('saldo').alias('min_saldo_M-4'))\n",
    "                    .withColumn('diff_saldo_M-4', col('max_saldo_M-4') - col ('min_saldo_M-4'))\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balance_pre1 = df_balance_M_1.join(df_balance_M_2, on = 'msisdn' , how = 'left')\n",
    "df_balance_pre2 = df_balance_pre1.join(df_balance_M_3, on = 'msisdn' , how = 'left') \n",
    "df_balance = df_balance_pre2.join(df_balance_M_4, on = 'msisdn' , how = 'left').withColumn('diff_saldo_4meses', col('max_saldo_M-4') - col('max_saldo_M-1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balance = (df_balance\n",
    " .withColumn('DIFF_SALDO_M-1', col('max_saldo_M-1') - col('min_saldo_M-1'))\n",
    " .withColumn('DIFF_SALDO_M-2', col('max_saldo_M-2') - col('min_saldo_M-2'))\n",
    " .withColumn('DIFF_SALDO_M-3', col('max_saldo_M-3') - col('min_saldo_M-3'))\n",
    " .withColumn('DELTA_DIFF_SALDO', col('DIFF_SALDO_M-3') - col('DIFF_SALDO_M-1'))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consumo de voz y SMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_voicesms_M_1 = (spark.read.table(\"raw_es.prepaid_trafficvoicesms\")\n",
    "                       .filter(col(\"year\") == (int(MONTH_BEFORE_M_1[:4])))\n",
    "                       .filter(col(\"month\") == (int(MONTH_BEFORE_M_1[4:6])))\n",
    "                       .filter(col(\"day\") <= 15)\n",
    "                 .withColumn(\"numeroorigen_M-1\", trim(col(\"numeroorigen\")))\n",
    "                 .withColumn(\"numerodestino_M-1\", trim(col(\"numerodestino\")))\n",
    "                 .withColumn(\"vozsms_M-1\", lower(trim(col(\"vozsms\"))))      \n",
    "                 .withColumn(\"voice_amount_M-1\", when(lower(col(\"vozsms\")) == 'voz', col(\"importecobrado\")).otherwise(0))\n",
    "                 .withColumn(\"sms_amount_M-1\", when(lower(col(\"vozsms\")) == 'sms', col(\"importecobrado\")).otherwise(0))\n",
    "              .groupBy(\"numeroorigen_M-1\")\n",
    "              .agg(sql_sum(\"voice_amount_M-1\").alias(\"voice_amount_M-1\"),\n",
    "                   sql_sum(\"sms_amount_M-1\").alias(\"sms_amount_M-1\"),\n",
    "                   sql_sum(\"importecobrado\").alias(\"voicesms_amount_M-1\"),\n",
    "                   count(when((lower(col(\"vozsms_M-1\")) == 'voz'), col(\"vozsms_M-1\")).otherwise(None)).alias(\"voice_num_M-1\"),\n",
    "                   count(when((lower(col(\"vozsms_M-1\")) == 'sms'), col(\"vozsms_M-1\")).otherwise(None)).alias(\"sms_num_M-1\"),\n",
    "                   sql_sum(when((lower(col(\"vozsms_M-1\")) == 'voz'), col(\"airduration\")).otherwise(None)).alias(\"voice_duration_M-1\"),\n",
    "                   avg(when((lower(col(\"vozsms\")) == 'voz'), col(\"airduration\")).otherwise(None)).alias(\"voice_avg_duration_M-1\"),\n",
    "                   countDistinct(when((lower(col(\"vozsms_M-1\")) == 'voz'), col(\"numerodestino_M-1\")).otherwise(None)).alias(\"voice_num_distinct_rec_M-1\"),\n",
    "                   countDistinct(when((lower(col(\"vozsms_M-1\")) == 'sms'), col(\"numerodestino_M-1\")).otherwise(None)).alias(\"sms_num_distinct_rec_M-1\"))\n",
    "             .withColumnRenamed(\"numeroorigen_M-1\", \"msisdn\")  \n",
    "               )\n",
    "\n",
    "df_voicesms_M_2 = (spark.read.table(\"raw_es.prepaid_trafficvoicesms\")\n",
    "                       .filter(col(\"year\") == (int(MONTH_BEFORE_M_2[:4])))\n",
    "                       .filter(col(\"month\") == (int(MONTH_BEFORE_M_2[4:6])))\n",
    "                 .withColumn(\"numeroorigen_M-2\", trim(col(\"numeroorigen\")))\n",
    "                 .withColumn(\"numerodestino_M-2\", trim(col(\"numerodestino\")))\n",
    "                 .withColumn(\"vozsms_M-2\", lower(trim(col(\"vozsms\"))))      \n",
    "                 .withColumn(\"voice_amount_M-2\", when(lower(col(\"vozsms\")) == 'voz', col(\"importecobrado\")).otherwise(0))\n",
    "                 .withColumn(\"sms_amount_M-2\", when(lower(col(\"vozsms\")) == 'sms', col(\"importecobrado\")).otherwise(0))\n",
    "              .groupBy(\"numeroorigen_M-2\")\n",
    "              .agg(sql_sum(\"voice_amount_M-2\").alias(\"voice_amount_M-2\"),\n",
    "                   sql_sum(\"sms_amount_M-2\").alias(\"sms_amount_M-2\"),\n",
    "                   sql_sum(\"importecobrado\").alias(\"voicesms_amount_M-2\"),\n",
    "                   count(when((lower(col(\"vozsms_M-2\")) == 'voz'), col(\"vozsms_M-2\")).otherwise(None)).alias(\"voice_num_M-2\"),\n",
    "                   count(when((lower(col(\"vozsms_M-2\")) == 'sms'), col(\"vozsms_M-2\")).otherwise(None)).alias(\"sms_num_M-2\"),\n",
    "                   sql_sum(when((lower(col(\"vozsms_M-2\")) == 'voz'), col(\"airduration\")).otherwise(None)).alias(\"voice_duration_M-2\"),\n",
    "                   avg(when((lower(col(\"vozsms_M-2\")) == 'voz'), col(\"airduration\")).otherwise(None)).alias(\"voice_avg_duration_M-2\"),\n",
    "                   countDistinct(when((lower(col(\"vozsms_M-2\")) == 'voz'), col(\"numerodestino_M-2\")).otherwise(None)).alias(\"voice_num_distinct_rec_M-2\"),\n",
    "                   countDistinct(when((lower(col(\"vozsms_M-2\")) == 'sms'), col(\"numerodestino_M-2\")).otherwise(None)).alias(\"sms_num_distinct_rec_M-2\"))\n",
    "             .withColumnRenamed(\"numeroorigen_M-2\", \"msisdn\")  \n",
    "               )\n",
    "\n",
    "df_voicesms_M_3 = (spark.read.table(\"raw_es.prepaid_trafficvoicesms\")\n",
    "                       .filter(col(\"year\") == (int(MONTH_BEFORE_M_3[:4])))\n",
    "                       .filter(col(\"month\") == (int(MONTH_BEFORE_M_3[4:6])))\n",
    "                 .withColumn(\"numeroorigen_M-3\", trim(col(\"numeroorigen\")))\n",
    "                 .withColumn(\"numerodestino_M-3\", trim(col(\"numerodestino\")))\n",
    "                 .withColumn(\"vozsms_M-3\", lower(trim(col(\"vozsms\"))))      \n",
    "                 .withColumn(\"voice_amount_M-3\", when(lower(col(\"vozsms\")) == 'voz', col(\"importecobrado\")).otherwise(0))\n",
    "                 .withColumn(\"sms_amount_M-3\", when(lower(col(\"vozsms\")) == 'sms', col(\"importecobrado\")).otherwise(0))\n",
    "              .groupBy(\"numeroorigen_M-3\")\n",
    "              .agg(sql_sum(\"voice_amount_M-3\").alias(\"voice_amount_M-3\"),\n",
    "                   sql_sum(\"sms_amount_M-3\").alias(\"sms_amount_M-3\"),\n",
    "                   sql_sum(\"importecobrado\").alias(\"voicesms_amount_M-3\"),\n",
    "                   count(when((lower(col(\"vozsms_M-3\")) == 'voz'), col(\"vozsms\")).otherwise(None)).alias(\"voice_num_M-3\"),\n",
    "                   count(when((lower(col(\"vozsms_M-3\")) == 'sms'), col(\"vozsms\")).otherwise(None)).alias(\"sms_num_M-3\"),\n",
    "                   sql_sum(when((lower(col(\"vozsms_M-3\")) == 'voz'), col(\"airduration\")).otherwise(None)).alias(\"voice_duration_M-3\"),\n",
    "                   avg(when((lower(col(\"vozsms_M-3\")) == 'voz'), col(\"airduration\")).otherwise(None)).alias(\"voice_avg_duration_M-3\"),\n",
    "                   countDistinct(when((lower(col(\"vozsms_M-3\")) == 'voz'), col(\"numerodestino_M-3\")).otherwise(None)).alias(\"voice_num_distinct_rec_M-3\"),\n",
    "                   countDistinct(when((lower(col(\"vozsms_M-3\")) == 'sms'), col(\"numerodestino_M-3\")).otherwise(None)).alias(\"sms_num_distinct_rec_M-3\"))\n",
    "             .withColumnRenamed(\"numeroorigen_M-3\", \"msisdn\")  \n",
    "               )\n",
    "\n",
    "df_voicesms_M_4 = (spark.read.table(\"raw_es.prepaid_trafficvoicesms\")\n",
    "                       .filter(col(\"year\") == (int(MONTH_BEFORE_M_4[:4])))\n",
    "                       .filter(col(\"month\") == (int(MONTH_BEFORE_M_4[4:6])))\n",
    "                 .withColumn(\"numeroorigen_M-4\", trim(col(\"numeroorigen\")))\n",
    "                 .withColumn(\"numerodestino_M-4\", trim(col(\"numerodestino\")))\n",
    "                 .withColumn(\"vozsms_M-4\", lower(trim(col(\"vozsms\"))))      \n",
    "                 .withColumn(\"voice_amount_M-4\", when(lower(col(\"vozsms\")) == 'voz', col(\"importecobrado\")).otherwise(0))\n",
    "                 .withColumn(\"sms_amount_M-4\", when(lower(col(\"vozsms\")) == 'sms', col(\"importecobrado\")).otherwise(0))\n",
    "              .groupBy(\"numeroorigen_M-4\")\n",
    "              .agg(sql_sum(\"voice_amount_M-4\").alias(\"voice_amount_M-4\"),\n",
    "                   sql_sum(\"sms_amount_M-4\").alias(\"sms_amount_M-4\"),\n",
    "                   sql_sum(\"importecobrado\").alias(\"voicesms_amount_M-4\"),\n",
    "                   count(when((lower(col(\"vozsms_M-4\")) == 'voz'), col(\"vozsms_M-4\")).otherwise(None)).alias(\"voice_num_M-4\"),\n",
    "                   count(when((lower(col(\"vozsms_M-4\")) == 'sms'), col(\"vozsms_M-4\")).otherwise(None)).alias(\"sms_num_M-4\"),\n",
    "                   sql_sum(when((lower(col(\"vozsms_M-4\")) == 'voz'), col(\"airduration\")).otherwise(None)).alias(\"voice_duration_M-4\"),\n",
    "                   avg(when((lower(col(\"vozsms_M-4\")) == 'voz'), col(\"airduration\")).otherwise(None)).alias(\"voice_avg_duration_M-4\"),\n",
    "                   countDistinct(when((lower(col(\"vozsms_M-4\")) == 'voz'), col(\"numerodestino_M-4\")).otherwise(None)).alias(\"voice_num_distinct_rec_M-4\"),\n",
    "                   countDistinct(when((lower(col(\"vozsms_M-4\")) == 'sms'), col(\"numerodestino_M-4\")).otherwise(None)).alias(\"sms_num_distinct_rec_M-4\"))\n",
    "             .withColumnRenamed(\"numeroorigen_M-4\", \"msisdn\")  \n",
    "               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_voicesms_pre1 = (df_voicesms_M_1\n",
    "                       .join(df_voicesms_M_2, on = 'msisdn' ,how = 'left'))\n",
    "\n",
    "df_voicesms_pre2 = (df_voicesms_pre1\n",
    "                            .join(df_voicesms_M_3, on = 'msisdn' ,how = 'left'))\n",
    "\n",
    "df_voicesms = (df_voicesms_pre2\n",
    "                       .join(df_voicesms_M_4, on = 'msisdn' ,how = 'left'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información de recargas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "recargas_cols = spark.read.table('raw_es.vf_pre_recargas').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "recargas_cols.remove('partitioned_month')\n",
    "recargas_cols.remove('year')\n",
    "recargas_cols.remove('month')\n",
    "recargas_cols.remove('day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mes M-2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recargas_M_2 = (spark.read.option(\"delimiter\", \"\\t\").option(\"header\", False).csv(\"/data/raw/vf_es/cvm/ES_CVM_PREPREC_DATALAB_M/1.1/csv/partitioned_month=\"\n",
    "                                                                                  +MONTH_BEFORE_M_2[0:6]+\"/year=\"+MONTH_BEFORE_M_2[0:4]+\"/month=\"+str(int(MONTH_BEFORE_M_2[4:6]))+\"/day=0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "cols_previas = df_recargas_M_2.columns\n",
    "\n",
    "for c in recargas_cols:\n",
    "    df_recargas_M_2 = df_recargas_M_2.withColumnRenamed(cols_previas[i], c)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recargas_M_2 = (df_recargas_M_2\n",
    "                   .withColumn('cdmetodo_M-2', col('cdmetodo').cast(DoubleType()))\n",
    "                   .withColumn('imporcaj_M-2', col('imporcaj').cast(DoubleType()))\n",
    "                   .withColumn('importar_M-2', col('importar').cast(DoubleType()))\n",
    "                   .withColumn('imporotr_M-2', col('imporotr').cast(DoubleType()))\n",
    "                   .withColumn('acreccaj_M-2', col('acreccaj').cast(DoubleType()))\n",
    "                   .withColumn('acrectar_M-2', col('acrectar').cast(DoubleType()))\n",
    "                   .withColumn('acrecotr_M-2', col('acrecotr').cast(DoubleType()))\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recargas_M_2 = (df_recargas_M_2\n",
    "                   .groupBy('nif')\n",
    "                   .agg(sum(col('importar_M-2')).alias('sum-importar_M-2'),\n",
    "                        sum(col('imporcaj_M-2')).alias('sum-imporcaj_M-2'),\n",
    "                        sum(col('imporotr_M-2')).alias('sum-imporotr_M-2'),\n",
    "                        sum(col('acreccaj_M-2')).alias('sum-acreccaj_M-2'),\n",
    "                        sum(col('acrectar_M-2')).alias('sum-acrectar_M-2'),\n",
    "                        sum(col('acrecotr_M-2')).alias('sum-acrecotr_M-2'),\n",
    "                        F.avg(col('cdmetodo_M-2')).alias('sum-cdmetodo_M-2'),\n",
    "                       )\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mes M-3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recargas_M_3 = (spark.read.option(\"delimiter\", \"\\t\").option(\"header\", False).csv(\"/data/raw/vf_es/cvm/ES_CVM_PREPREC_DATALAB_M/1.1/csv/partitioned_month=\"\n",
    "                                                                                  +MONTH_BEFORE_M_3[0:6]+\"/year=\"+MONTH_BEFORE_M_3[0:4]+\"/month=\"+str(int(MONTH_BEFORE_M_3[4:6]))+\"/day=0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "cols_previas = df_recargas_M_3.columns\n",
    "\n",
    "for c in recargas_cols:\n",
    "    df_recargas_M_3 = df_recargas_M_3.withColumnRenamed(cols_previas[i], c)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recargas_M_3 = (df_recargas_M_3\n",
    "                   .withColumn('cdmetodo_M-3', col('cdmetodo').cast(DoubleType()))\n",
    "                   .withColumn('imporcaj_M-3', col('imporcaj').cast(DoubleType()))\n",
    "                   .withColumn('importar_M-3', col('importar').cast(DoubleType()))\n",
    "                   .withColumn('imporotr_M-3', col('imporotr').cast(DoubleType()))\n",
    "                   .withColumn('acreccaj_M-3', col('acreccaj').cast(DoubleType()))\n",
    "                   .withColumn('acrectar_M-3', col('acrectar').cast(DoubleType()))\n",
    "                   .withColumn('acrecotr_M-3', col('acrecotr').cast(DoubleType()))\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recargas_M_3 = (df_recargas_M_3\n",
    "                   .groupBy('nif')\n",
    "                   .agg(sum(col('importar_M-3')).alias('sum-importar_M-3'),\n",
    "                        sum(col('imporcaj_M-3')).alias('sum-imporcaj_M-3'),\n",
    "                        sum(col('imporotr_M-3')).alias('sum-imporotr_M-3'),\n",
    "                        sum(col('acreccaj_M-3')).alias('sum-acreccaj_M-3'),\n",
    "                        sum(col('acrectar_M-3')).alias('sum-acrectar_M-3'),\n",
    "                        sum(col('acrecotr_M-3')).alias('sum-acrecotr_M-3'),\n",
    "                        F.avg(col('cdmetodo_M-3')).alias('sum-cdmetodo_M-3'),\n",
    "                       )\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mes M-4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recargas_M_4 = (spark.read.option(\"delimiter\", \"\\t\").option(\"header\", False).csv(\"/data/raw/vf_es/cvm/ES_CVM_PREPREC_DATALAB_M/1.1/csv/partitioned_month=\"\n",
    "                                                                                  +MONTH_BEFORE_M_4[0:6]+\"/year=\"+MONTH_BEFORE_M_4[0:4]+\"/month=\"+str(int(MONTH_BEFORE_M_4[4:6]))+\"/day=0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "cols_previas = df_recargas_M_4.columns\n",
    "\n",
    "for c in recargas_cols:\n",
    "    df_recargas_M_4 = df_recargas_M_4.withColumnRenamed(cols_previas[i], c)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recargas_M_4 = (df_recargas_M_4\n",
    "                   .withColumn('cdmetodo_M-4', col('cdmetodo').cast(DoubleType()))\n",
    "                   .withColumn('imporcaj_M-4', col('imporcaj').cast(DoubleType()))\n",
    "                   .withColumn('importar_M-4', col('importar').cast(DoubleType()))\n",
    "                   .withColumn('imporotr_M-4', col('imporotr').cast(DoubleType()))\n",
    "                   .withColumn('acreccaj_M-4', col('acreccaj').cast(DoubleType()))\n",
    "                   .withColumn('acrectar_M-4', col('acrectar').cast(DoubleType()))\n",
    "                   .withColumn('acrecotr_M-4', col('acrecotr').cast(DoubleType()))\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recargas_M_4 = (df_recargas_M_4\n",
    "                   .groupBy('nif')\n",
    "                   .agg(sum(col('importar_M-4')).alias('sum-importar_M-4'),\n",
    "                        sum(col('imporcaj_M-4')).alias('sum-imporcaj_M-4'),\n",
    "                        sum(col('imporotr_M-4')).alias('sum-imporotr_M-4'),\n",
    "                        sum(col('acreccaj_M-4')).alias('sum-acreccaj_M-4'),\n",
    "                        sum(col('acrectar_M-4')).alias('sum-acrectar_M-4'),\n",
    "                        sum(col('acrecotr_M-4')).alias('sum-acrecotr_M-4'),\n",
    "                        F.avg(col('cdmetodo_M-4')).alias('sum-cdmetodo_M-4'),\n",
    "                       )\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mes M-5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recargas_M_5 = (spark.read.option(\"delimiter\", \"\\t\").option(\"header\", False).csv(\"/data/raw/vf_es/cvm/ES_CVM_PREPREC_DATALAB_M/1.1/csv/partitioned_month=\"\n",
    "                                                                                  +MONTH_BEFORE_M_5[0:6]+\"/year=\"+MONTH_BEFORE_M_5[0:4]+\"/month=\"+str(int(MONTH_BEFORE_M_5[4:6]))+\"/day=0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "cols_previas = df_recargas_M_5.columns\n",
    "\n",
    "for c in recargas_cols:\n",
    "    df_recargas_M_5 = df_recargas_M_5.withColumnRenamed(cols_previas[i], c)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recargas_M_5 = (df_recargas_M_5\n",
    "                   .withColumn('cdmetodo_M-5', col('cdmetodo').cast(DoubleType()))\n",
    "                   .withColumn('imporcaj_M-5', col('imporcaj').cast(DoubleType()))\n",
    "                   .withColumn('importar_M-5', col('importar').cast(DoubleType()))\n",
    "                   .withColumn('imporotr_M-5', col('imporotr').cast(DoubleType()))\n",
    "                   .withColumn('acreccaj_M-5', col('acreccaj').cast(DoubleType()))\n",
    "                   .withColumn('acrectar_M-5', col('acrectar').cast(DoubleType()))\n",
    "                   .withColumn('acrecotr_M-5', col('acrecotr').cast(DoubleType()))\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recargas_M_5 = (df_recargas_M_5\n",
    "                   .groupBy('nif')\n",
    "                   .agg(sum(col('importar_M-5')).alias('sum-importar_M-5'),\n",
    "                        sum(col('imporcaj_M-5')).alias('sum-imporcaj_M-5'),\n",
    "                        sum(col('imporotr_M-5')).alias('sum-imporotr_M-5'),\n",
    "                        sum(col('acreccaj_M-5')).alias('sum-acreccaj_M-5'),\n",
    "                        sum(col('acrectar_M-5')).alias('sum-acrectar_M-5'),\n",
    "                        sum(col('acrecotr_M-5')).alias('sum-acrecotr_M-5'),\n",
    "                        F.avg(col('cdmetodo_M-5')).alias('sum-cdmetodo_M-5'),\n",
    "                       )\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Join de todas la información de recargas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recargas_pre1 = df_recargas_M_2.join(df_recargas_M_3, on = 'nif', how = 'leftouter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recargas_pre2 = df_recargas_pre1.join(df_recargas_M_4, on = 'nif', how = 'leftouter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recargas_final = df_recargas_pre2.join(df_recargas_M_5, on = 'nif', how = 'leftouter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información del 'Monthly Fact'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mes M-2:  para hacer el tablón de entrenamiento de las predicciones de noviembre, no había datos del mes M-2 (julio), entonces he puesto M-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthly_fac_M_2 = (spark.read.option(\"delimiter\", \"\\t\").option(\"header\", False).csv(\"/data/raw/vf_es/cvm/ES_CVM_PREPAMONTHFACT_DATALAB_M/1.1/csv/partitioned_month=\"\n",
    "                                                                                  +MONTH_BEFORE_M_2[0:6]+\"/year=\"+MONTH_BEFORE_M_2[0:4]+\"/month=\"+str(int(MONTH_BEFORE_M_2[4:6]))+\"/day=0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "previos = spark.read.table('raw_es.vf_pre_prepaid_monthly_fact').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "previos.remove('msisdn')\n",
    "previos.remove('partitioned_month')\n",
    "previos.remove('year')\n",
    "previos.remove('month')\n",
    "previos.remove('day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "df_monthly_fac_M_2 = df_monthly_fac_M_2.withColumnRenamed('_c0', 'msisdn')\n",
    "\n",
    "mon_cols = df_monthly_fac_M_2.columns\n",
    "\n",
    "for c in previos:\n",
    "    df_monthly_fac_M_2 = df_monthly_fac_M_2.withColumnRenamed(mon_cols[i], c+'_M-2')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthly_fac_M_2 = df_monthly_fac_M_2.drop(*['fx_ciclo', 'mes', 'partitioned_month', 'year', 'month', 'day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mes M-3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthly_fac_M_3 = (spark.read.option(\"delimiter\", \"\\t\").option(\"header\", False).csv(\"/data/raw/vf_es/cvm/ES_CVM_PREPAMONTHFACT_DATALAB_M/1.1/csv/partitioned_month=\"\n",
    "                                                                                  +MONTH_BEFORE_M_4[0:6]+\"/year=\"+MONTH_BEFORE_M_4[0:4]+\"/month=\"+str(int(MONTH_BEFORE_M_4[4:6]))+\"/day=0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "df_monthly_fac_M_3 = df_monthly_fac_M_3.withColumnRenamed('_c0', 'msisdn')\n",
    "\n",
    "mon_cols = df_monthly_fac_M_3.columns\n",
    "\n",
    "for c in previos:\n",
    "    df_monthly_fac_M_3 = df_monthly_fac_M_3.withColumnRenamed(mon_cols[i], c+'_M-3')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthly_fac_M_3 = df_monthly_fac_M_3.drop(*['fx_ciclo', 'mes', 'partitioned_month', 'year', 'month', 'day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mes M-4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthly_fac_M_4 = (spark.read.option(\"delimiter\", \"\\t\").option(\"header\", False).csv(\"/data/raw/vf_es/cvm/ES_CVM_PREPAMONTHFACT_DATALAB_M/1.1/csv/partitioned_month=\"\n",
    "                                                                                  +MONTH_BEFORE_M_4[0:6]+\"/year=\"+MONTH_BEFORE_M_4[0:4]+\"/month=\"+str(int(MONTH_BEFORE_M_4[4:6]))+\"/day=0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "df_monthly_fac_M_4 = df_monthly_fac_M_4.withColumnRenamed('_c0', 'msisdn')\n",
    "\n",
    "mon_cols = df_monthly_fac_M_4.columns\n",
    "\n",
    "for c in previos:\n",
    "    df_monthly_fac_M_4 = df_monthly_fac_M_4.withColumnRenamed(mon_cols[i], c+'_M-4')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthly_fac_M_4 = df_monthly_fac_M_4.drop(*['fx_ciclo', 'mes', 'partitioned_month', 'year', 'month', 'day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mes M-5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthly_fac_M_5 = (spark.read.option(\"delimiter\", \"\\t\").option(\"header\", False).csv(\"/data/raw/vf_es/cvm/ES_CVM_PREPAMONTHFACT_DATALAB_M/1.1/csv/partitioned_month=\"\n",
    "                                                                                  +MONTH_BEFORE_M_5[0:6]+\"/year=\"+MONTH_BEFORE_M_5[0:4]+\"/month=\"+str(int(MONTH_BEFORE_M_5[4:6]))+\"/day=0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "df_monthly_fac_M_5 = df_monthly_fac_M_5.withColumnRenamed('_c0', 'msisdn')\n",
    "\n",
    "mon_cols = df_monthly_fac_M_5.columns\n",
    "\n",
    "for c in previos:\n",
    "    df_monthly_fac_M_5 = df_monthly_fac_M_5.withColumnRenamed(mon_cols[i], c+'_M-5')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthly_fac_M_5 = df_monthly_fac_M_5.drop(*['fx_ciclo', 'mes', 'partitioned_month', 'year', 'month', 'day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Join de tablas del *`Monthly Fac`*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthlyfact_pre0 = df_monthly_fac_M_2.join(df_monthly_fac_M_3, on = 'msisdn', how = 'leftouter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthlyfact_pre1 = df_monthlyfact_pre0.join(df_monthly_fac_M_4, on = 'msisdn', how = 'leftouter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthlyfact_final = df_monthlyfact_pre1.join(df_monthly_fac_M_5, on = 'msisdn', how = 'leftouter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_fac_cols = df_monthlyfact_final.columns\n",
    "\n",
    "monthly_fac_cols.remove('msisdn')\n",
    "\n",
    "for c in monthly_fac_cols:\n",
    "    df_monthlyfact_final = df_monthlyfact_final.withColumn(c, col(c).cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consumo de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_consumed_M_1 = (spark.read.table(\"raw_es.prepaid_trafficdata\")\n",
    "                 .filter(col(\"year\") == (int(MONTH_BEFORE_M_1[:4])))\n",
    "                 .filter(col(\"month\") == (int(MONTH_BEFORE_M_1[4:6])))\n",
    "                 .filter(col(\"month\") <= 15)\n",
    "                 .withColumn(\"data_mb\", col(\"volumen\")/(1024*1024))\n",
    "                 .groupBy(\"msisdn\")\n",
    "                 .agg(sql_sum(\"data_mb\").alias(\"data_mb_M-1\"),\n",
    "                      sql_sum(\"CARGOREAL\").alias(\"data_amount_M-1\"),\n",
    "                      count(\"data_mb\").alias(\"num_conexions_M-1\"))\n",
    "                 .select(*[\"data_mb_M-1\", \"msisdn\", \"data_amount_M-1\", \"num_conexions_M-1\"])\n",
    "                       )\n",
    "\n",
    "df_data_consumed_M_2 = (spark.read.table(\"raw_es.prepaid_trafficdata\")\n",
    "                 .filter(col(\"year\") == (int(MONTH_BEFORE_M_2[:4])))\n",
    "                 .filter(col(\"month\") == (int(MONTH_BEFORE_M_2[4:6])))\n",
    "                 .withColumn(\"data_mb\", col(\"volumen\")/(1024*1024))\n",
    "                 .groupBy(\"msisdn\")\n",
    "                 .agg(sql_sum(\"data_mb\").alias(\"data_mb_M-2\"),\n",
    "                      sql_sum(\"CARGOREAL\").alias(\"data_amount_M-2\"),\n",
    "                      count(\"data_mb\").alias(\"num_conexions_M-2\"))\n",
    "                 .select(*[\"data_mb_M-2\", \"msisdn\", \"data_amount_M-2\", \"num_conexions_M-2\"])\n",
    "                       )\n",
    "\n",
    "df_data_consumed_M_3 = (spark.read.table(\"raw_es.prepaid_trafficdata\")\n",
    "                 .filter(col(\"year\") == (int(MONTH_BEFORE_M_3[:4])))\n",
    "                 .filter(col(\"month\") == (int(MONTH_BEFORE_M_3[4:6])))\n",
    "                 .withColumn(\"data_mb\", col(\"volumen\")/(1024*1024))\n",
    "                 .groupBy(\"msisdn\")\n",
    "                 .agg(sql_sum(\"data_mb\").alias(\"data_mb_M-3\"),\n",
    "                      sql_sum(\"CARGOREAL\").alias(\"data_amount_M-3\"),\n",
    "                      count(\"data_mb\").alias(\"num_conexions_M-3\"))\n",
    "                 .select(*[\"data_mb_M-3\", \"msisdn\", \"data_amount_M-3\", \"num_conexions_M-3\"])\n",
    "                       )\n",
    "\n",
    "df_data_consumed_M_4 = (spark.read.table(\"raw_es.prepaid_trafficdata\")\n",
    "                 .filter(col(\"year\") == (int(MONTH_BEFORE_M_4[:4])))\n",
    "                 .filter(col(\"month\") == (int(MONTH_BEFORE_M_4[4:6])))\n",
    "                 .withColumn(\"data_mb\", col(\"volumen\")/(1024*1024))\n",
    "                 .groupBy(\"msisdn\")\n",
    "                 .agg(sql_sum(\"data_mb\").alias(\"data_mb_M-4\"),\n",
    "                      sql_sum(\"CARGOREAL\").alias(\"data_amount_M-4\"),\n",
    "                      count(\"data_mb\").alias(\"num_conexions_M-4\"))\n",
    "                 .select(*[\"data_mb_M-4\", \"msisdn\", \"data_amount_M-4\", \"num_conexions_M-4\"])\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_consumed_pre1 = (df_data_consumed_M_1\n",
    "                       .join(df_data_consumed_M_2, on = 'msisdn' ,how = 'left'))\n",
    "\n",
    "df_data_consumed_pre2 = (df_data_consumed_pre1\n",
    "                            .join(df_data_consumed_M_3, on = 'msisdn' ,how = 'left'))\n",
    "\n",
    "df_data_consumed = (df_data_consumed_pre2\n",
    "                       .join(df_data_consumed_M_4, on = 'msisdn' ,how = 'left'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información de tarificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ### Ahora, trabajamos con los resultados agregados por mes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lectura de columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarificador_meses_previos = spark.read.table(\"raw_es.vf_pre_info_tarif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarificador_meses_previos = tarificador_meses_previos.drop(*['partitioned_month', 'year', 'month', 'day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- M-2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarificador_month_M_2 = (sqlContext.read.format('csv').options(header='false', inferSchema='true', delimiter = '\\t')\n",
    "                    .load('/data/raw/vf_es/cvm/ES_CVM_PREPTAR_DATALAB_M/1.1/csv/partitioned_month='+MONTH_BEFORE_M_2[0:6]+'/year='+MONTH_BEFORE_M_2[0:4]+'/month='+str(int(MONTH_BEFORE_M_2[4:6]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarificador_month_M_2 = tarificador_month_M_2.drop(*['day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "tarificador_month_M_2 = tarificador_month_M_2.withColumnRenamed('_c0', 'msisdn')\n",
    "\n",
    "while i < len(tarificador_month_M_2.columns):\n",
    "    tarificador_month_M_2 = tarificador_month_M_2.withColumnRenamed(tarificador_month_M_2.columns[i], tarificador_meses_previos.columns[i].upper()+'_previo_M_2')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- M-3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarificador_month_M_3= (sqlContext.read.format('csv').options(header='false', inferSchema='true', delimiter = '\\t')\n",
    "                    .load('/data/raw/vf_es/cvm/ES_CVM_PREPTAR_DATALAB_M/1.1/csv/partitioned_month='+MONTH_BEFORE_M_3[0:6]+'/year='+MONTH_BEFORE_M_3[0:4]+'/month='+str(int(MONTH_BEFORE_M_3[4:6]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarificador_month_M_3 = tarificador_month_M_3.drop(*['day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "tarificador_month_M_3 = tarificador_month_M_3.withColumnRenamed('_c0', 'msisdn')\n",
    "\n",
    "while i < len(tarificador_month_M_3.columns):\n",
    "    tarificador_month_M_3 = tarificador_month_M_3.withColumnRenamed(tarificador_month_M_3.columns[i], tarificador_meses_previos.columns[i].upper()+'_previo_M_3')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- M-4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarificador_month_M_4 = (sqlContext.read.format('csv').options(header='false', inferSchema='true', delimiter = '\\t')\n",
    "                    .load('/data/raw/vf_es/cvm/ES_CVM_PREPTAR_DATALAB_M/1.1/csv/partitioned_month='+MONTH_BEFORE_M_4[0:6]+'/year='+MONTH_BEFORE_M_4[0:4]+'/month='+str(int(MONTH_BEFORE_M_4[4:6]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarificador_month_M_4 = tarificador_month_M_4.drop(*['day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "tarificador_month_M_4 = tarificador_month_M_4.withColumnRenamed('_c0', 'msisdn')\n",
    "\n",
    "while i < len(tarificador_month_M_4.columns):\n",
    "    tarificador_month_M_4 = tarificador_month_M_4.withColumnRenamed(tarificador_month_M_4.columns[i], tarificador_meses_previos.columns[i].upper()+'_previo_M_4')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- M-5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarificador_month_M_5 = (sqlContext.read.format('csv').options(header='false', inferSchema='true', delimiter = '\\t')\n",
    "                    .load('/data/raw/vf_es/cvm/ES_CVM_PREPTAR_DATALAB_M/1.1/csv/partitioned_month='+MONTH_BEFORE_M_5[0:6]+'/year='+MONTH_BEFORE_M_5[0:4]+'/month='+str(int(MONTH_BEFORE_M_5[4:6]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarificador_month_M_5 = tarificador_month_M_5.drop(*['day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "tarificador_month_M_5 = tarificador_month_M_5.withColumnRenamed('_c0', 'msisdn')\n",
    "\n",
    "while i < len(tarificador_month_M_5.columns):\n",
    "    tarificador_month_M_5 = tarificador_month_M_5.withColumnRenamed(tarificador_month_M_5.columns[i], tarificador_meses_previos.columns[i].upper()+'_previo_M_5')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Join de toda la información de tarificación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarifas_pre = tarificador_month_M_2.join(tarificador_month_M_3, on = 'msisdn', how = 'inner')\n",
    "tarifas_pre1 = tarifas_pre.join(tarificador_month_M_4, on = 'msisdn', how = 'inner')\n",
    "df_tarifas = tarifas_pre1.join(tarificador_month_M_5, on = 'msisdn', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1829856"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tarifas.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información de la cartera `Yu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "yu_meses_previos = spark.read.table(\"raw_es.vf_pre_cartera_yu_ba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "yu_meses_previos = yu_meses_previos.drop(*['partitioned_month', 'year', 'month', 'day']).withColumnRenamed('telefono', 'msisdn').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mes M-2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yu_M_2 = (sqlContext.read.format('csv')\n",
    "                    .options(header='false', inferSchema='true', delimiter = '\\t')\n",
    "                    .load('/data/raw/vf_es/cvm/ES_CVM_EXTRYUBAPORT_DATALAB_M/1.1/csv/partitioned_month='+MONTH_BEFORE_M_2[0:6]+'/year='+MONTH_BEFORE_M_2[0:4]+'/month='+str(int(MONTH_BEFORE_M_2[4:6])))\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yu_M_2 = df_yu_M_2.drop(*['day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "df_yu_M_2 = df_yu_M_2.withColumnRenamed('_c0', 'msisdn')\n",
    "\n",
    "while i < len(yu_meses_previos):\n",
    "    df_yu_M_2 = df_yu_M_2.withColumnRenamed(df_yu_M_2.columns[i], yu_meses_previos[i].upper()+'_previo_M_2')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mes M-3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yu_M_3 = (sqlContext.read.format('csv')\n",
    "                    .options(header='false', inferSchema='true', delimiter = '\\t')\n",
    "                    .load('/data/raw/vf_es/cvm/ES_CVM_EXTRYUBAPORT_DATALAB_M/1.1/csv/partitioned_month='+MONTH_BEFORE_M_3[0:6]+'/year='+MONTH_BEFORE_M_3[0:4]+'/month='+str(int(MONTH_BEFORE_M_3[4:6])))\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yu_M_3 = df_yu_M_3.drop(*['day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "df_yu_M_3 = df_yu_M_3.withColumnRenamed('_c0', 'msisdn')\n",
    "\n",
    "while i < len(yu_meses_previos):\n",
    "    df_yu_M_3 = df_yu_M_3.withColumnRenamed(df_yu_M_3.columns[i], yu_meses_previos[i].upper()+'_previo_M_3')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mes M-4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yu_M_4 = (sqlContext.read.format('csv')\n",
    "                    .options(header='false', inferSchema='true', delimiter = '\\t')\n",
    "                    .load('/data/raw/vf_es/cvm/ES_CVM_EXTRYUBAPORT_DATALAB_M/1.1/csv/partitioned_month='+MONTH_BEFORE_M_4[0:6]+'/year='+MONTH_BEFORE_M_4[0:4]+'/month='+str(int(MONTH_BEFORE_M_4[4:6])))\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yu_M_4 = df_yu_M_4.drop(*['day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "df_yu_M_4 = df_yu_M_4.withColumnRenamed('_c0', 'msisdn')\n",
    "\n",
    "while i < len(yu_meses_previos):\n",
    "    df_yu_M_4 = df_yu_M_4.withColumnRenamed(df_yu_M_4.columns[i], yu_meses_previos[i].upper()+'_previo_M_4')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Join de información sobre Comunidad Yu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yu_previo1 = df_yu_M_2.join(df_yu_M_3, on = 'msisdn', how = 'leftouter')\n",
    "df_yu_final = df_yu_previo1.join(df_yu_M_4, on = 'msisdn', how = 'leftouter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CUR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_vega = spark.read.parquet('/data/raw/vf_es/billingtopsups/CUR_VEGA/1.0/parquet/year='+MONTH_BEFORE_M_2[:4]+'/month='+str(int(MONTH_BEFORE_M_2[4:6])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cur_vega = cur_vega.withColumn('msisdn', expr(\"substring(MSISDN, 3, length(MSISDN)-1)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_timestamp = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import datediff, to_date, to_timestamp\n",
    "\n",
    "cur_vega_pre = (test_cur_vega\n",
    "            .withColumn('activacion', when(col('razon_concesion') == 'ACTIVACION', 1).otherwise(0))\n",
    "            .withColumn('renovacion', when(col('razon_concesion') == 'RENOVACION', 1).otherwise(0))\n",
    "            .withColumn('suscripcion', when(col('razon_concesion') == 'SUSCRIPCION', 1).otherwise(0))\n",
    "            .withColumn('fx_concesion', to_timestamp(\"FECHA_CONCESION\", \"%Y-%m-%d %H:%M:%S\"))\n",
    "            .withColumn('fx_fin_validez', to_timestamp(\"FECHA_FIN_VALIDEZ\", \"%Y-%m-%d %H:%M:%S\"))\n",
    "            .withColumn('days_fx_concesion_2_fin_validez', datediff('fx_fin_validez','fx_concesion'))\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_vega = (cur_vega_pre\n",
    "            .groupBy('msisdn')\n",
    "            .agg(F.sum(col('activacion')).alias('num_activaciones'),\n",
    "                 F.sum(col('renovacion')).alias('num_renovacion'),\n",
    "                 F.sum(col('suscripcion')).alias('num_suscripcion'),\n",
    "                 F.max(col('tipo_beneficio')).alias('tipo_beneficio'),\n",
    "                 F.sum(col('days_fx_concesion_2_fin_validez')).alias('days_fx_concesion_2_fin_validez')\n",
    "                )\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dump = spark.read.parquet('/data/raw/vf_es/billingtopsups/CUR_DUMP/1.0/parquet/year='+MONTH_BEFORE_M_2[:4]+'/month='+str(int(MONTH_BEFORE_M_2[4:6])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cur_dump = (cur_dump\n",
    "                 .withColumn('msisdn', expr(\"substring(vfsid, 3, length(vfsid)-1)\"))\n",
    "                 .withColumn('fx_1stcall', to_timestamp(\"vf1stcalldate\", \"%Y-%m-%d %H:%M:%S\"))\n",
    "                 .withColumn('fx_1stactivation', to_timestamp(\"vf1stactdate\", \"%Y-%m-%d %H:%M:%S\"))\n",
    "                 .withColumn('fx_eslapsed', to_timestamp(\"vfeslapseddate\", \"%Y-%m-%d %H:%M:%S\"))\n",
    "                 .withColumn('fx_expiration', to_timestamp(\"vfesexpirationdate\", \"%Y-%m-%d %H:%M:%S\"))\n",
    "                 .withColumn('days_since_activation2call', datediff('fx_1stactivation','fx_1stcall'))\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dump = (test_cur_dump\n",
    "            .groupBy('msisdn')\n",
    "            .agg(F.max(col('vfespreactreason')).alias('pre_activation_reason'),\n",
    "                 F.sum(col('vfimeisv')).alias('imei_sv'),\n",
    "                 F.max(col('vfplan')).alias('tarifa'),\n",
    "                 F.sum(col('days_since_activation2call')).alias('days_since_activation2call'),\n",
    "\n",
    "                )\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unimos tablas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_pre0 = df_prepago_labeled.join(cur_dump, on = 'msisdn', how = 'leftouter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_pre1 = df_final_pre0.join(cur_vega, on = 'msisdn', how = 'leftouter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_pre2 = df_final_pre1.join(df_tarifas, on = 'msisdn', how = \"leftouter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_pre3 = df_final_pre2.join(df_yu_final, on = 'msisdn', how = \"leftouter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_pre4 = df_final_pre3.join(df_monthlyfact_final, on = 'msisdn', how = 'leftouter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_pre5 = df_final_pre4.join(df_recargas_final, on = df_final_pre4['NIF_CLIENTE']==df_recargas_final['nif'], how= 'leftouter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_pre6 = df_final_pre5.join(df_balance_receptor, on='msisdn', how=\"leftouter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_pre7 = df_final_pre6.join(df_balance_emisor, on ='msisdn', how=\"leftouter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_pre8 = (df_final_pre7\n",
    "    .withColumn(\"tbal_rec_amount\", 1.21*col(\"importe_traspasado_receptor_M-1\"))\n",
    "    .withColumnRenamed(\"num_rec\", \"tbal_rec_num\")\n",
    "    .withColumn(\"tbal_tra_amount\", 1.21*col(\"importe_traspasado_emisor_M-1\") + 1.21*col(\"importe_cargo_emisor_M-1\"))\n",
    "    .withColumnRenamed(\"num_em\", \"tbal_tra_num\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_pre9 = df_final_pre8.join(df_topups, on = 'msisdn', how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_pre10 = df_final_pre9.join(df_voicesms, on = 'msisdn', how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_pre11 = df_final_pre10.join(df_data_consumed, on = 'msisdn', how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_pre12 = df_final_pre11.join(df_advance_solicitado, on = 'msisdn', how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_pre13 = df_final_pre12.join(df_balance, on ='msisdn', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_pre14 = df_final_pre13.join(df_advance_recuperado, on = 'msisdn', how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final_pre14.drop(*[\"MSISDN_tarif\", \"MSISDN_tarif_M_1\", \"MSISDN_tarif_M_2\", \"MSISDN_tarif_M_3\", \"MSISDN_tarif_M_4\", \"MSISDN_tarif_M_5\", \"NIF_FACTURACION_M-2\",\n",
    "                                     \"msisdn_emisor\",\"msisdn_receptor\", 'MSISDN_tarif', \"NIF_FACTURACION_M-1\", 'Num_services_M-2', \"NIF_FACTURACION_M-3\", \"Fx_ejec_M\", \"Num_services_M-1\",\n",
    "                                     \"count(month)\", \"nationality\", 'msisdn_pre', 'MSISDN_previo_M_2', \"year_rec\", \"month_rec\", \"day_rec\", \"msisdn_rec\", \"MSISDN_balances\",\n",
    "                                     \"year_advance\", \"month_advance\", \"day_advance\", \"msisdn_advance\",\"year_data\", \"month_data\", \"day_data\", \"msisdn_data\",\"year_data\", \"month_data\", \"day_data\", \"msisdn_data\",\n",
    "                                     \"year_topups\", \"month_topups\", \"day_topups\", \"ndc_msisdn\", \n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Añadimos ahora información de Netscout, CCC y otras fuentes de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta fecha ha de ser cambiada en función de la entrega a realizar.\n",
    "\n",
    "ClosingDay = MONTH_BEFORE_M_2\n",
    "\n",
    "ClosingDay_date = datetime.date(int(ClosingDay[:4]), int(ClosingDay[4:6]), int(ClosingDay[6:8]))\n",
    "\n",
    "hdfs_partition_path = 'year=' + str(int(ClosingDay[:4])) + '/month=' + str(int(ClosingDay[4:6])) + '/day=' + str(int(ClosingDay[6:8]))\n",
    "\n",
    "hdfs_write_path_common='/data/udf/vf_es/amdocs_ids/'\n",
    "\n",
    "path_customer = hdfs_write_path_common +'customer/'+hdfs_partition_path\n",
    "path_service = hdfs_write_path_common +'service/'+hdfs_partition_path\n",
    "path_netscout_apps = hdfs_write_path_common +'netscout_apps/'+hdfs_partition_path\n",
    "path_customer_agg = hdfs_write_path_common +'customer_agg/'+hdfs_partition_path\n",
    "\n",
    "netscout_apps_load = spark.read.load(path_netscout_apps)\n",
    "custAggServices=(spark.read.load(path_customer_agg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información de CCC: M-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClosingDay_M_2 = MONTH_BEFORE_M_2\n",
    "\n",
    "hdfs_partition_path_M_2 = 'year=' + str(int(ClosingDay_M_2[:4])) + '/month=' + str(int(ClosingDay_M_2[4:6])) + '/day=' + str(int(ClosingDay_M_2[6:8]))\n",
    "path_calls_to_competitor = '/data/attributes/vf_es/return_feed/call_to_competitor/'+hdfs_partition_path_M_2\n",
    "path_ccc = hdfs_write_path_common +'call_centre_calls/' + hdfs_partition_path_M_2\n",
    "\n",
    "competitor_calls_M_2 = (spark.read.load(path_calls_to_competitor))\n",
    "df_ccc_load_M_2 = (spark.read.load(path_ccc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ccc_load_M_2 = (df_ccc_load_M_2\n",
    "                   .select(['Bucket_Sub_Bucket_Churn_Cancellations_Other_churn_issues',\n",
    "                            'Bucket_Sub_Bucket_Churn_Cancellations_Churn_cancellations_process',\n",
    "                            'Bucket_Sub_Bucket_Prepaid_balance_Top_up_process',\n",
    "                            'Bucket_Sub_Bucket_Churn_Cancellations_Negotiation',\n",
    "                            'Bucket_Sub_Bucket_Churn_Cancellations_Referrals',\n",
    "                            'Bucket_Sub_Bucket_Churn_Cancellations_Transfers',\n",
    "                            'Bucket_Sub_Bucket_Churn_Cancellations_Network',\n",
    "                            'Raw_Productos_Voz','Raw_Resultado_Bajas',\n",
    "                            'Raw_Provision_Resto','Raw_Provision_Movil',\n",
    "                            'Bucket_Churn_Cancellations','Bucket_Prepaid_balance',\n",
    "                            'Raw_Baja','Raw_Cierre', 'msisdn'\n",
    "                           ])\n",
    "                   .withColumnRenamed('Bucket_Sub_Bucket_Churn_Cancellations_Other_churn_issues', 'Bucket_Sub_Bucket_Churn_Cancellations_Other_churn_issues-M-2')\n",
    "                   .withColumnRenamed('Bucket_Sub_Bucket_Churn_Cancellations_Churn_cancellations_process', 'Bucket_Sub_Bucket_Churn_Cancellations_Churn_cancellations_process-M-2')\n",
    "                   .withColumnRenamed('Bucket_Sub_Bucket_Prepaid_balance_Top_up_process', 'Bucket_Sub_Bucket_Prepaid_balance_Top_up_process-M-2')\n",
    "                   .withColumnRenamed('Bucket_Sub_Bucket_Churn_Cancellations_Negotiation', 'Bucket_Sub_Bucket_Churn_Cancellations_Negotiation-M-2')\n",
    "                   .withColumnRenamed('Bucket_Sub_Bucket_Churn_Cancellations_Referrals', 'Bucket_Sub_Bucket_Churn_Cancellations_Referrals-M-2')\n",
    "                   .withColumnRenamed('Bucket_Sub_Bucket_Churn_Cancellations_Transfers', 'Bucket_Sub_Bucket_Churn_Cancellations_Transfers-M-2')\n",
    "                   .withColumnRenamed('Bucket_Sub_Bucket_Churn_Cancellations_Network', 'Bucket_Sub_Bucket_Churn_Cancellations_Network-M-2')\n",
    "                   .withColumnRenamed('Raw_Productos_Voz', 'Raw_Productos_Voz-M-2')\n",
    "                   .withColumnRenamed('Raw_Resultado_Bajas', 'Raw_Resultado_Bajas-M-2')\n",
    "                   .withColumnRenamed('Raw_Provision_Resto', 'Raw_Provision_Resto-M-2')\n",
    "                   .withColumnRenamed('Raw_Provision_Movil', 'Raw_Provision_Movil-M-2')\n",
    "                   .withColumnRenamed('Bucket_Churn_Cancellations', 'Bucket_Churn_Cancellations-M-2')\n",
    "                   .withColumnRenamed('Bucket_Prepaid_balance', 'Bucket_Prepaid_balance-M-2')\n",
    "                   .withColumnRenamed('Raw_Baja', 'Raw_Baja-M-2')\n",
    "                   .withColumnRenamed('Raw_Cierre', 'Raw_Cierre-M-2')\n",
    "\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información de CCC: M-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClosingDay_M_3 = MONTH_BEFORE_M_3\n",
    "\n",
    "hdfs_partition_path_M_3 = 'year=' + str(int(ClosingDay_M_3[:4])) + '/month=' + str(int(ClosingDay_M_3[4:6])) + '/day=' + str(int(ClosingDay_M_3[6:8]))\n",
    "path_calls_to_competitor = '/data/attributes/vf_es/return_feed/call_to_competitor/'+hdfs_partition_path_M_3\n",
    "path_ccc = hdfs_write_path_common +'call_centre_calls/' + hdfs_partition_path_M_3\n",
    "\n",
    "competitor_calls_M_3 = (spark.read.load(path_calls_to_competitor))\n",
    "df_ccc_load_M_3 = (spark.read.load(path_ccc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ccc_load_M_3 = (df_ccc_load_M_3\n",
    "                   .select(['Bucket_Sub_Bucket_Churn_Cancellations_Other_churn_issues',\n",
    "                            'Bucket_Sub_Bucket_Churn_Cancellations_Churn_cancellations_process',\n",
    "                            'Bucket_Sub_Bucket_Prepaid_balance_Top_up_process',\n",
    "                            'Bucket_Sub_Bucket_Churn_Cancellations_Negotiation',\n",
    "                            'Bucket_Sub_Bucket_Churn_Cancellations_Referrals',\n",
    "                            'Bucket_Sub_Bucket_Churn_Cancellations_Transfers',\n",
    "                            'Bucket_Sub_Bucket_Churn_Cancellations_Network',\n",
    "                            'Raw_Productos_Voz','Raw_Resultado_Bajas',\n",
    "                            'Raw_Provision_Resto','Raw_Provision_Movil',\n",
    "                            'Bucket_Churn_Cancellations','Bucket_Prepaid_balance',\n",
    "                            'Raw_Baja','Raw_Cierre', 'msisdn'\n",
    "                           ])\n",
    "                   .withColumnRenamed('Bucket_Sub_Bucket_Churn_Cancellations_Other_churn_issues', 'Bucket_Sub_Bucket_Churn_Cancellations_Other_churn_issues-M-3')\n",
    "                   .withColumnRenamed('Bucket_Sub_Bucket_Churn_Cancellations_Churn_cancellations_process', 'Bucket_Sub_Bucket_Churn_Cancellations_Churn_cancellations_process-M-3')\n",
    "                   .withColumnRenamed('Bucket_Sub_Bucket_Prepaid_balance_Top_up_process', 'Bucket_Sub_Bucket_Prepaid_balance_Top_up_process-M-3')\n",
    "                   .withColumnRenamed('Bucket_Sub_Bucket_Churn_Cancellations_Negotiation', 'Bucket_Sub_Bucket_Churn_Cancellations_Negotiation-M-3')\n",
    "                   .withColumnRenamed('Bucket_Sub_Bucket_Churn_Cancellations_Referrals', 'Bucket_Sub_Bucket_Churn_Cancellations_Referrals-M-3')\n",
    "                   .withColumnRenamed('Bucket_Sub_Bucket_Churn_Cancellations_Transfers', 'Bucket_Sub_Bucket_Churn_Cancellations_Transfers-M-3')\n",
    "                   .withColumnRenamed('Bucket_Sub_Bucket_Churn_Cancellations_Network', 'Bucket_Sub_Bucket_Churn_Cancellations_Network-M-3')\n",
    "                   .withColumnRenamed('Raw_Productos_Voz', 'Raw_Productos_Voz-M-3')\n",
    "                   .withColumnRenamed('Raw_Resultado_Bajas', 'Raw_Resultado_Bajas-M-3')\n",
    "                   .withColumnRenamed('Raw_Provision_Resto', 'Raw_Provision_Resto-M-3')\n",
    "                   .withColumnRenamed('Raw_Provision_Movil', 'Raw_Provision_Movil-M-3')\n",
    "                   .withColumnRenamed('Bucket_Churn_Cancellations', 'Bucket_Churn_Cancellations-M-3')\n",
    "                   .withColumnRenamed('Bucket_Prepaid_balance', 'Bucket_Prepaid_balance-M-3')\n",
    "                   .withColumnRenamed('Raw_Baja', 'Raw_Baja-M-3')\n",
    "                   .withColumnRenamed('Raw_Cierre', 'Raw_Cierre-M-3')\n",
    "\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Llamadas a competidores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitor_calls_M_2 = (competitor_calls_M_2\n",
    "                        .withColumnRenamed('group', 'group_M-2')\n",
    "                        .withColumnRenamed('total_duration', 'total_duration_M-2')\n",
    "                        .withColumnRenamed('times_called', 'times_called_M-2')\n",
    "                        .withColumnRenamed('event_date', 'event_date_M-2')\n",
    "                        .withColumnRenamed('load_date', 'load_date_M-2')\n",
    "                        .withColumnRenamed('competitor', 'competitor_M-2')\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitor_calls_M_3 = (competitor_calls_M_3\n",
    "                        .withColumnRenamed('group', 'group_M-3')\n",
    "                        .withColumnRenamed('total_duration', 'total_duration_M-3')\n",
    "                        .withColumnRenamed('times_called', 'times_called_M-3')\n",
    "                        .withColumnRenamed('event_date', 'event_date_M-3')\n",
    "                        .withColumnRenamed('load_date', 'load_date_M-3')\n",
    "                        .withColumnRenamed('competitor', 'competitor_M-3')\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unimos todo lo anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_CAR_SRV=(serviceDF_load.select('msisdn', 'NUM_CLIENTE')\n",
    "      .join(netscout_apps_load, 'msisdn', 'leftouter')\n",
    "      .join(custAggServices, 'NUM_CLIENTE', 'leftouter')\n",
    "      .join(df_ccc_load_M_2, 'msisdn', 'leftouter')\n",
    "      .join(df_ccc_load_M_3, 'msisdn', 'leftouter')\n",
    "      .join(competitor_calls_M_2, 'msisdn', 'leftouter')\n",
    "      .join(competitor_calls_M_3, 'msisdn', 'leftouter')\n",
    "             ).drop('NUM_CLIENTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_CAR_SRV_prepared = (data_CAR_SRV.withColumn('ClosingDay',lit(ClosingDay)).drop(*['nacionalidad']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepaid_final = df_final.join(data_CAR_SRV_prepared, on = 'msisdn', how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANTE: El atributo `month_of_analysis` se utiliza para separar las muestras de entrenamiento de las muestras de predicción después de haber ejecutado el General Model Trainer:\n",
    "   - Para el IDS de entrenamiento: `month_of_analysis` = *Month of training = M-1*.\n",
    "   - Para el IDS de predicción: `month_of_analysis` = *Month of prediction = M*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepaid_final = prepaid_final.withColumn('month_of_analysis', lit('Month of training = M-1').cast(StringType()))\n",
    "prepaid_final = prepaid_final.withColumn('month_of_analysis', lit('Month of prediction = M').cast(StringType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\n",
    " 'TRATAMIENTO',\n",
    " 'NOMBRE',\n",
    " 'PRIM_APELLIDO',\n",
    " 'SEG_APELLIDO',\n",
    " 'CLASE_CLI_COD_CLASE_CLIENTE',\n",
    " 'DIR_LINEA1',\n",
    " 'DIR_LINEA2',\n",
    " 'DIR_LINEA3',\n",
    " 'COD_ESTADO_GENERAL',\n",
    " 'NOM_COMPLETO',\n",
    " 'DIR_FACTURA1',\n",
    " 'DIR_FACTURA2',\n",
    " 'DIR_FACTURA3',\n",
    " 'DIR_FACTURA4',\n",
    " 'TRAT_FACT',\n",
    " 'NOMBRE_CLI_FACT',\n",
    " 'APELLIDO1_CLI_FACT',\n",
    " 'APELLIDO2_CLI_FACT',\n",
    " 'DIR_NUM_DIRECCION',\n",
    " 'NIF_CLIENTE',\n",
    " 'FECHA_NACI',\n",
    " 'METODO_PAGO',\n",
    " 'PUBLICIDAD',\n",
    " 'ENCUESTAS',\n",
    " 'CTA_CORREO_CONTACTO',\n",
    " 'CTA_CORREO',\n",
    " 'FACTURA_CATALAN',\n",
    " 'FACTURA_ELECTRONICA',\n",
    " 'SUPEROFERTA',\n",
    " 'NIF_FACTURACION',\n",
    " 'X_PUBLICIDAD_EMAIL',\n",
    " 'CICLO',\n",
    " 'x_tipo_cuenta_corp',\n",
    " 'x_antiguedad_cuenta',\n",
    " 'x_datos_navegacion',\n",
    " 'x_datos_trafico',\n",
    " 'x_cesion_datos',\n",
    " 'x_user_facebook',\n",
    " 'x_user_twitter',\n",
    " 'FLG_LORTAD',\n",
    " 'FLG_ROBINSON',\n",
    " 'X_FORMATO_FACTURA',\n",
    " 'X_IDIOMA_FACTURA',\n",
    " 'FECHA_MIGRACION',\n",
    " 'ENCUESTAS2',\n",
    " 'cta_correo_flag',\n",
    " 'cta_correo_server',\n",
    " 'Instancia_P',\n",
    " 'OBJID',\n",
    " 'TACADA',\n",
    " 'FX_SRV_BASIC',\n",
    " 'PRICE_SRV_BASIC',\n",
    " 'RGU',\n",
    " 'TIPO_SIM',\n",
    " 'IMSI',\n",
    " 'TARIFF',\n",
    " 'FX_TARIFF',\n",
    " 'DESC_TARIFF',\n",
    " 'PRICE_TARIFF',\n",
    " 'VOICE_TARIFF',\n",
    " 'FX_VOICE_TARIFF',\n",
    " 'PRICE_VOICE_TARIFF',\n",
    " 'DATA',\n",
    " 'FX_DATA',\n",
    " 'PRICE_DATA',\n",
    " 'DTO_LEV1',\n",
    " 'FX_DTO_LEV1',\n",
    " 'PRICE_DTO_LEV1',\n",
    " 'DTO_LEV2',\n",
    " 'FX_DTO_LEV2',\n",
    " 'PRICE_DTO_LEV2',\n",
    " 'DTO_LEV3',\n",
    " 'FX_DTO_LEV3',\n",
    " 'PRICE_DTO_LEV3',\n",
    " 'DATA_ADDITIONAL',\n",
    " 'FX_DATA_ADDITIONAL',\n",
    " 'PRICE_DATA_ADDITIONAL',\n",
    " 'OOB',\n",
    " 'FX_OOB',\n",
    " 'PRICE_OOB',\n",
    " 'NETFLIX_NAPSTER',\n",
    " 'FX_NETFLIX_NAPSTER',\n",
    " 'PRICE_NETFLIX_NAPSTER',\n",
    " 'ROAMING_BASIC',\n",
    " 'FX_ROAMING_BASIC',\n",
    " 'PRICE_ROAMING_BASIC',\n",
    " 'ROAM_USA_EUR',\n",
    " 'FX_ROAM_USA_EUR',\n",
    " 'PRICE_ROAM_USA_EUR',\n",
    " 'ROAM_ZONA_2',\n",
    " 'FX_ROAM_ZONA_2',\n",
    " 'PRICE_ROAM_ZONA_2',\n",
    " 'CONSUM_MIN',\n",
    " 'FX_CONSUM_MIN',\n",
    " 'PRICE_CONSUM_MIN',\n",
    " 'SIM_VF',\n",
    " 'HOMEZONE',\n",
    " 'FX_HOMEZONE',\n",
    " 'PRICE_HOMEZONE',\n",
    " 'MOBILE_HOMEZONE',\n",
    " 'FBB_UPGRADE',\n",
    " 'FX_FBB_UPGRADE',\n",
    " 'PRICE_FBB_UPGRADE',\n",
    " 'DECO_TV',\n",
    " 'FX_DECO_TV',\n",
    " 'PRICE_DECO_TV',\n",
    " 'NUM_SERIE_DECO_TV',\n",
    " 'OBJID_DECO_TV',\n",
    " 'TV_CUOTA_ALTA',\n",
    " 'FX_TV_CUOTA_ALTA',\n",
    " 'PRICE_TV_CUOTA_ALTA',\n",
    " 'TV_TARIFF',\n",
    " 'FX_TV_TARIFF',\n",
    " 'PRICE_TV_TARIFF',\n",
    " 'TV_CUOT_CHARGES',\n",
    " 'FX_TV_CUOT_CHARGES',\n",
    " 'PRICE_TV_CUOT_CHARGES',\n",
    " 'TV_PROMO',\n",
    " 'FX_TV_PROMO',\n",
    " 'PRICE_TV_PROMO',\n",
    " 'TV_PROMO_USER',\n",
    " 'FX_TV_PROMO_USER',\n",
    " 'PRICE_TV_PROMO_USER',\n",
    " 'TV_ABONOS',\n",
    " 'FX_TV_ABONOS',\n",
    " 'PRICE_TV_ABONOS',\n",
    " 'TV_LOYALTY',\n",
    " 'FX_TV_LOYALTY',\n",
    " 'PRICE_TV_LOYALTY',\n",
    " 'TV_SVA',\n",
    " 'FX_TV_SVA',\n",
    " 'PRICE_TV_SVA',\n",
    " 'FOOTBALL_TV',\n",
    " 'FX_FOOTBALL_TV',\n",
    " 'PRICE_FOOTBALL_TV',\n",
    " 'MOTOR_TV',\n",
    " 'FX_MOTOR_TV',\n",
    " 'PRICE_MOTOR_TV',\n",
    " 'PVR_TV',\n",
    " 'FX_PVR_TV',\n",
    " 'PRICE_PVR_TV',\n",
    " 'ZAPPER_TV',\n",
    " 'FX_ZAPPER_TV',\n",
    " 'PRICE_ZAPPER_TV',\n",
    " 'TRYBUY_TV',\n",
    " 'FX_TRYBUY_TV',\n",
    " 'PRICE_TRYBUY_TV',\n",
    " 'TRYBUY_AUTOM_TV',\n",
    " 'FX_TRYBUY_AUTOM_TV',\n",
    " 'PRICE_TRYBUY_AUTOM_TV',\n",
    " 'CAMPO1',\n",
    " 'CAMPO2',\n",
    " 'CAMPO3',\n",
    " 'flag_msisdn_err',\n",
    " 'TV_TOTAL_CHARGES',\n",
    " 'MOBILE_BAM_TOTAL_CHARGES',\n",
    " 'msisdn_CAR',\n",
    " 'Fecha_ejecucion'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "msisdn_cols = [c for c in prepaid_final.columns if 'MSISDN_' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepaid_final = prepaid_final.drop(*drop_cols+msisdn_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|Churned|  count|\n",
      "+-------+-------+\n",
      "|   null|1521707|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prepaid_final.groupBy('Churned').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escribimos los datos almacenados en la BDP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANTE**: Cuando estemos almacenando el IDS de una nueva ejecución en una tabla de la BDP, es necesario utilizar el modo 'overwrite'. Después, para ensamblar las muestras de entrenamiento sobre las muestras de predicción, es necesario que utilicemos el modo 'append', para que no borre los registros anteriormente guardados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepaid_final.write.saveAsTable('tests_es.carnaum2_churn_prepago_ids', format='parquet', mode='append') # Use *mode = 'overwrite'* or 'append'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string or a number, not 'datetime.timedelta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-779d9b71aee6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtotal_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtotal_time_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tiempo de ejecución '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtotal_time\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' segundos'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string or a number, not 'datetime.timedelta'"
     ]
    }
   ],
   "source": [
    "end_time = dt.datetime.now()\n",
    "total_time = 2*str(int(end_time - start_time))\n",
    "total_time_sec=total_time.total_seconds() \n",
    "print('Tiempo de ejecución ' + total_time+' segundos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
