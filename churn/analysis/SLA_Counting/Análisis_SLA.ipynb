{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added '/var/SP/data/home/bgmerin1/src/Repositorios/use-cases' to path\n",
      "Added '/var/SP/data/home/bgmerin1/src/Repositorios' to path\n"
     ]
    }
   ],
   "source": [
    "def set_paths():\n",
    "    '''\n",
    "    Deployment should be something like \"dirs/dir1/use-cases\"\n",
    "    This function adds to the path \"dirs/dir1/use-cases\" and \"dirs/dir1/\"\n",
    "    :return:\n",
    "    '''\n",
    "    import imp\n",
    "    from os.path import dirname\n",
    "    import os\n",
    "    import sys\n",
    "\n",
    "    USE_CASES = \"/var/SP/data/home/bgmerin1/src/Repositorios/use-cases\"#dirname(os.path.abspath(imp.find_module('churn')[1]))\n",
    "\n",
    "    if USE_CASES not in sys.path:\n",
    "        sys.path.append(USE_CASES)\n",
    "        print(\"Added '{}' to path\".format(USE_CASES))\n",
    "\n",
    "    # if deployment is correct, this path should be the one that contains \"use-cases\", \"pykhaos\", ...\n",
    "    # FIXME another way of doing it more general?\n",
    "    DEVEL_SRC = os.path.dirname(USE_CASES)  # dir before use-cases dir\n",
    "    if DEVEL_SRC not in sys.path:\n",
    "        sys.path.append(DEVEL_SRC)\n",
    "        print(\"Added '{}' to path\".format(DEVEL_SRC))\n",
    "set_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import greatest, lower, upper, trim,least\n",
    "from pyspark.sql.functions import collect_set, col, lpad, lit, collect_list, desc, asc, mean as sql_mean, sum as sql_sum, datediff, count as sql_count\n",
    "#from pyspark.sql.types import StringType, ArrayType, MapType, StructType, StructField, IntegerType\n",
    "from pyspark.sql.functions import array, regexp_extract, datediff, to_date, from_unixtime, unix_timestamp, desc, when, col, lit, udf, size, \\\n",
    "    array, isnan, upper, coalesce, length, lower, concat, create_map, sum as sql_sum, greatest, max as sql_max, sort_array\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "import re\n",
    "from pyspark.sql.types import ArrayType, FloatType, StringType\n",
    "from pyspark.sql.functions import datediff\n",
    "import numpy as np\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import lag, mean as sql_avg\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pyspark.sql.functions import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para que no haga falta recargar el notebook si hacemos un cambio en alguna de las funciones que estamos importando\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set BDP parameters\n",
    "def setting_bdp(min_n_executors = 3, max_n_executors = 15, n_cores = 8, executor_memory = \"12g\", driver_memory=\"8g\",\n",
    "                   app_name = \"Python app\", driver_overhead=\"1g\", executor_overhead='3g'):\n",
    "\n",
    "    MAX_N_EXECUTORS = max_n_executors\n",
    "    MIN_N_EXECUTORS = min_n_executors\n",
    "    N_CORES_EXECUTOR = n_cores\n",
    "    EXECUTOR_IDLE_MAX_TIME = 120\n",
    "    EXECUTOR_MEMORY = executor_memory\n",
    "    DRIVER_MEMORY = driver_memory\n",
    "    N_CORES_DRIVER = 1\n",
    "    MEMORY_OVERHEAD = N_CORES_EXECUTOR * 2048\n",
    "    QUEUE = \"root.BDPtenants.es.medium\"\n",
    "    BDA_CORE_VERSION = \"1.0.0\"\n",
    "\n",
    "    SPARK_COMMON_OPTS = os.environ.get('SPARK_COMMON_OPTS', '')\n",
    "    SPARK_COMMON_OPTS += \" --executor-memory %s --driver-memory %s\" % (EXECUTOR_MEMORY, DRIVER_MEMORY)\n",
    "    SPARK_COMMON_OPTS += \" --conf spark.shuffle.manager=tungsten-sort\"\n",
    "    SPARK_COMMON_OPTS += \"  --queue %s\" % QUEUE\n",
    "\n",
    "    # Dynamic allocation configuration\n",
    "    SPARK_COMMON_OPTS += \" --conf spark.dynamicAllocation.enabled=true\"\n",
    "    SPARK_COMMON_OPTS += \" --conf spark.shuffle.service.enabled=true\"\n",
    "    SPARK_COMMON_OPTS += \" --conf spark.dynamicAllocation.maxExecutors=%s\" % (MAX_N_EXECUTORS)\n",
    "    SPARK_COMMON_OPTS += \" --conf spark.dynamicAllocation.minExecutors=%s\" % (MIN_N_EXECUTORS)\n",
    "    SPARK_COMMON_OPTS += \" --conf spark.executor.cores=%s\" % (N_CORES_EXECUTOR)\n",
    "    SPARK_COMMON_OPTS += \" --conf spark.dynamicAllocation.executorIdleTimeout=%s\" % (EXECUTOR_IDLE_MAX_TIME)\n",
    "    # SPARK_COMMON_OPTS += \" --conf spark.ui.port=58235\"\n",
    "    SPARK_COMMON_OPTS += \" --conf spark.port.maxRetries=100\"\n",
    "    SPARK_COMMON_OPTS += \" --conf spark.app.name='%s'\" % (app_name)\n",
    "    SPARK_COMMON_OPTS += \" --conf spark.submit.deployMode=client\"\n",
    "    SPARK_COMMON_OPTS += \" --conf spark.ui.showConsoleProgress=true\"\n",
    "    SPARK_COMMON_OPTS += \" --conf spark.sql.broadcastTimeout=1200\"\n",
    "    SPARK_COMMON_OPTS += \" --conf spark.yarn.executor.memoryOverhead={}\".format(executor_overhead)\n",
    "    SPARK_COMMON_OPTS += \" --conf spark.yarn.executor.driverOverhead={}\".format(driver_overhead)\n",
    "\n",
    "    BDA_ENV = os.environ.get('BDA_USER_HOME', '')\n",
    "\n",
    "    # Attach bda-core-ra codebase\n",
    "    SPARK_COMMON_OPTS+=\" --files {}/scripts/properties/red_agent/nodes.properties,{}/scripts/properties/red_agent/nodes-de.properties,{}/scripts/properties/red_agent/nodes-es.properties,{}/scripts/properties/red_agent/nodes-ie.properties,{}/scripts/properties/red_agent/nodes-it.properties,{}/scripts/properties/red_agent/nodes-pt.properties,{}/scripts/properties/red_agent/nodes-uk.properties\".format(*[BDA_ENV]*7)\n",
    "\n",
    "    os.environ[\"SPARK_COMMON_OPTS\"] = SPARK_COMMON_OPTS\n",
    "    os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"%s pyspark-shell \" % SPARK_COMMON_OPTS\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spark_session(app_name=\"default name\", log_level='INFO', min_n_executors = 3, max_n_executors = 15, n_cores = 4, executor_memory = \"12g\", driver_memory=\"8g\"):\n",
    "    HOME_SRC = os.path.join(os.environ.get('BDA_USER_HOME', ''), \"src\")\n",
    "    if HOME_SRC not in sys.path:\n",
    "        sys.path.append(HOME_SRC)\n",
    "\n",
    "\n",
    "    setting_bdp(app_name=app_name, min_n_executors = min_n_executors, max_n_executors = max_n_executors, n_cores = n_cores, executor_memory = executor_memory, driver_memory=driver_memory)\n",
    "    from common.src.main.python.utils.hdfs_generic import run_sc\n",
    "    sc, spark, sql_context = run_sc(log_level=log_level)\n",
    "\n",
    "\n",
    "    return sc, spark, sql_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(app_name, min_n_executors = 3, max_n_executors = 15, n_cores = 4, executor_memory = \"12g\", driver_memory=\"8g\"):\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(\"_initialize spark\")\n",
    "    #import pykhaos.utils.pyspark_configuration as pyspark_config\n",
    "    sc, spark, sql_context = get_spark_session(app_name=app_name, log_level=\"OFF\", min_n_executors = min_n_executors, max_n_executors = max_n_executors, n_cores = n_cores,\n",
    "                             executor_memory = executor_memory, driver_memory=driver_memory)\n",
    "    print(\"Ended spark session: {} secs | default parallelism={}\".format(time.time() - start_time,\n",
    "                                                                         sc.defaultParallelism))\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_initialize spark\n",
      "Ended spark session: 35.6452200413 secs | default parallelism=2\n"
     ]
    }
   ],
   "source": [
    "spark = initialize(\"Analisys SLA\",executor_memory = \"32g\",min_n_executors = 6,max_n_executors = 15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_master=spark.read.parquet('/data/attributes/vf_es/trigger_analysis/customer_master/year=2019/month=5/day=21')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3899811"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_master_ppF=customer_master.filter(col('segment_nif')!='Pure_prepaid')\n",
    "customer_master_ppF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5540911"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccc=spark.read.parquet('/data/attributes/vf_es/trigger_analysis/ccc/year=2019/month=5/day=21')\n",
    "ccc.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3899811"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccc_ppF=customer_master_ppF.join(ccc,'NIF_CLIENTE','left')\n",
    "ccc_ppF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3795363"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cccFiltered=ccc_ppF.select(['nif_cliente','CHURN_CANCELLATIONS_w4','label']).filter(col('CHURN_CANCELLATIONS_w4')==0)\n",
    "cccFiltered.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSLA=spark.read.parquet('/user/bgmerin1/SLA/year=2019/month=5/day=21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2292929"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSLALabeled=customer_master.join(dfSLA,['nif_cliente'],'inner')\n",
    "dfSLALabeled.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|label|  count|\n",
      "+-----+-------+\n",
      "|  0.0|2211383|\n",
      "|  1.0|  81546|\n",
      "+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfSLALabeled.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1740807"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSLALabeledCCC=dfSLA.join(cccFiltered,['nif_cliente'],'inner')\n",
    "dfSLALabeledCCC.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|label|  count|\n",
      "+-----+-------+\n",
      "|  0.0|1676067|\n",
      "|  1.0|  64740|\n",
      "+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfSLALabeledCCC.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Churn y factor SLA \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordenes cerradas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "days_range = [30, 60, 90, 120, 180, 240, 365]\n",
    "\n",
    "#volumen y churn rate\n",
    "\n",
    "dfLabel=dfSLALabeled.groupBy('label').count()\n",
    "dfAgr=dfLabel.toPandas()\n",
    "label0=dfAgr.iloc[0]['count']\n",
    "label1=dfAgr.iloc[1]['count']  \n",
    "    \n",
    "print 'Churn rate:', label1/(label1+label0)*100\n",
    "print dfLabel.show()\n",
    "\n",
    "for day in days_range:\n",
    "    print 'Range Day:',day \n",
    "    \n",
    "    cont=0\n",
    "        \n",
    "    var='mean_sla_factor_last'+str(day)\n",
    "    dfSLALabeledC=dfSLALabeled.filter(col(var)>-1)\n",
    "    \n",
    "    while cont <= 2:\n",
    "    \n",
    "        if cont==0: \n",
    "            dfSLALabeledFilter=dfSLALabeledC.filter(col(var)<1)\n",
    "            titulo='Max_SLA <1:'\n",
    "        if cont==1: \n",
    "            dfSLALabeledFilter=dfSLALabeledC.filter((col(var)>1) & (col(var)<3))\n",
    "            titulo='1 < Max_SLA <3:'\n",
    "        if cont==2: \n",
    "            dfSLALabeledFilter=dfSLALabeledC.filter(col(var)>3)\n",
    "            titulo='Max_SLA > 3:'\n",
    "        \n",
    "        dfLabel=dfSLALabeledFilter.groupBy('label').count()\n",
    "        dfAgr=dfLabel.toPandas()\n",
    "        label0=dfAgr.iloc[0]['count']\n",
    "        label1=dfAgr.iloc[1]['count']\n",
    "        \n",
    "        print titulo,label1/(label1+label0)*100\n",
    "        print dfLabel.show()\n",
    "        cont=cont+1\n",
    "        \n",
    "    print '\\n'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Incluyendo el filtro CCC\n",
    "\n",
    "days_range = [30, 60, 90, 120, 180, 240, 365]\n",
    "\n",
    "dfLabel=dfSLALabeledCCC.groupBy('label').count()\n",
    "dfAgr=dfLabel.toPandas()\n",
    "label0=dfAgr.iloc[0]['count']\n",
    "label1=dfAgr.iloc[1]['count']  \n",
    "    \n",
    "print 'Churn rate:', label1/(label1+label0)*100\n",
    "print dfLabel.show()\n",
    "\n",
    "del dfLabel\n",
    "\n",
    "#volumen y churn rate\n",
    "\n",
    "for day in days_range:\n",
    "    print 'Range Day:',day \n",
    "    \n",
    "    cont=0\n",
    "        \n",
    "    var='mean_sla_factor_last'+str(day)\n",
    "        \n",
    "    while cont <= 2:\n",
    "    \n",
    "        if cont==0: \n",
    "            dfSLALabeledFilter=dfSLALabeledCCC.filter(col(var)<1)\n",
    "            titulo='Max_SLA <1:'\n",
    "        if cont==1: \n",
    "            dfSLALabeledFilter=dfSLALabeledCCC.filter((col(var)>1) & (col(var)<3))\n",
    "            titulo='1 < Max_SLA <3:'\n",
    "        if cont==2: \n",
    "            dfSLALabeledFilter=dfSLALabeledCCC.filter(col(var)>3)\n",
    "            titulo='Max_SLA > 3:'\n",
    "        \n",
    "        dfLabel=dfSLALabeledFilter.groupBy('label').count()\n",
    "        dfAgr=dfLabel.toPandas()\n",
    "        label0=dfAgr.iloc[0]['count']\n",
    "        label1=dfAgr.iloc[1]['count']\n",
    "    \n",
    "        print(titulo,label1/(label1+label0)*100)\n",
    "        print dfLabel.show()\n",
    "    \n",
    "        del dfSLALabeledFilter\n",
    "        del dfLabel\n",
    "        \n",
    "        cont=cont+1\n",
    "        \n",
    "    print '\\n'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordenes abiertas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import greatest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range Day: 30\n",
      "Churn rate: 3.556411908087865\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0| 2211383|\n",
      "|  1.0|   81546|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "2252419\n",
      "('Max_SLA <1:', 3.419346045296191)\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0| 2175401|\n",
      "|  1.0|   77018|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "8651\n",
      "('1 < Max_SLA <3:', 12.796208530805686)\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0|    7544|\n",
      "|  1.0|    1107|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "28705\n",
      "('Max_SLA > 3:', 10.88312140742031)\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0|   25581|\n",
      "|  1.0|    3124|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "Range Day: 60\n",
      "Churn rate: 3.556411908087865\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0| 2211383|\n",
      "|  1.0|   81546|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "2212395\n",
      "('Max_SLA <1:', 3.381041812153797)\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0| 2137593|\n",
      "|  1.0|   74802|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "10146\n",
      "('1 < Max_SLA <3:', 11.856889414547606)\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0|    8943|\n",
      "|  1.0|    1203|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "67295\n",
      "('Max_SLA > 3:', 7.797013151051341)\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0|   62048|\n",
      "|  1.0|    5247|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "Range Day: 90\n",
      "Churn rate: 3.556411908087865\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0| 2211383|\n",
      "|  1.0|   81546|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "2191748\n",
      "('Max_SLA <1:', 3.3673123005017)\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0| 2117945|\n",
      "|  1.0|   73803|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "12909\n",
      "('1 < Max_SLA <3:', 10.666976528003719)\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0|   11532|\n",
      "|  1.0|    1377|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "85185\n",
      "('Max_SLA > 3:', 7.130363326876797)\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0|   79111|\n",
      "|  1.0|    6074|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "Range Day: 120\n",
      "Churn rate: 3.556411908087865\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0| 2211383|\n",
      "|  1.0|   81546|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "2181114\n",
      "('Max_SLA <1:', 3.364335839392164)\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0| 2107734|\n",
      "|  1.0|   73380|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "13416\n",
      "('1 < Max_SLA <3:', 10.457662492546213)\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0|   12013|\n",
      "|  1.0|    1403|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "95320\n",
      "('Max_SLA > 3:', 6.791859001258917)\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0|   88846|\n",
      "|  1.0|    6474|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "Range Day: 180\n",
      "Churn rate: 3.556411908087865\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0| 2211383|\n",
      "|  1.0|   81546|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "2173661\n",
      "('Max_SLA <1:', 3.362483846377149)\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0| 2100572|\n",
      "|  1.0|   73089|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "13529\n",
      "('1 < Max_SLA <3:', 10.399881735531082)\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0|   12122|\n",
      "|  1.0|    1407|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "102669\n",
      "('Max_SLA > 3:', 6.586213949682962)\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0|   95907|\n",
      "|  1.0|    6762|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "Range Day: 240\n",
      "Churn rate: 3.556411908087865\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0| 2211383|\n",
      "|  1.0|   81546|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "2173661\n",
      "('Max_SLA <1:', 3.362483846377149)\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0| 2100572|\n",
      "|  1.0|   73089|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "13529\n",
      "('1 < Max_SLA <3:', 10.399881735531082)\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0|   12122|\n",
      "|  1.0|    1407|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "102669\n",
      "('Max_SLA > 3:', 6.586213949682962)\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0|   95907|\n",
      "|  1.0|    6762|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "Range Day: 365\n",
      "Churn rate: 3.556411908087865\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0| 2211383|\n",
      "|  1.0|   81546|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "2173661\n",
      "('Max_SLA <1:', 3.362483846377149)\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0| 2100572|\n",
      "|  1.0|   73089|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "13529\n",
      "('1 < Max_SLA <3:', 10.399881735531082)\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0|   12122|\n",
      "|  1.0|    1407|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "102669\n",
      "('Max_SLA > 3:', 6.586213949682962)\n",
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|  0.0|   95907|\n",
      "|  1.0|    6762|\n",
      "+-----+--------+\n",
      "\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Con el total de 칩rdenes abiertas (sin importar el tipo o si est치n dentro o fuera de SLA)\n",
    "\n",
    "days_range = [30, 60, 90, 120, 180, 240, 365]\n",
    "\n",
    "for day in days_range:\n",
    "    \n",
    "    print 'Range Day:',day\n",
    "    selColumns=[]\n",
    "    for column in dfSLALabeled.columns:\n",
    "        if 'Max_SLA_factor_running'+str(day) in column:\n",
    "            selColumns.append(column)\n",
    "\n",
    "    dfMaxLabeled=(dfSLALabeled.withColumn('Max_'+str(day),greatest(*selColumns)).select(['nif_cliente','label','Max_'+str(day)]))\n",
    "    #dfMinLabeled=(dfSLALabeled.withColumn('Min_'+str(day),least(*selColumns)).select(['nif_cliente','label','Min_'+str(day)]))\n",
    "\n",
    "    dfMaxLabeledC=dfMaxLabeled.filter(col('Max_'+str(day))>-1)\n",
    "    \n",
    "    dfLabel=dfMaxLabeledC.groupBy('label').agg(count('*'))\n",
    "    dfAgr=dfLabel.toPandas()\n",
    "    label0=dfAgr.iloc[0]['count(1)']\n",
    "    label1=dfAgr.iloc[1]['count(1)']\n",
    "    \n",
    "    print 'Churn rate:', label1/(label1+label0)*100\n",
    "    print dfLabel.show()\n",
    "        \n",
    "    var='Max_'+str(day)\n",
    "    \n",
    "    cont=0\n",
    "    \n",
    "    while cont <= 2:\n",
    "    \n",
    "        if cont==0: \n",
    "            dfMaxLabeledFilter=dfMaxLabeledC.filter(col(var)<1)\n",
    "            titulo='Max_SLA <1:'\n",
    "        if cont==1: \n",
    "            dfMaxLabeledFilter=dfMaxLabeledC.filter((col(var)>1) & (col(var)<3))\n",
    "            titulo='1 < Max_SLA <3:'\n",
    "        if cont==2: \n",
    "            dfMaxLabeledFilter=dfMaxLabeledC.filter(col(var)>3)\n",
    "            titulo='Max_SLA > 3:'\n",
    "        \n",
    "        print(dfMaxLabeledFilter.count())\n",
    "        dfLabel=dfMaxLabeledFilter.groupBy('label').agg(count('*'))\n",
    "        dfAgr=dfLabel.toPandas()\n",
    "        label0=dfAgr.iloc[0]['count(1)']\n",
    "        label1=dfAgr.iloc[1]['count(1)']\n",
    "    \n",
    "        print(titulo,label1/(label1+label0)*100)\n",
    "        print dfLabel.show()\n",
    "        \n",
    "        cont=cont+1\n",
    "        \n",
    "    print '\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in dfSLALabeled.columns:\n",
    "    if 'Max_SLA_factor_running30' in column:\n",
    "        selColumns.append(column)\n",
    "\n",
    "dfMaxLabeledddd=(dfSLALabeled.withColumn('Max_30',greatest(*selColumns)).select(['nif_cliente','label','Max_30']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+------+\n",
      "|nif_cliente|label|Max_30|\n",
      "+-----------+-----+------+\n",
      "+-----------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfMaxLabeledddd.filter(col('Max_30')<0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con el total de 칩rdenes abiertas (sin importar el tipo o si est치n dentro o fuera de SLA)\n",
    "## Incluyendo el filtro CCC\n",
    "\n",
    "\n",
    "days_range = [30, 60, 90, 120, 180, 240, 365]\n",
    "\n",
    "\n",
    "for day in days_range:\n",
    "    \n",
    "    cont=0\n",
    "    \n",
    "    print 'Range Day:',day\n",
    "    selColumns=[]\n",
    "    for column in dfSLALabeledCCC.columns:\n",
    "        if 'Max_SLA_factor_running'+str(day) in column:\n",
    "            selColumns.append(column)\n",
    "            \n",
    "    dfMaxLabeled=(dfSLALabeledCCC.withColumn('Max_'+str(day),greatest(*selColumns)).select(['nif_cliente','label','Max_'+str(day)]))\n",
    "    dfMaxLabeledC=dfMaxLabeled.dropna(subset='Max_'+str(day))\n",
    "    \n",
    "    print(dfMaxLabeledC.count())    \n",
    "    \n",
    "    dfLabel=dfMaxLabeledC.groupBy('label').agg(count('*'))\n",
    "    dfAgr=dfLabel.toPandas()\n",
    "    label0=dfAgr.iloc[0]['count(1)']\n",
    "    label1=dfAgr.iloc[1]['count(1)'] \n",
    "    \n",
    "    print('Churn Rate',label1/(label1+label0)*100)\n",
    "    \n",
    "    var='Max_'+str(day)\n",
    "    \n",
    "    while cont <= 2:\n",
    "    \n",
    "        if cont==0: \n",
    "            dfMaxLabeledFilter=dfMaxLabeledC.filter(col(var)<1)\n",
    "            titulo='Max_SLA <1:'\n",
    "        if cont==1: \n",
    "            dfMaxLabeledFilter=dfMaxLabeledC.filter((col(var)>1) & (col(var)<3))\n",
    "            titulo='1 < Max_SLA <3:'\n",
    "        if cont==2: \n",
    "            dfMaxLabeledFilter=dfMaxLabeledC.filter(col(var)>3)\n",
    "            titulo='Max_SLA > 3:'\n",
    "\n",
    "        print 'Churn rate:', label1/(label1+label0)*100\n",
    "        print dfLabel.show()\n",
    "\n",
    "        print(dfMaxLabeledFilter.count())\n",
    "        dfLabel=dfMaxLabeledFilter.groupBy('label').agg(count('*'))\n",
    "        dfAgr=dfLabel.toPandas()\n",
    "        label0=dfAgr.iloc[0]['count(1)']\n",
    "        label1=dfAgr.iloc[1]['count(1)']\n",
    "\n",
    "        print(titulo,label1/(label1+label0)*100)\n",
    "\n",
    "        del dfMaxLabeledFilter\n",
    "        del dfLabel\n",
    "\n",
    "        cont=cont+1\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selColumns=[]\n",
    "day=30\n",
    "for column in dfSLALabeled.columns:\n",
    "    if 'Max_SLA_factor_running'+str(day) in column:\n",
    "        selColumns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMaxx=(dfSLALabeled.withColumn('Max_30',greatest(*selColumns)).select(['nif_cliente','label','Max_30']))\n",
    "dfMaxx.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMaxx.filter((col('Max_30')<3) & (col('Max_30')>1)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMaxxx=(dfSLA.withColumn('Max_30',greatest(*selColumns)).select(['nif_cliente','Max_30']))\n",
    "\n",
    "dfMaxxx.filter((col('Max_30')<3) & (col('Max_30')>1)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disminucion_Max_SLA_factor_running30_OutsideSLA\n",
    "disminucion_Max_SLA_factor_running60_OutsideSLA\n",
    "disminucion_Max_SLA_factor_running90_OutsideSLA\n",
    "disminucion_Max_SLA_factor_running120_OutsideSLA\n",
    "disminucion_Max_SLA_factor_running180_OutsideSLA\n",
    "disminucion_Max_SLA_factor_running240_OutsideSLA\n",
    "disminucion_Max_SLA_factor_running365_OutsideSLA\n",
    "disminucion_Max_SLA_factor_running30_InsideSLA\n",
    "disminucion_Max_SLA_factor_running60_InsideSLA\n",
    "disminucion_Max_SLA_factor_running90_InsideSLA\n",
    "disminucion_Max_SLA_factor_running120_InsideSLA\n",
    "disminucion_Max_SLA_factor_running180_InsideSLA\n",
    "disminucion_Max_SLA_factor_running240_InsideSLA\n",
    "disminucion_Max_SLA_factor_running365_InsideSLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_range = [30, 60, 90, 120, 180, 240, 365]\n",
    "\n",
    "for day in days_range:\n",
    "    print(day)\n",
    "    print('Label1/(Label0+Label1) %')\n",
    "    \n",
    "    var='mean_sla_factor_last'+str(day)\n",
    "        \n",
    "    dfSLALabeledFilter=dfSLALabeled.filter(col(var)<1)\n",
    "    dfLabel=dfSLALabeledFilter.groupBy('label').agg(count('*'))\n",
    "    dfAgr=dfLabel.toPandas()\n",
    "    label0=dfAgr.iloc[0]['count(1)']\n",
    "    label1=dfAgr.iloc[1]['count(1)']\n",
    "    \n",
    "    print('Filtro <1:',label1/(label1+label0)*100)\n",
    "        \n",
    "    dfSLALabeledFilter=dfSLALabeled.filter((col(var)>1) & (col(var)<3))\n",
    "    dfLabel=dfSLALabeledFilter.groupBy('label').agg(count('*'))\n",
    "    dfAgr=dfLabel.toPandas()\n",
    "    label0=dfAgr.iloc[0]['count(1)']\n",
    "    label1=dfAgr.iloc[1]['count(1)']\n",
    "    \n",
    "    print('Filtro >1 y <3:',label1/(label1+label0)*100)\n",
    "        \n",
    "    dfSLALabeledFilter=dfSLALabeled.filter(col(var)>3)\n",
    "    dfLabel=dfSLALabeledFilter.groupBy('label').agg(count('*'))\n",
    "    dfAgr=dfLabel.toPandas()\n",
    "    label0=dfAgr.iloc[0]['count(1)']\n",
    "    label1=dfAgr.iloc[1]['count(1)']\n",
    "    \n",
    "    print('Filtro >3:',label1/(label1+label0)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn factor_SLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mas churn mas se va de SLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn tipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_master.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
